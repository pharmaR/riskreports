\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\makeatletter\@ifl@t@r\fmtversion{2018/04/01}{}{\usepackage[utf8]{inputenc}}\makeatother
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `dplyr'}}
\par\bigskip{\large \today}
\end{center}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdftitle = {dplyr: A Grammar of Data Manipulation}}}{}
\ifthenelse{\boolean{Rd@use@hyper}}{\hypersetup{pdfauthor = {Hadley Wickham; Romain François; Lionel Henry; Kirill Müller; Davis Vaughan}}}{}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{A Grammar of Data Manipulation}
\item[Version]\AsIs{1.1.4}
\item[Description]\AsIs{A fast, consistent tool for working with data frame like
objects, both in memory and out of memory.}
\item[License]\AsIs{MIT + file LICENSE}
\item[URL]\AsIs{}\url{https://dplyr.tidyverse.org}\AsIs{, }\url{https://github.com/tidyverse/dplyr}\AsIs{}
\item[BugReports]\AsIs{}\url{https://github.com/tidyverse/dplyr/issues}\AsIs{}
\item[Depends]\AsIs{R (>= 3.5.0)}
\item[Imports]\AsIs{cli (>= 3.4.0), generics, glue (>= 1.3.2), lifecycle (>=
1.0.3), magrittr (>= 1.5), methods, pillar (>= 1.9.0), R6,
rlang (>= 1.1.0), tibble (>= 3.2.0), tidyselect (>= 1.2.0),
utils, vctrs (>= 0.6.4)}
\item[Suggests]\AsIs{bench, broom, callr, covr, DBI, dbplyr (>= 2.2.1), ggplot2,
knitr, Lahman, lobstr, microbenchmark, nycflights13, purrr,
rmarkdown, RMySQL, RPostgreSQL, RSQLite, stringi (>= 1.7.6),
testthat (>= 3.1.5), tidyr (>= 1.3.0), withr}
\item[VignetteBuilder]\AsIs{knitr}
\item[Config/Needs/website]\AsIs{tidyverse, shiny, pkgdown, tidyverse/tidytemplate}
\item[Config/testthat/edition]\AsIs{3}
\item[Encoding]\AsIs{UTF-8}
\item[LazyData]\AsIs{true}
\item[RoxygenNote]\AsIs{7.2.3}
\item[NeedsCompilation]\AsIs{yes}
\item[Author]\AsIs{Hadley Wickham [aut, cre] (<}\url{https://orcid.org/0000-0003-4757-117X}\AsIs{>),
Romain François [aut] (<}\url{https://orcid.org/0000-0002-2444-4226}\AsIs{>),
Lionel Henry [aut],
Kirill Müller [aut] (<}\url{https://orcid.org/0000-0002-1416-3412}\AsIs{>),
Davis Vaughan [aut] (<}\url{https://orcid.org/0000-0003-4777-038X}\AsIs{>),
Posit Software, PBC [cph, fnd]}
\item[Maintainer]\AsIs{Hadley Wickham }\email{hadley@posit.co}\AsIs{}
\item[Repository]\AsIs{CRAN}
\item[Date/Publication]\AsIs{2023-11-17 16:50:02 UTC}
\item[Archs]\AsIs{x64}
\end{description}
\Rdcontents{Contents}
\HeaderA{dplyr-package}{dplyr: A Grammar of Data Manipulation}{dplyr.Rdash.package}
\aliasA{dplyr}{dplyr-package}{dplyr}
\keyword{internal}{dplyr-package}
%
\begin{Description}
To learn more about dplyr, start with the vignettes:
\code{browseVignettes(package = "dplyr")}
\end{Description}
%
\begin{Author}
\strong{Maintainer}: Hadley Wickham \email{hadley@posit.co} (\Rhref{https://orcid.org/0000-0003-4757-117X}{ORCID})

Authors:
\begin{itemize}

\item{} Romain François (\Rhref{https://orcid.org/0000-0002-2444-4226}{ORCID})
\item{} Lionel Henry
\item{} Kirill Müller (\Rhref{https://orcid.org/0000-0002-1416-3412}{ORCID})
\item{} Davis Vaughan \email{davis@posit.co} (\Rhref{https://orcid.org/0000-0003-4777-038X}{ORCID})

\end{itemize}


Other contributors:
\begin{itemize}

\item{} Posit Software, PBC [copyright holder, funder]

\end{itemize}


\end{Author}
%
\begin{SeeAlso}
Useful links:
\begin{itemize}

\item{} \url{https://dplyr.tidyverse.org}
\item{} \url{https://github.com/tidyverse/dplyr}
\item{} Report bugs at \url{https://github.com/tidyverse/dplyr/issues}

\end{itemize}


\end{SeeAlso}
\HeaderA{across}{Apply a function (or functions) across multiple columns}{across}
\aliasA{if\_all}{across}{if.Rul.all}
\aliasA{if\_any}{across}{if.Rul.any}
%
\begin{Description}
\code{across()} makes it easy to apply the same transformation to multiple
columns, allowing you to use \code{\LinkA{select()}{select}} semantics inside in "data-masking"
functions like \code{\LinkA{summarise()}{summarise}} and \code{\LinkA{mutate()}{mutate}}. See \code{vignette("colwise")} for
more details.

\code{if\_any()} and \code{if\_all()} apply the same
predicate function to a selection of columns and combine the
results into a single logical vector: \code{if\_any()} is \code{TRUE} when
the predicate is \code{TRUE} for \emph{any} of the selected columns, \code{if\_all()}
is \code{TRUE} when the predicate is \code{TRUE} for \emph{all} selected columns.

If you just need to select columns without applying a transformation to each
of them, then you probably want to use \code{\LinkA{pick()}{pick}} instead.

\code{across()} supersedes the family of "scoped variants" like
\code{summarise\_at()}, \code{summarise\_if()}, and \code{summarise\_all()}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
across(.cols, .fns, ..., .names = NULL, .unpack = FALSE)

if_any(.cols, .fns, ..., .names = NULL)

if_all(.cols, .fns, ..., .names = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.cols}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Columns to transform.
You can't select grouping columns because they are already automatically
handled by the verb (i.e. \code{\LinkA{summarise()}{summarise}} or \code{\LinkA{mutate()}{mutate}}).

\item[\code{.fns}] Functions to apply to each of the selected columns.
Possible values are:
\begin{itemize}

\item{} A function, e.g. \code{mean}.
\item{} A purrr-style lambda, e.g. \code{\textasciitilde{} mean(.x, na.rm = TRUE)}
\item{} A named list of functions or lambdas, e.g.
\AsIs{\texttt{list(mean = mean, n\_miss = \textasciitilde{} sum(is.na(.x))}}. Each function is applied
to each column, and the output is named by combining the function name
and the column name using the glue specification in \code{.names}.

\end{itemize}


Within these functions you can use \code{\LinkA{cur\_column()}{cur.Rul.column}} and \code{\LinkA{cur\_group()}{cur.Rul.group}}
to access the current column and grouping keys respectively.

\item[\code{...}] \strong{[Deprecated]}

Additional arguments for the function calls in \code{.fns} are no longer
accepted in \code{...} because it's not clear when they should be evaluated:
once per \code{across()} or once per group? Instead supply additional arguments
directly in \code{.fns} by using a lambda. For example, instead of
\code{across(a:b, mean, na.rm = TRUE)} write
\code{across(a:b, \textasciitilde{} mean(.x, na.rm = TRUE))}.

\item[\code{.names}] A glue specification that describes how to name the output
columns. This can use \code{\{.col\}} to stand for the selected column name, and
\code{\{.fn\}} to stand for the name of the function being applied. The default
(\code{NULL}) is equivalent to \code{"\{.col\}"} for the single function case and
\code{"\{.col\}\_\{.fn\}"} for the case where a list is used for \code{.fns}.

\item[\code{.unpack}] \strong{[Experimental]}

Optionally \LinkA{unpack}{unpack} data frames returned by functions in
\code{.fns}, which expands the df-columns out into individual columns, retaining
the number of rows in the data frame.
\begin{itemize}

\item{} If \code{FALSE}, the default, no unpacking is done.
\item{} If \code{TRUE}, unpacking is done with a default glue specification of
\code{"\{outer\}\_\{inner\}"}.
\item{} Otherwise, a single glue specification can be supplied to describe how to
name the unpacked columns. This can use \code{\{outer\}} to refer to the name
originally generated by \code{.names}, and \code{\{inner\}} to refer to the names of
the data frame you are unpacking.

\end{itemize}

\end{ldescription}
\end{Arguments}
%
\begin{Value}
\code{across()} typically returns a tibble with one column for each column in
\code{.cols} and each function in \code{.fns}. If \code{.unpack} is used, more columns may
be returned depending on how the results of \code{.fns} are unpacked.

\code{if\_any()} and \code{if\_all()} return a logical vector.
\end{Value}
%
\begin{Section}{Timing of evaluation}

R code in dplyr verbs is generally evaluated once per group.
Inside \code{across()} however, code is evaluated once for each
combination of columns and groups. If the evaluation timing is
important, for example if you're generating random variables, think
about when it should happen and place your code in consequence.

\begin{alltt}gdf <-
  tibble(g = c(1, 1, 2, 3), v1 = 10:13, v2 = 20:23) %>%
  group_by(g)

set.seed(1)

# Outside: 1 normal variate
n <- rnorm(1)
gdf %>% mutate(across(v1:v2, ~ .x + n))
#> # A tibble: 4 x 3
#> # Groups:   g [3]
#>       g    v1    v2
#>   <dbl> <dbl> <dbl>
#> 1     1  9.37  19.4
#> 2     1 10.4   20.4
#> 3     2 11.4   21.4
#> 4     3 12.4   22.4

# Inside a verb: 3 normal variates (ngroup)
gdf %>% mutate(n = rnorm(1), across(v1:v2, ~ .x + n))
#> # A tibble: 4 x 4
#> # Groups:   g [3]
#>       g    v1    v2      n
#>   <dbl> <dbl> <dbl>  <dbl>
#> 1     1  10.2  20.2  0.184
#> 2     1  11.2  21.2  0.184
#> 3     2  11.2  21.2 -0.836
#> 4     3  14.6  24.6  1.60

# Inside `across()`: 6 normal variates (ncol * ngroup)
gdf %>% mutate(across(v1:v2, ~ .x + rnorm(1)))
#> # A tibble: 4 x 3
#> # Groups:   g [3]
#>       g    v1    v2
#>   <dbl> <dbl> <dbl>
#> 1     1  10.3  20.7
#> 2     1  11.3  21.7
#> 3     2  11.2  22.6
#> 4     3  13.5  22.7
\end{alltt}

\end{Section}
%
\begin{SeeAlso}
\code{\LinkA{c\_across()}{c.Rul.across}} for a function that returns a vector
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# For better printing
iris <- as_tibble(iris)

# across() -----------------------------------------------------------------
# Different ways to select the same set of columns
# See <https://tidyselect.r-lib.org/articles/syntax.html> for details
iris %>%
  mutate(across(c(Sepal.Length, Sepal.Width), round))
iris %>%
  mutate(across(c(1, 2), round))
iris %>%
  mutate(across(1:Sepal.Width, round))
iris %>%
  mutate(across(where(is.double) & !c(Petal.Length, Petal.Width), round))

# Using an external vector of names
cols <- c("Sepal.Length", "Petal.Width")
iris %>%
  mutate(across(all_of(cols), round))

# If the external vector is named, the output columns will be named according
# to those names
names(cols) <- tolower(cols)
iris %>%
  mutate(across(all_of(cols), round))

# A purrr-style formula
iris %>%
  group_by(Species) %>%
  summarise(across(starts_with("Sepal"), ~ mean(.x, na.rm = TRUE)))

# A named list of functions
iris %>%
  group_by(Species) %>%
  summarise(across(starts_with("Sepal"), list(mean = mean, sd = sd)))

# Use the .names argument to control the output names
iris %>%
  group_by(Species) %>%
  summarise(across(starts_with("Sepal"), mean, .names = "mean_{.col}"))
iris %>%
  group_by(Species) %>%
  summarise(across(starts_with("Sepal"), list(mean = mean, sd = sd), .names = "{.col}.{.fn}"))

# If a named external vector is used for column selection, .names will use
# those names when constructing the output names
iris %>%
  group_by(Species) %>%
  summarise(across(all_of(cols), mean, .names = "mean_{.col}"))

# When the list is not named, .fn is replaced by the function's position
iris %>%
  group_by(Species) %>%
  summarise(across(starts_with("Sepal"), list(mean, sd), .names = "{.col}.fn{.fn}"))

# When the functions in .fns return a data frame, you typically get a
# "packed" data frame back
quantile_df <- function(x, probs = c(0.25, 0.5, 0.75)) {
  tibble(quantile = probs, value = quantile(x, probs))
}

iris %>%
  reframe(across(starts_with("Sepal"), quantile_df))

# Use .unpack to automatically expand these packed data frames into their
# individual columns
iris %>%
  reframe(across(starts_with("Sepal"), quantile_df, .unpack = TRUE))

# .unpack can utilize a glue specification if you don't like the defaults
iris %>%
  reframe(across(starts_with("Sepal"), quantile_df, .unpack = "{outer}.{inner}"))

# This is also useful inside mutate(), for example, with a multi-lag helper
multilag <- function(x, lags = 1:3) {
  names(lags) <- as.character(lags)
  purrr::map_dfr(lags, lag, x = x)
}

iris %>%
  group_by(Species) %>%
  mutate(across(starts_with("Sepal"), multilag, .unpack = TRUE)) %>%
  select(Species, starts_with("Sepal"))

# if_any() and if_all() ----------------------------------------------------
iris %>%
  filter(if_any(ends_with("Width"), ~ . > 4))
iris %>%
  filter(if_all(ends_with("Width"), ~ . > 2))

\end{ExampleCode}
\end{Examples}
\HeaderA{add\_rownames}{Convert row names to an explicit variable.}{add.Rul.rownames}
\keyword{internal}{add\_rownames}
%
\begin{Description}
\strong{[Deprecated]}
Please use \code{\LinkA{tibble::rownames\_to\_column()}{tibble::rownames.Rul.to.Rul.column()}} instead.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
add_rownames(df, var = "rowname")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{df}] Input data frame with rownames.

\item[\code{var}] Name of variable to use
\end{ldescription}
\end{Arguments}
\HeaderA{all\_equal}{Flexible equality comparison for data frames}{all.Rul.equal}
\keyword{internal}{all\_equal}
%
\begin{Description}
\strong{[Deprecated]}

\code{all\_equal()} allows you to compare data frames, optionally ignoring
row and column names. It is deprecated as of dplyr 1.1.0, because it
makes it too easy to ignore important differences.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
all_equal(
  target,
  current,
  ignore_col_order = TRUE,
  ignore_row_order = TRUE,
  convert = FALSE,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{target}, \code{current}] Two data frames to compare.

\item[\code{ignore\_col\_order}] Should order of columns be ignored?

\item[\code{ignore\_row\_order}] Should order of rows be ignored?

\item[\code{convert}] Should similar classes be converted? Currently this will
convert factor to character and integer to double.

\item[\code{...}] Ignored. Needed for compatibility with \code{all.equal()}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
\code{TRUE} if equal, otherwise a character vector describing
the reasons why they're not equal. Use \code{\LinkA{isTRUE()}{isTRUE}} if using the
result in an \code{if} expression.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
scramble <- function(x) x[sample(nrow(x)), sample(ncol(x))]

# `all_equal()` ignored row and column ordering by default,
# but we now feel that that makes it too easy to make mistakes
mtcars2 <- scramble(mtcars)
all_equal(mtcars, mtcars2)

# Instead, be explicit about the row and column ordering
all.equal(
  mtcars,
  mtcars2[rownames(mtcars), names(mtcars)]
)
\end{ExampleCode}
\end{Examples}
\HeaderA{all\_vars}{Apply predicate to all variables}{all.Rul.vars}
\aliasA{any\_vars}{all\_vars}{any.Rul.vars}
%
\begin{Description}
\strong{[Superseded]}

\code{all\_vars()} and \code{any\_vars()} were only needed for the scoped verbs, which
have been superseded by the use of \code{\LinkA{across()}{across}} in an existing verb. See
\code{vignette("colwise")} for details.

These quoting functions signal to scoped filtering verbs
(e.g. \code{\LinkA{filter\_if()}{filter.Rul.if}} or \code{\LinkA{filter\_all()}{filter.Rul.all}}) that a predicate expression
should be applied to all relevant variables. The \code{all\_vars()}
variant takes the intersection of the predicate expressions with
\code{\&} while the \code{any\_vars()} variant takes the union with \code{|}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
all_vars(expr)

any_vars(expr)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{expr}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> An expression that
returns a logical vector, using \code{.} to refer to the "current" variable.
\end{ldescription}
\end{Arguments}
%
\begin{SeeAlso}
\code{\LinkA{vars()}{vars}} for other quoting functions that you
can use with scoped verbs.
\end{SeeAlso}
\HeaderA{args\_by}{Helper for consistent documentation of \code{.by}}{args.Rul.by}
\keyword{internal}{args\_by}
%
\begin{Description}
Use \AsIs{\texttt{@inheritParams args\_by}} to consistently document \code{.by}.
\end{Description}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.by}] \strong{[Experimental]}

<\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Optionally, a selection of columns to
group by for just this operation, functioning as an alternative to \code{\LinkA{group\_by()}{group.Rul.by}}. For
details and examples, see \LinkA{?dplyr\_by}{dplyr.Rul.by}.
\end{ldescription}
\end{Arguments}
\HeaderA{arrange}{Order rows using column values}{arrange}
\methaliasA{arrange.data.frame}{arrange}{arrange.data.frame}
\keyword{single table verbs}{arrange}
%
\begin{Description}
\code{arrange()} orders the rows of a data frame by the values of selected
columns.

Unlike other dplyr verbs, \code{arrange()} largely ignores grouping; you
need to explicitly mention grouping variables (or use  \code{.by\_group = TRUE})
in order to group by them, and functions of variables are evaluated
once per data frame, not once per group.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
arrange(.data, ..., .by_group = FALSE)

## S3 method for class 'data.frame'
arrange(.data, ..., .by_group = FALSE, .locale = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Variables, or
functions of variables. Use \code{\LinkA{desc()}{desc}} to sort a variable in descending
order.

\item[\code{.by\_group}] If \code{TRUE}, will sort first by grouping variable. Applies to
grouped data frames only.

\item[\code{.locale}] The locale to sort character vectors in.
\begin{itemize}

\item{} If \code{NULL}, the default, uses the \code{"C"} locale unless the
\code{dplyr.legacy\_locale} global option escape hatch is active. See the
\LinkA{dplyr-locale}{dplyr.Rdash.locale} help page for more details.
\item{} If a single string from \code{\LinkA{stringi::stri\_locale\_list()}{stringi::stri.Rul.locale.Rul.list()}} is supplied, then
this will be used as the locale to sort with. For example, \code{"en"} will
sort with the American English locale. This requires the stringi package.
\item{} If \code{"C"} is supplied, then character vectors will always be sorted in the
C locale. This does not require stringi and is often much faster than
supplying a locale identifier.

\end{itemize}


The C locale is not the same as English locales, such as \code{"en"},
particularly when it comes to data containing a mix of upper and lower case
letters. This is explained in more detail on the \LinkA{locale}{dplyr.Rdash.locale}
help page under the \AsIs{\texttt{Default locale}} section.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
%
\begin{SubSection}{Missing values}

Unlike base sorting with \code{sort()}, \code{NA} are:
\begin{itemize}

\item{} always sorted to the end for local data, even when wrapped with \code{desc()}.
\item{} treated differently for remote data, depending on the backend.

\end{itemize}

\end{SubSection}

\end{Details}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} All rows appear in the output, but (usually) in a different place.
\item{} Columns are not modified.
\item{} Groups are not modified.
\item{} Data frame attributes are preserved.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{filter}{filter}()},
\code{\LinkA{mutate}{mutate}()},
\code{\LinkA{reframe}{reframe}()},
\code{\LinkA{rename}{rename}()},
\code{\LinkA{select}{select}()},
\code{\LinkA{slice}{slice}()},
\code{\LinkA{summarise}{summarise}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
arrange(mtcars, cyl, disp)
arrange(mtcars, desc(disp))

# grouped arrange ignores groups
by_cyl <- mtcars %>% group_by(cyl)
by_cyl %>% arrange(desc(wt))
# Unless you specifically ask:
by_cyl %>% arrange(desc(wt), .by_group = TRUE)

# use embracing when wrapping in a function;
# see ?rlang::args_data_masking for more details
tidy_eval_arrange <- function(.data, var) {
  .data %>%
    arrange({{ var }})
}
tidy_eval_arrange(mtcars, mpg)

# Use `across()` or `pick()` to select columns with tidy-select
iris %>% arrange(pick(starts_with("Sepal")))
iris %>% arrange(across(starts_with("Sepal"), desc))
\end{ExampleCode}
\end{Examples}
\HeaderA{arrange\_all}{Arrange rows by a selection of variables}{arrange.Rul.all}
\aliasA{arrange\_at}{arrange\_all}{arrange.Rul.at}
\aliasA{arrange\_if}{arrange\_all}{arrange.Rul.if}
\keyword{internal}{arrange\_all}
%
\begin{Description}
\strong{[Superseded]}

Scoped verbs (\AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}}, \AsIs{\texttt{\_all}}) have been superseded by the use of
\code{\LinkA{pick()}{pick}} or \code{\LinkA{across()}{across}} in an existing verb. See \code{vignette("colwise")} for
details.

These \LinkA{scoped}{scoped} variants of \code{\LinkA{arrange()}{arrange}} sort a data frame by a
selection of variables. Like \code{\LinkA{arrange()}{arrange}}, you can modify the
variables before ordering with the \code{.funs} argument.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
arrange_all(.tbl, .funs = list(), ..., .by_group = FALSE, .locale = NULL)

arrange_at(.tbl, .vars, .funs = list(), ..., .by_group = FALSE, .locale = NULL)

arrange_if(
  .tbl,
  .predicate,
  .funs = list(),
  ...,
  .by_group = FALSE,
  .locale = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.funs}] A function \code{fun}, a quosure style lambda \code{\textasciitilde{} fun(.)} or a list of either form.

\item[\code{...}] Additional arguments for the function calls in
\code{.funs}. These are evaluated only once, with \LinkA{tidy dots}{tidy dots} support.

\item[\code{.by\_group}] If \code{TRUE}, will sort first by grouping variable. Applies to
grouped data frames only.

\item[\code{.locale}] The locale to sort character vectors in.
\begin{itemize}

\item{} If \code{NULL}, the default, uses the \code{"C"} locale unless the
\code{dplyr.legacy\_locale} global option escape hatch is active. See the
\LinkA{dplyr-locale}{dplyr.Rdash.locale} help page for more details.
\item{} If a single string from \code{\LinkA{stringi::stri\_locale\_list()}{stringi::stri.Rul.locale.Rul.list()}} is supplied, then
this will be used as the locale to sort with. For example, \code{"en"} will
sort with the American English locale. This requires the stringi package.
\item{} If \code{"C"} is supplied, then character vectors will always be sorted in the
C locale. This does not require stringi and is often much faster than
supplying a locale identifier.

\end{itemize}


The C locale is not the same as English locales, such as \code{"en"},
particularly when it comes to data containing a mix of upper and lower case
letters. This is explained in more detail on the \LinkA{locale}{dplyr.Rdash.locale}
help page under the \AsIs{\texttt{Default locale}} section.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Grouping variables}


The grouping variables that are part of the selection participate
in the sorting of the data frame.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
df <- as_tibble(mtcars)
arrange_all(df)
# ->
arrange(df, pick(everything()))

arrange_all(df, desc)
# ->
arrange(df, across(everything(), desc))
\end{ExampleCode}
\end{Examples}
\HeaderA{auto\_copy}{Copy tables to same source, if necessary}{auto.Rul.copy}
%
\begin{Description}
Copy tables to same source, if necessary
\end{Description}
%
\begin{Usage}
\begin{verbatim}
auto_copy(x, y, copy = FALSE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] \code{y} will be copied to \code{x}, if necessary.

\item[\code{copy}] If \code{x} and \code{y} are not from the same data source,
and \code{copy} is \code{TRUE}, then \code{y} will be copied into the
same src as \code{x}.  This allows you to join tables across srcs, but
it is a potentially expensive operation so you must opt into it.

\item[\code{...}] Other arguments passed on to methods.
\end{ldescription}
\end{Arguments}
\HeaderA{backend\_dbplyr}{Database and SQL generics.}{backend.Rul.dbplyr}
\aliasA{db\_analyze}{backend\_dbplyr}{db.Rul.analyze}
\aliasA{db\_begin}{backend\_dbplyr}{db.Rul.begin}
\aliasA{db\_commit}{backend\_dbplyr}{db.Rul.commit}
\aliasA{db\_create\_index}{backend\_dbplyr}{db.Rul.create.Rul.index}
\aliasA{db\_create\_indexes}{backend\_dbplyr}{db.Rul.create.Rul.indexes}
\aliasA{db\_create\_table}{backend\_dbplyr}{db.Rul.create.Rul.table}
\aliasA{db\_data\_type}{backend\_dbplyr}{db.Rul.data.Rul.type}
\aliasA{db\_desc}{backend\_dbplyr}{db.Rul.desc}
\aliasA{db\_drop\_table}{backend\_dbplyr}{db.Rul.drop.Rul.table}
\aliasA{db\_explain}{backend\_dbplyr}{db.Rul.explain}
\aliasA{db\_has\_table}{backend\_dbplyr}{db.Rul.has.Rul.table}
\aliasA{db\_insert\_into}{backend\_dbplyr}{db.Rul.insert.Rul.into}
\aliasA{db\_list\_tables}{backend\_dbplyr}{db.Rul.list.Rul.tables}
\aliasA{db\_query\_fields}{backend\_dbplyr}{db.Rul.query.Rul.fields}
\aliasA{db\_query\_rows}{backend\_dbplyr}{db.Rul.query.Rul.rows}
\aliasA{db\_rollback}{backend\_dbplyr}{db.Rul.rollback}
\aliasA{db\_save\_query}{backend\_dbplyr}{db.Rul.save.Rul.query}
\aliasA{db\_write\_table}{backend\_dbplyr}{db.Rul.write.Rul.table}
\aliasA{sql\_escape\_ident}{backend\_dbplyr}{sql.Rul.escape.Rul.ident}
\aliasA{sql\_escape\_string}{backend\_dbplyr}{sql.Rul.escape.Rul.string}
\aliasA{sql\_join}{backend\_dbplyr}{sql.Rul.join}
\aliasA{sql\_select}{backend\_dbplyr}{sql.Rul.select}
\aliasA{sql\_semi\_join}{backend\_dbplyr}{sql.Rul.semi.Rul.join}
\aliasA{sql\_set\_op}{backend\_dbplyr}{sql.Rul.set.Rul.op}
\aliasA{sql\_subquery}{backend\_dbplyr}{sql.Rul.subquery}
\aliasA{sql\_translate\_env}{backend\_dbplyr}{sql.Rul.translate.Rul.env}
\keyword{internal}{backend\_dbplyr}
%
\begin{Description}
The \code{sql\_} generics are used to build the different types of SQL queries.
The default implementations in dbplyr generates ANSI 92 compliant SQL.
The \code{db\_} generics execute actions on the database. The default
implementations in dbplyr typically just call the standard DBI S4
method.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
db_desc(x)

sql_translate_env(con)

db_list_tables(con)

db_has_table(con, table)

db_data_type(con, fields)

db_save_query(con, sql, name, temporary = TRUE, ...)

db_begin(con, ...)

db_commit(con, ...)

db_rollback(con, ...)

db_write_table(con, table, types, values, temporary = FALSE, ...)

db_create_table(con, table, types, temporary = FALSE, ...)

db_insert_into(con, table, values, ...)

db_create_indexes(con, table, indexes = NULL, unique = FALSE, ...)

db_create_index(con, table, columns, name = NULL, unique = FALSE, ...)

db_drop_table(con, table, force = FALSE, ...)

db_analyze(con, table, ...)

db_explain(con, sql, ...)

db_query_fields(con, sql, ...)

db_query_rows(con, sql, ...)

sql_select(
  con,
  select,
  from,
  where = NULL,
  group_by = NULL,
  having = NULL,
  order_by = NULL,
  limit = NULL,
  distinct = FALSE,
  ...
)

sql_subquery(con, from, name = random_table_name(), ...)

sql_join(con, x, y, vars, type = "inner", by = NULL, ...)

sql_semi_join(con, x, y, anti = FALSE, by = NULL, ...)

sql_set_op(con, x, y, method)

sql_escape_string(con, x)

sql_escape_ident(con, x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{con}] A database connection.

\item[\code{table}] A string, the table name.

\item[\code{fields}] A list of fields, as in a data frame.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
A few backend methods do not call the standard DBI S4 methods including
\begin{itemize}

\item{} \code{db\_data\_type()}: Calls \code{\LinkA{DBI::dbDataType()}{DBI::dbDataType()}} for every field
(e.g. data frame column) and returns a vector of corresponding SQL data
types
\item{} \code{db\_save\_query()}: Builds and executes a
\AsIs{\texttt{CREATE [TEMPORARY] TABLE <table> ...}} SQL command.
\item{} \code{db\_create\_index()}: Builds and executes a
\AsIs{\texttt{CREATE INDEX <name> ON <table>}} SQL command.
\item{} \code{db\_drop\_table()}: Builds and executes a
\AsIs{\texttt{DROP TABLE [IF EXISTS]  <table>}} SQL command.
\item{} \code{db\_analyze()}: Builds and executes an
\AsIs{\texttt{ANALYZE <table>}} SQL command.

\end{itemize}


Currently, \code{\LinkA{copy\_to()}{copy.Rul.to}} is the only user of \code{db\_begin()}, \code{db\_commit()},
\code{db\_rollback()}, \code{db\_write\_table()}, \code{db\_create\_indexes()}, \code{db\_drop\_table()} and
\code{db\_analyze()}. If you find yourself overriding many of these
functions it may suggest that you should just override \code{copy\_to()}
instead.

\code{db\_create\_table()} and \code{db\_insert\_into()} have been deprecated
in favour of \code{db\_write\_table()}.
\end{Details}
%
\begin{Value}
Usually a logical value indicating success. Most failures should generate
an error. However, \code{db\_has\_table()} should return \code{NA} if
temporary tables cannot be listed with \code{\LinkA{DBI::dbListTables()}{DBI::dbListTables()}} (due to backend
API limitations for example). As a result, you methods will rely on the
backend to throw an error if a table exists when it shouldn't.
\end{Value}
\HeaderA{band\_members}{Band membership}{band.Rul.members}
\aliasA{band\_instruments}{band\_members}{band.Rul.instruments}
\aliasA{band\_instruments2}{band\_members}{band.Rul.instruments2}
\keyword{datasets}{band\_members}
%
\begin{Description}
These data sets describe band members of the Beatles and Rolling Stones. They
are toy data sets that can be displayed in their entirety on a slide (e.g. to
demonstrate a join).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
band_members

band_instruments

band_instruments2
\end{verbatim}
\end{Usage}
%
\begin{Format}
Each is a tibble with two variables and three observations
\end{Format}
%
\begin{Details}
\code{band\_instruments} and \code{band\_instruments2} contain the same data but use
different column names for the first column of the data set.
\code{band\_instruments} uses \code{name}, which matches the name of the key column of
\code{band\_members}; \code{band\_instruments2} uses \code{artist}, which does not.
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
band_members
band_instruments
band_instruments2
\end{ExampleCode}
\end{Examples}
\HeaderA{between}{Detect where values fall in a specified range}{between}
%
\begin{Description}
This is a shortcut for \code{x >= left \& x <= right}, implemented for local
vectors and translated to the appropriate SQL for remote tables.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
between(x, left, right)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A vector

\item[\code{left}, \code{right}] Boundary values. Both \code{left} and \code{right} are recycled to
the size of \code{x}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
\code{x}, \code{left}, and \code{right} are all cast to their common type before the
comparison is made.
\end{Details}
%
\begin{Value}
A logical vector the same size as \code{x}.
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{join\_by()}{join.Rul.by}} if you are looking for documentation for the \code{between()} overlap
join helper.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
between(1:12, 7, 9)

x <- rnorm(1e2)
x[between(x, -1, 1)]

# On a tibble using `filter()`
filter(starwars, between(height, 100, 150))
\end{ExampleCode}
\end{Examples}
\HeaderA{bind\_cols}{Bind multiple data frames by column}{bind.Rul.cols}
%
\begin{Description}
Bind any number of data frames by column, making a wider result.
This is similar to \code{do.call(cbind, dfs)}.

Where possible prefer using a \LinkA{join}{left.Rul.join} to combine multiple
data frames. \code{bind\_cols()} binds the rows in order in which they appear
so it is easy to create meaningless results without realising it.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
bind_cols(
  ...,
  .name_repair = c("unique", "universal", "check_unique", "minimal")
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] Data frames to combine. Each argument can either be a data frame,
a list that could be a data frame, or a list of data frames.
Inputs are \LinkA{recycled}{recycled} to the same length,
then matched by position.

\item[\code{.name\_repair}] One of \code{"unique"}, \code{"universal"}, or
\code{"check\_unique"}. See \code{\LinkA{vctrs::vec\_as\_names()}{vctrs::vec.Rul.as.Rul.names()}} for the meaning of these
options.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame the same type as the first element of \code{...}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
df1 <- tibble(x = 1:3)
df2 <- tibble(y = 3:1)
bind_cols(df1, df2)

# Row sizes must be compatible when column-binding
try(bind_cols(tibble(x = 1:3), tibble(y = 1:2)))
\end{ExampleCode}
\end{Examples}
\HeaderA{bind\_rows}{Bind multiple data frames by row}{bind.Rul.rows}
\aliasA{bind}{bind\_rows}{bind}
%
\begin{Description}
Bind any number of data frames by row, making a longer result. This is
similar to \code{do.call(rbind, dfs)}, but the output will contain all columns
that appear in any of the inputs.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
bind_rows(..., .id = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] Data frames to combine. Each argument can either be a data frame,
a list that could be a data frame, or a list of data frames. Columns are
matched by name, and any missing columns will be filled with \code{NA}.

\item[\code{.id}] The name of an optional identifier column. Provide a string to
create an output column that identifies each input. The column will use
names if available, otherwise it will use positions.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame the same type as the first element of \code{...}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
df1 <- tibble(x = 1:2, y = letters[1:2])
df2 <- tibble(x = 4:5, z = 1:2)

# You can supply individual data frames as arguments:
bind_rows(df1, df2)

# Or a list of data frames:
bind_rows(list(df1, df2))

# When you supply a column name with the `.id` argument, a new
# column is created to link each row to its original data frame
bind_rows(list(df1, df2), .id = "id")
bind_rows(list(a = df1, b = df2), .id = "id")
\end{ExampleCode}
\end{Examples}
\HeaderA{case\_match}{A general vectorised \code{switch()}}{case.Rul.match}
%
\begin{Description}
This function allows you to vectorise multiple \code{\LinkA{switch()}{switch}} statements. Each
case is evaluated sequentially and the first match for each element
determines the corresponding value in the output vector. If no cases match,
the \code{.default} is used.

\code{case\_match()} is an R equivalent of the SQL "simple" \AsIs{\texttt{CASE WHEN}} statement.
%
\begin{SubSection}{Connection to \code{case\_when()}}

While \code{\LinkA{case\_when()}{case.Rul.when}} uses logical expressions on the left-hand side of the
formula, \code{case\_match()} uses values to match against \code{.x} with. The following
two statements are roughly equivalent:

\begin{alltt}case_when(
  x %in% c("a", "b") ~ 1,
  x %in% "c" ~ 2,
  x %in% c("d", "e") ~ 3
)

case_match(
  x,
  c("a", "b") ~ 1,
  "c" ~ 2,
  c("d", "e") ~ 3
)
\end{alltt}

\end{SubSection}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
case_match(.x, ..., .default = NULL, .ptype = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.x}] A vector to match against.

\item[\code{...}] <\code{\LinkA{dynamic-dots}{dynamic.Rdash.dots}}> A sequence of two-sided
formulas: \code{old\_values \textasciitilde{} new\_value}. The right hand side (RHS) determines
the output value for all values of \code{.x} that match the left hand side
(LHS).

The LHS must evaluate to the same type of vector as \code{.x}. It can be any
length, allowing you to map multiple \code{.x} values to the same RHS value.
If a value is repeated in the LHS, i.e. a value in \code{.x} matches to
multiple cases, the first match is used.

The RHS inputs will be coerced to their common type. Each RHS input will be
\LinkA{recycled}{recycled} to the size of \code{.x}.

\item[\code{.default}] The value used when values in \code{.x} aren't matched by any of
the LHS inputs. If \code{NULL}, the default, a missing value will be used.

\code{.default} is \LinkA{recycled}{recycled} to the size of
\code{.x}.

\item[\code{.ptype}] An optional prototype declaring the desired output type. If
not supplied, the output type will be taken from the common type of
all RHS inputs and \code{.default}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector with the same size as \code{.x} and the same type as the common type of
the RHS inputs and \code{.default} (if not overridden by \code{.ptype}).
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{case\_when()}{case.Rul.when}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x <- c("a", "b", "a", "d", "b", NA, "c", "e")

# `case_match()` acts like a vectorized `switch()`.
# Unmatched values "fall through" as a missing value.
case_match(
  x,
  "a" ~ 1,
  "b" ~ 2,
  "c" ~ 3,
  "d" ~ 4
)

# Missing values can be matched exactly, and `.default` can be used to
# control the value used for unmatched values of `.x`
case_match(
  x,
  "a" ~ 1,
  "b" ~ 2,
  "c" ~ 3,
  "d" ~ 4,
  NA ~ 0,
  .default = 100
)

# Input values can be grouped into the same expression to map them to the
# same output value
case_match(
  x,
  c("a", "b") ~ "low",
  c("c", "d", "e") ~ "high"
)

# `case_match()` isn't limited to character input:
y <- c(1, 2, 1, 3, 1, NA, 2, 4)

case_match(
  y,
  c(1, 3) ~ "odd",
  c(2, 4) ~ "even",
  .default = "missing"
)

# Setting `.default` to the original vector is a useful way to replace
# selected values, leaving everything else as is
case_match(y, NA ~ 0, .default = y)

starwars %>%
  mutate(
    # Replace missings, but leave everything else alone
    hair_color = case_match(hair_color, NA ~ "unknown", .default = hair_color),
    # Replace some, but not all, of the species
    species = case_match(
      species,
      "Human" ~ "Humanoid",
      "Droid" ~ "Robot",
      c("Wookiee", "Ewok") ~ "Hairy",
      .default = species
    ),
    .keep = "used"
  )
\end{ExampleCode}
\end{Examples}
\HeaderA{case\_when}{A general vectorised if-else}{case.Rul.when}
%
\begin{Description}
This function allows you to vectorise multiple \code{\LinkA{if\_else()}{if.Rul.else}} statements. Each
case is evaluated sequentially and the first match for each element
determines the corresponding value in the output vector. If no cases match,
the \code{.default} is used as a final "else" statment.

\code{case\_when()} is an R equivalent of the SQL "searched" \AsIs{\texttt{CASE WHEN}} statement.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
case_when(..., .default = NULL, .ptype = NULL, .size = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] <\code{\LinkA{dynamic-dots}{dynamic.Rdash.dots}}> A sequence of two-sided
formulas. The left hand side (LHS) determines which values match this case.
The right hand side (RHS) provides the replacement value.

The LHS inputs must evaluate to logical vectors.

The RHS inputs will be coerced to their common type.

All inputs will be recycled to their common size. That said, we encourage
all LHS inputs to be the same size. Recycling is mainly useful for RHS
inputs, where you might supply a size 1 input that will be recycled to the
size of the LHS inputs.

\code{NULL} inputs are ignored.

\item[\code{.default}] The value used when all of the LHS inputs return either
\code{FALSE} or \code{NA}.

\code{.default} must be size 1 or the same size as the common size computed
from \code{...}.

\code{.default} participates in the computation of the common type with the RHS
inputs.

\code{NA} values in the LHS conditions are treated like \code{FALSE}, meaning that
the result at those locations will be assigned the \code{.default} value. To
handle missing values in the conditions differently, you must explicitly
catch them with another condition before they fall through to the
\code{.default}. This typically involves some variation of \code{is.na(x) \textasciitilde{} value}
tailored to your usage of \code{case\_when()}.

If \code{NULL}, the default, a missing value will be used.

\item[\code{.ptype}] An optional prototype declaring the desired output type. If
supplied, this overrides the common type of the RHS inputs.

\item[\code{.size}] An optional size declaring the desired output size. If supplied,
this overrides the common size computed from \code{...}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector with the same size as the common size computed from the
inputs in \code{...} and the same type as the common type of the RHS inputs
in \code{...}.
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{case\_match()}{case.Rul.match}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x <- 1:70
case_when(
  x %% 35 == 0 ~ "fizz buzz",
  x %% 5 == 0 ~ "fizz",
  x %% 7 == 0 ~ "buzz",
  .default = as.character(x)
)

# Like an if statement, the arguments are evaluated in order, so you must
# proceed from the most specific to the most general. This won't work:
case_when(
  x %%  5 == 0 ~ "fizz",
  x %%  7 == 0 ~ "buzz",
  x %% 35 == 0 ~ "fizz buzz",
  .default = as.character(x)
)

# If none of the cases match and no `.default` is supplied, NA is used:
case_when(
  x %% 35 == 0 ~ "fizz buzz",
  x %% 5 == 0 ~ "fizz",
  x %% 7 == 0 ~ "buzz",
)

# Note that `NA` values on the LHS are treated like `FALSE` and will be
# assigned the `.default` value. You must handle them explicitly if you
# want to use a different value. The exact way to handle missing values is
# dependent on the set of LHS conditions you use.
x[2:4] <- NA_real_
case_when(
  x %% 35 == 0 ~ "fizz buzz",
  x %% 5 == 0 ~ "fizz",
  x %% 7 == 0 ~ "buzz",
  is.na(x) ~ "nope",
  .default = as.character(x)
)

# `case_when()` evaluates all RHS expressions, and then constructs its
# result by extracting the selected (via the LHS expressions) parts.
# In particular `NaN`s are produced in this case:
y <- seq(-2, 2, by = .5)
case_when(
  y >= 0 ~ sqrt(y),
  .default = y
)

# `case_when()` is particularly useful inside `mutate()` when you want to
# create a new variable that relies on a complex combination of existing
# variables
starwars %>%
  select(name:mass, gender, species) %>%
  mutate(
    type = case_when(
      height > 200 | mass > 200 ~ "large",
      species == "Droid" ~ "robot",
      .default = "other"
    )
  )


# `case_when()` is not a tidy eval function. If you'd like to reuse
# the same patterns, extract the `case_when()` call in a normal
# function:
case_character_type <- function(height, mass, species) {
  case_when(
    height > 200 | mass > 200 ~ "large",
    species == "Droid" ~ "robot",
    .default = "other"
  )
}

case_character_type(150, 250, "Droid")
case_character_type(150, 150, "Droid")

# Such functions can be used inside `mutate()` as well:
starwars %>%
  mutate(type = case_character_type(height, mass, species)) %>%
  pull(type)

# `case_when()` ignores `NULL` inputs. This is useful when you'd
# like to use a pattern only under certain conditions. Here we'll
# take advantage of the fact that `if` returns `NULL` when there is
# no `else` clause:
case_character_type <- function(height, mass, species, robots = TRUE) {
  case_when(
    height > 200 | mass > 200 ~ "large",
    if (robots) species == "Droid" ~ "robot",
    .default = "other"
  )
}

starwars %>%
  mutate(type = case_character_type(height, mass, species, robots = FALSE)) %>%
  pull(type)
\end{ExampleCode}
\end{Examples}
\HeaderA{check\_dbplyr}{dbplyr compatibility functions}{check.Rul.dbplyr}
\aliasA{wrap\_dbplyr\_obj}{check\_dbplyr}{wrap.Rul.dbplyr.Rul.obj}
\keyword{internal}{check\_dbplyr}
%
\begin{Description}
In dplyr 0.7.0, a number of database and SQL functions moved from dplyr to
dbplyr. The generic functions stayed in dplyr (since there is no easy way
to conditionally import a generic from different packages), but many other
SQL and database helper functions moved. If you have written a backend,
these functions generate the code you need to work with both dplyr 0.5.0
dplyr 0.7.0.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
check_dbplyr()

wrap_dbplyr_obj(obj_name)
\end{verbatim}
\end{Usage}
%
\begin{Examples}
\begin{ExampleCode}

wrap_dbplyr_obj("build_sql")
wrap_dbplyr_obj("base_agg")

\end{ExampleCode}
\end{Examples}
\HeaderA{coalesce}{Find the first non-missing element}{coalesce}
%
\begin{Description}
Given a set of vectors, \code{coalesce()} finds the first non-missing value at
each position. It's inspired by the SQL \code{COALESCE} function which does the
same thing for SQL \code{NULL}s.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
coalesce(..., .ptype = NULL, .size = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] <\code{\LinkA{dynamic-dots}{dynamic.Rdash.dots}}>

One or more vectors. These will be
\LinkA{recycled}{recycled} against each other, and will be
cast to their common type.

\item[\code{.ptype}] An optional prototype declaring the desired output type. If
supplied, this overrides the common type of the vectors in \code{...}.

\item[\code{.size}] An optional size declaring the desired output size. If supplied,
this overrides the common size of the vectors in \code{...}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector with the same type and size as the common type and common
size of the vectors in \code{...}.
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{na\_if()}{na.Rul.if}} to replace specified values with an \code{NA}.
\code{\LinkA{tidyr::replace\_na()}{tidyr::replace.Rul.na()}} to replace \code{NA} with a value.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Use a single value to replace all missing values
x <- sample(c(1:5, NA, NA, NA))
coalesce(x, 0L)

# The equivalent to a missing value in a list is `NULL`
coalesce(list(1, 2, NULL), list(NA))

# Or generate a complete vector from partially missing pieces
y <- c(1, 2, NA, NA, 5)
z <- c(NA, NA, 3, 4, 5)
coalesce(y, z)

# Supply lists by splicing them into dots:
vecs <- list(
  c(1, 2, NA, NA, 5),
  c(NA, NA, 3, 4, 5)
)
coalesce(!!!vecs)
\end{ExampleCode}
\end{Examples}
\HeaderA{combine}{Combine vectors}{combine}
\keyword{internal}{combine}
%
\begin{Description}
\strong{[Deprecated]}

\code{combine()} is deprecated in favour of \code{\LinkA{vctrs::vec\_c()}{vctrs::vec.Rul.c()}}. \code{combine()}
attempted to automatically guess whether you wanted \code{\LinkA{c()}{c}} or \code{\LinkA{unlist()}{unlist}},
but could fail in surprising ways. We now believe it's better to be explicit.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
combine(...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] Vectors to combine.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
f1 <- factor("a")
f2 <- factor("b")

combine(f1, f2)
# ->
vctrs::vec_c(f1, f1)

combine(list(f1, f2))
# ->
vctrs::vec_c(!!!list(f1, f2))
\end{ExampleCode}
\end{Examples}
\HeaderA{common\_by}{Extract out common by variables}{common.Rul.by}
\keyword{internal}{common\_by}
%
\begin{Description}
Extract out common by variables
\end{Description}
%
\begin{Usage}
\begin{verbatim}
common_by(by = NULL, x, y)
\end{verbatim}
\end{Usage}
\HeaderA{compute}{Force computation of a database query}{compute}
\aliasA{collapse}{compute}{collapse}
\aliasA{collect}{compute}{collect}
%
\begin{Description}
\code{compute()} stores results in a remote temporary table.
\code{collect()} retrieves data into a local tibble.
\code{collapse()} is slightly different: it doesn't force computation, but
instead forces generation of the SQL query. This is sometimes needed to work
around bugs in dplyr's SQL generation.

All functions preserve grouping and ordering.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
compute(x, ...)

collect(x, ...)

collapse(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A data frame, data frame extension (e.g. a tibble), or a lazy
data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for more
details.

\item[\code{...}] Arguments passed on to methods
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Methods}

These functions are \strong{generics}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
\begin{itemize}

\item{} \code{compute()}: no methods found
\item{} \code{collect()}: no methods found
\item{} \code{collapse()}: no methods found

\end{itemize}

\end{Section}
%
\begin{SeeAlso}
\code{\LinkA{copy\_to()}{copy.Rul.to}}, the opposite of \code{collect()}: it takes a local data
frame and uploads it to the remote source.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

mtcars2 <- dbplyr::src_memdb() %>%
  copy_to(mtcars, name = "mtcars2-cc", overwrite = TRUE)

remote <- mtcars2 %>%
  filter(cyl == 8) %>%
  select(mpg:drat)

# Compute query and save in remote table
compute(remote)

# Compute query bring back to this session
collect(remote)

# Creates a fresh query based on the generated SQL
collapse(remote)

\end{ExampleCode}
\end{Examples}
\HeaderA{consecutive\_id}{Generate a unique identifier for consecutive combinations}{consecutive.Rul.id}
%
\begin{Description}
\code{consecutive\_id()} generates a unique identifier that increments every time
a variable (or combination of variables) changes. Inspired by
\code{data.table::rleid()}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
consecutive_id(...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] Unnamed vectors. If multiple vectors are supplied, then they should
have the same length.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A numeric vector the same length as the longest
element of \code{...}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
consecutive_id(c(TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, NA, NA))
consecutive_id(c(1, 1, 1, 2, 1, 1, 2, 2))

df <- data.frame(x = c(0, 0, 1, 0), y = c(2, 2, 2, 2))
df %>% group_by(x, y) %>% summarise(n = n())
df %>% group_by(id = consecutive_id(x, y), x, y) %>% summarise(n = n())
\end{ExampleCode}
\end{Examples}
\HeaderA{context}{Information about the "current" group or variable}{context}
\aliasA{cur\_column}{context}{cur.Rul.column}
\aliasA{cur\_group}{context}{cur.Rul.group}
\aliasA{cur\_group\_id}{context}{cur.Rul.group.Rul.id}
\aliasA{cur\_group\_rows}{context}{cur.Rul.group.Rul.rows}
\aliasA{n}{context}{n}
%
\begin{Description}
These functions return information about the "current" group or "current"
variable, so only work inside specific contexts like \code{\LinkA{summarise()}{summarise}} and
\code{\LinkA{mutate()}{mutate}}.
\begin{itemize}

\item{} \code{n()} gives the current group size.
\item{} \code{cur\_group()} gives the group keys, a tibble with one row and one column
for each grouping variable.
\item{} \code{cur\_group\_id()} gives a unique numeric identifier for the current group.
\item{} \code{cur\_group\_rows()} gives the row indices for the current group.
\item{} \code{cur\_column()} gives the name of the current column (in \code{\LinkA{across()}{across}} only).

\end{itemize}


See \code{\LinkA{group\_data()}{group.Rul.data}} for equivalent functions that return values for all
groups.

See \code{\LinkA{pick()}{pick}} for a way to select a subset of columns using tidyselect syntax
while inside \code{summarise()} or \code{mutate()}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
n()

cur_group()

cur_group_id()

cur_group_rows()

cur_column()
\end{verbatim}
\end{Usage}
%
\begin{Section}{data.table}

If you're familiar with data.table:
\begin{itemize}

\item{} \code{cur\_group\_id()} <-> \code{.GRP}
\item{} \code{cur\_group()} <-> \code{.BY}
\item{} \code{cur\_group\_rows()} <-> \code{.I}

\end{itemize}


See \code{\LinkA{pick()}{pick}} for an equivalent to \code{.SD}.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(
  g = sample(rep(letters[1:3], 1:3)),
  x = runif(6),
  y = runif(6)
)
gf <- df %>% group_by(g)

gf %>% summarise(n = n())

gf %>% mutate(id = cur_group_id())
gf %>% reframe(row = cur_group_rows())
gf %>% summarise(data = list(cur_group()))

gf %>% mutate(across(everything(), ~ paste(cur_column(), round(.x, 2))))
\end{ExampleCode}
\end{Examples}
\HeaderA{copy\_to}{Copy a local data frame to a remote src}{copy.Rul.to}
%
\begin{Description}
This function uploads a local data frame into a remote data source, creating
the table definition as needed. Wherever possible, the new object will be
temporary, limited to the current connection to the source.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
copy_to(dest, df, name = deparse(substitute(df)), overwrite = FALSE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dest}] remote data source

\item[\code{df}] local data frame

\item[\code{name}] name for new remote table.

\item[\code{overwrite}] If \code{TRUE}, will overwrite an existing table with
name \code{name}. If \code{FALSE}, will throw an error if \code{name} already
exists.

\item[\code{...}] other parameters passed to methods.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a \code{tbl} object in the remote source
\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
\code{\LinkA{collect()}{collect}} for the opposite action; downloading remote data into
a local dbl.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
iris2 <- dbplyr::src_memdb() %>% copy_to(iris, overwrite = TRUE)
iris2

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{count}{Count the observations in each group}{count}
\aliasA{add\_count}{count}{add.Rul.count}
\aliasA{add\_tally}{count}{add.Rul.tally}
\methaliasA{count.data.frame}{count}{count.data.frame}
\aliasA{tally}{count}{tally}
%
\begin{Description}
\code{count()} lets you quickly count the unique values of one or more variables:
\code{df \%>\% count(a, b)} is roughly equivalent to
\code{df \%>\% group\_by(a, b) \%>\% summarise(n = n())}.
\code{count()} is paired with \code{tally()}, a lower-level helper that is equivalent
to \code{df \%>\% summarise(n = n())}. Supply \code{wt} to perform weighted counts,
switching the summary from \code{n = n()} to \code{n = sum(wt)}.

\code{add\_count()} and \code{add\_tally()} are equivalents to \code{count()} and \code{tally()}
but use \code{mutate()} instead of \code{summarise()} so that they add a new column
with group-wise counts.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
count(x, ..., wt = NULL, sort = FALSE, name = NULL)

## S3 method for class 'data.frame'
count(
  x,
  ...,
  wt = NULL,
  sort = FALSE,
  name = NULL,
  .drop = group_by_drop_default(x)
)

tally(x, wt = NULL, sort = FALSE, name = NULL)

add_count(x, ..., wt = NULL, sort = FALSE, name = NULL, .drop = deprecated())

add_tally(x, wt = NULL, sort = FALSE, name = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr).

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Variables to group
by.

\item[\code{wt}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Frequency weights.
Can be \code{NULL} or a variable:
\begin{itemize}

\item{} If \code{NULL} (the default), counts the number of rows in each group.
\item{} If a variable, computes \code{sum(wt)} for each group.

\end{itemize}


\item[\code{sort}] If \code{TRUE}, will show the largest groups at the top.

\item[\code{name}] The name of the new column in the output.

If omitted, it will default to \code{n}. If there's already a column called \code{n},
it will use \code{nn}. If there's a column called \code{n} and \code{nn}, it'll use
\code{nnn}, and so on, adding \code{n}s until it gets a new name.

\item[\code{.drop}] Handling of factor levels that don't appear in the data, passed
on to \code{\LinkA{group\_by()}{group.Rul.by}}.

For \code{count()}: if \code{FALSE} will include counts for empty groups (i.e. for
levels of factors that don't exist in the data).

\strong{[Deprecated]} For \code{add\_count()}: deprecated since it
can't actually affect the output.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{.data}. \code{count()} and \code{add\_count()}
group transiently, so the output has the same groups as the input.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
# count() is a convenient way to get a sense of the distribution of
# values in a dataset
starwars %>% count(species)
starwars %>% count(species, sort = TRUE)
starwars %>% count(sex, gender, sort = TRUE)
starwars %>% count(birth_decade = round(birth_year, -1))

# use the `wt` argument to perform a weighted count. This is useful
# when the data has already been aggregated once
df <- tribble(
  ~name,    ~gender,   ~runs,
  "Max",    "male",       10,
  "Sandra", "female",      1,
  "Susan",  "female",      4
)
# counts rows:
df %>% count(gender)
# counts runs:
df %>% count(gender, wt = runs)

# When factors are involved, `.drop = FALSE` can be used to retain factor
# levels that don't appear in the data
df2 <- tibble(
  id = 1:5,
  type = factor(c("a", "c", "a", NA, "a"), levels = c("a", "b", "c"))
)
df2 %>% count(type)
df2 %>% count(type, .drop = FALSE)

# Or, using `group_by()`:
df2 %>% group_by(type, .drop = FALSE) %>% count()

# tally() is a lower-level function that assumes you've done the grouping
starwars %>% tally()
starwars %>% group_by(species) %>% tally()

# both count() and tally() have add_ variants that work like
# mutate() instead of summarise
df %>% add_count(gender, wt = runs)
df %>% add_tally(wt = runs)
\end{ExampleCode}
\end{Examples}
\HeaderA{cross\_join}{Cross join}{cross.Rul.join}
\keyword{joins}{cross\_join}
%
\begin{Description}
Cross joins match each row in \code{x} to every row in \code{y}, resulting in a data
frame with \code{nrow(x) * nrow(y)} rows.

Since cross joins result in all possible matches between \code{x} and \code{y}, they
technically serve as the basis for all \LinkA{mutating joins}{mutate.Rdash.joins}, which
can generally be thought of as cross joins followed by a filter. In practice,
a more specialized procedure is used for better performance.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
cross_join(x, y, ..., copy = FALSE, suffix = c(".x", ".y"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] A pair of data frames, data frame extensions (e.g. a tibble), or
lazy data frames (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] Other parameters passed onto methods.

\item[\code{copy}] If \code{x} and \code{y} are not from the same data source,
and \code{copy} is \code{TRUE}, then \code{y} will be copied into the
same src as \code{x}.  This allows you to join tables across srcs, but
it is a potentially expensive operation so you must opt into it.

\item[\code{suffix}] If there are non-joined duplicate variables in \code{x} and
\code{y}, these suffixes will be added to the output to disambiguate them.
Should be a character vector of length 2.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{x} (including the same groups). The output has
the following properties:
\begin{itemize}

\item{} There are \code{nrow(x) * nrow(y)} rows returned.
\item{} Output columns include all columns from both \code{x} and \code{y}. Column name
collisions are resolved using \code{suffix}.
\item{} The order of the rows and columns of \code{x} is preserved as much as possible.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other joins: 
\code{\LinkA{filter-joins}{filter.Rdash.joins}},
\code{\LinkA{mutate-joins}{mutate.Rdash.joins}},
\code{\LinkA{nest\_join}{nest.Rul.join}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Cross joins match each row in `x` to every row in `y`.
# Data within the columns is not used in the matching process.
cross_join(band_instruments, band_members)

# Control the suffix added to variables duplicated in
# `x` and `y` with `suffix`.
cross_join(band_instruments, band_members, suffix = c("", "_y"))
\end{ExampleCode}
\end{Examples}
\HeaderA{cumall}{Cumulativate versions of any, all, and mean}{cumall}
\aliasA{cumany}{cumall}{cumany}
\aliasA{cummean}{cumall}{cummean}
%
\begin{Description}
dplyr provides \code{cumall()}, \code{cumany()}, and \code{cummean()} to complete R's set
of cumulative functions.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
cumall(x)

cumany(x)

cummean(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] For \code{cumall()} and \code{cumany()}, a logical vector; for
\code{cummean()} an integer or numeric vector.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector the same length as \code{x}.
\end{Value}
%
\begin{Section}{Cumulative logical functions}


These are particularly useful in conjunction with \code{filter()}:
\begin{itemize}

\item{} \code{cumall(x)}: all cases until the first \code{FALSE}.
\item{} \code{cumall(!x)}: all cases until the first \code{TRUE}.
\item{} \code{cumany(x)}: all cases after the first \code{TRUE}.
\item{} \code{cumany(!x)}: all cases after the first \code{FALSE}.

\end{itemize}

\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
# `cummean()` returns a numeric/integer vector of the same length
# as the input vector.
x <- c(1, 3, 5, 2, 2)
cummean(x)
cumsum(x) / seq_along(x)

# `cumall()` and `cumany()` return logicals
cumall(x < 5)
cumany(x == 3)

# `cumall()` vs. `cumany()`
df <- data.frame(
  date = as.Date("2020-01-01") + 0:6,
  balance = c(100, 50, 25, -25, -50, 30, 120)
)
# all rows after first overdraft
df %>% filter(cumany(balance < 0))
# all rows until first overdraft
df %>% filter(cumall(!(balance < 0)))

\end{ExampleCode}
\end{Examples}
\HeaderA{c\_across}{Combine values from multiple columns}{c.Rul.across}
%
\begin{Description}
\code{c\_across()} is designed to work with \code{\LinkA{rowwise()}{rowwise}} to make it easy to
perform row-wise aggregations. It has two differences from \code{c()}:
\begin{itemize}

\item{} It uses tidy select semantics so you can easily select multiple variables.
See \code{vignette("rowwise")} for more details.
\item{} It uses \code{\LinkA{vctrs::vec\_c()}{vctrs::vec.Rul.c()}} in order to give safer outputs.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
c_across(cols)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{cols}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Columns to transform.
You can't select grouping columns because they are already automatically
handled by the verb (i.e. \code{\LinkA{summarise()}{summarise}} or \code{\LinkA{mutate()}{mutate}}).
\end{ldescription}
\end{Arguments}
%
\begin{SeeAlso}
\code{\LinkA{across()}{across}} for a function that returns a tibble.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(id = 1:4, w = runif(4), x = runif(4), y = runif(4), z = runif(4))
df %>%
  rowwise() %>%
  mutate(
    sum = sum(c_across(w:z)),
    sd = sd(c_across(w:z))
  )
\end{ExampleCode}
\end{Examples}
\HeaderA{defunct}{Defunct functions}{defunct}
\aliasA{bench\_tbls}{defunct}{bench.Rul.tbls}
\aliasA{changes}{defunct}{changes}
\aliasA{compare\_tbls}{defunct}{compare.Rul.tbls}
\aliasA{compare\_tbls2}{defunct}{compare.Rul.tbls2}
\aliasA{current\_vars}{defunct}{current.Rul.vars}
\aliasA{eval\_tbls}{defunct}{eval.Rul.tbls}
\aliasA{eval\_tbls2}{defunct}{eval.Rul.tbls2}
\aliasA{failwith}{defunct}{failwith}
\aliasA{id}{defunct}{id}
\aliasA{location}{defunct}{location}
\aliasA{rename\_vars}{defunct}{rename.Rul.vars}
\aliasA{select\_var}{defunct}{select.Rul.var}
\aliasA{select\_vars}{defunct}{select.Rul.vars}
\keyword{internal}{defunct}
%
\begin{Description}
\strong{[Defunct]}

These functions were deprecated for at least two years before being
made defunct. If there's a known replacement, calling the function
will tell you about it.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
# Deprecated in 0.5.0 -------------------------------------

id(.variables, drop = FALSE)

# Deprecated in 0.7.0 -------------------------------------

failwith(default = NULL, f, quiet = FALSE)

# Deprecated in 0.8.* -------------------------------------

select_vars(vars = chr(), ..., include = chr(), exclude = chr())

rename_vars(vars = chr(), ..., strict = TRUE)

select_var(vars, var = -1)

current_vars(...)

# Deprecated in 1.0.0 -------------------------------------

bench_tbls(tbls, op, ..., times = 10)

compare_tbls(tbls, op, ref = NULL, compare = equal_data_frame, ...)

compare_tbls2(tbls_x, tbls_y, op, ref = NULL, compare = equal_data_frame, ...)

eval_tbls(tbls, op)

eval_tbls2(tbls_x, tbls_y, op)

location(df)

changes(x, y)
\end{verbatim}
\end{Usage}
\HeaderA{deprec-context}{Information about the "current" group or variable}{deprec.Rdash.context}
\aliasA{cur\_data}{deprec-context}{cur.Rul.data}
\aliasA{cur\_data\_all}{deprec-context}{cur.Rul.data.Rul.all}
\keyword{internal}{deprec-context}
%
\begin{Description}
\strong{[Deprecated]}

These functions were deprecated in dplyr 1.1.0.
\begin{itemize}

\item{} \code{cur\_data()} is deprecated in favor of \code{\LinkA{pick()}{pick}}.
\item{} \code{cur\_data\_all()} is deprecated but does not have a direct replacement as
selecting the grouping variables is not well-defined and is unlikely to
ever be useful.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
cur_data()

cur_data_all()
\end{verbatim}
\end{Usage}
\HeaderA{desc}{Descending order}{desc}
%
\begin{Description}
Transform a vector into a format that will be sorted in descending order.
This is useful within \code{\LinkA{arrange()}{arrange}}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
desc(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] vector to transform
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
desc(1:10)
desc(factor(letters))

first_day <- seq(as.Date("1910/1/1"), as.Date("1920/1/1"), "years")
desc(first_day)

starwars %>% arrange(desc(mass))
\end{ExampleCode}
\end{Examples}
\HeaderA{dim\_desc}{Describing dimensions}{dim.Rul.desc}
\keyword{internal}{dim\_desc}
%
\begin{Description}
Prints the dimensions of an array-like object in a user-friendly manner,
substituting \code{NA} with ?? (for SQL queries).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
dim_desc(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Object to show dimensions for.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
dim_desc(mtcars)
\end{ExampleCode}
\end{Examples}
\HeaderA{distinct}{Keep distinct/unique rows}{distinct}
%
\begin{Description}
Keep only unique/distinct rows from a data frame. This is similar
to \code{\LinkA{unique.data.frame()}{unique.data.frame}} but considerably faster.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
distinct(.data, ..., .keep_all = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Optional variables to
use when determining uniqueness. If there are multiple rows for a given
combination of inputs, only the first row will be preserved. If omitted,
will use all variables in the data frame.

\item[\code{.keep\_all}] If \code{TRUE}, keep all variables in \code{.data}.
If a combination of \code{...} is not distinct, this keeps the
first row of values.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} Rows are a subset of the input but appear in the same order.
\item{} Columns are not modified if \code{...} is empty or \code{.keep\_all} is \code{TRUE}.
Otherwise, \code{distinct()} first calls \code{mutate()} to create new columns.
\item{} Groups are not modified.
\item{} Data frame attributes are preserved.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(
  x = sample(10, 100, rep = TRUE),
  y = sample(10, 100, rep = TRUE)
)
nrow(df)
nrow(distinct(df))
nrow(distinct(df, x, y))

distinct(df, x)
distinct(df, y)

# You can choose to keep all other variables as well
distinct(df, x, .keep_all = TRUE)
distinct(df, y, .keep_all = TRUE)

# You can also use distinct on computed variables
distinct(df, diff = abs(x - y))

# Use `pick()` to select columns with tidy-select
distinct(starwars, pick(contains("color")))

# Grouping -------------------------------------------------

df <- tibble(
  g = c(1, 1, 2, 2, 2),
  x = c(1, 1, 2, 1, 2),
  y = c(3, 2, 1, 3, 1)
)
df <- df %>% group_by(g)

# With grouped data frames, distinctness is computed within each group
df %>% distinct(x)

# When `...` are omitted, `distinct()` still computes distinctness using
# all variables in the data frame
df %>% distinct()
\end{ExampleCode}
\end{Examples}
\HeaderA{distinct\_all}{Select distinct rows by a selection of variables}{distinct.Rul.all}
\aliasA{distinct\_at}{distinct\_all}{distinct.Rul.at}
\aliasA{distinct\_if}{distinct\_all}{distinct.Rul.if}
\keyword{internal}{distinct\_all}
%
\begin{Description}
\strong{[Superseded]}

Scoped verbs (\AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}}, \AsIs{\texttt{\_all}}) have been superseded by the use of
\code{\LinkA{pick()}{pick}} or \code{\LinkA{across()}{across}} in an existing verb. See \code{vignette("colwise")} for
details.

These \LinkA{scoped}{scoped} variants of \code{\LinkA{distinct()}{distinct}} extract distinct rows by a
selection of variables. Like \code{distinct()}, you can modify the
variables before ordering with the \code{.funs} argument.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
distinct_all(.tbl, .funs = list(), ..., .keep_all = FALSE)

distinct_at(.tbl, .vars, .funs = list(), ..., .keep_all = FALSE)

distinct_if(.tbl, .predicate, .funs = list(), ..., .keep_all = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.funs}] A function \code{fun}, a quosure style lambda \code{\textasciitilde{} fun(.)} or a list of either form.

\item[\code{...}] Additional arguments for the function calls in
\code{.funs}. These are evaluated only once, with \LinkA{tidy dots}{tidy dots} support.

\item[\code{.keep\_all}] If \code{TRUE}, keep all variables in \code{.data}.
If a combination of \code{...} is not distinct, this keeps the
first row of values.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Grouping variables}


The grouping variables that are part of the selection are taken
into account to determine distinct rows.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(x = rep(2:5, each = 2) / 2, y = rep(2:3, each = 4) / 2)

distinct_all(df)
# ->
distinct(df, pick(everything()))

distinct_at(df, vars(x,y))
# ->
distinct(df, pick(x, y))

distinct_if(df, is.numeric)
# ->
distinct(df, pick(where(is.numeric)))

# You can supply a function that will be applied before extracting the distinct values
# The variables of the sorted tibble keep their original values.
distinct_all(df, round)
# ->
distinct(df, across(everything(), round))
\end{ExampleCode}
\end{Examples}
\HeaderA{distinct\_prepare}{Same basic philosophy as group\_by\_prepare(): lazy\_dots comes in, list of data and vars (character vector) comes out.}{distinct.Rul.prepare}
\aliasA{group\_by\_prepare}{distinct\_prepare}{group.Rul.by.Rul.prepare}
\keyword{internal}{distinct\_prepare}
%
\begin{Description}
\AsIs{\texttt{*\_prepare()}} performs standard manipulation that is needed prior
to actual data processing. They are only be needed by packages
that implement dplyr backends.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
distinct_prepare(
  .data,
  vars,
  group_vars = character(),
  .keep_all = FALSE,
  caller_env = caller_env(2),
  error_call = caller_env()
)

group_by_prepare(
  .data,
  ...,
  .add = FALSE,
  .dots = deprecated(),
  add = deprecated(),
  error_call = caller_env()
)
\end{verbatim}
\end{Usage}
%
\begin{Value}
A list
\begin{ldescription}
\item[\code{data}] Modified tbl
\item[\code{groups}] Modified groups
\end{ldescription}
\end{Value}
\HeaderA{do}{Do anything}{do}
\keyword{internal}{do}
%
\begin{Description}
\strong{[Superseded]}

\code{do()} is superseded as of dplyr 1.0.0, because its syntax never really
felt like it belonged with the rest of dplyr. It's replaced by a combination
of \code{\LinkA{reframe()}{reframe}} (which can produce multiple rows and multiple columns),
\code{\LinkA{nest\_by()}{nest.Rul.by}} (which creates a \LinkA{rowwise}{rowwise} tibble of nested data),
and \code{\LinkA{pick()}{pick}} (which allows you to access the data for the "current" group).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
do(.data, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] a tbl

\item[\code{...}] Expressions to apply to each group. If named, results will be
stored in a new column. If unnamed, must return a data frame. You can
use \code{.} to refer to the current group. You can not mix named and
unnamed arguments.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# do() with unnamed arguments becomes reframe() or summarise()
# . becomes pick()
by_cyl <- mtcars %>% group_by(cyl)
by_cyl %>% do(head(., 2))
# ->
by_cyl %>% reframe(head(pick(everything()), 2))
by_cyl %>% slice_head(n = 2)

# Can refer to variables directly
by_cyl %>% do(mean = mean(.$vs))
# ->
by_cyl %>% summarise(mean = mean(vs))

# do() with named arguments becomes nest_by() + mutate() & list()
models <- by_cyl %>% do(mod = lm(mpg ~ disp, data = .))
# ->
models <- mtcars %>%
  nest_by(cyl) %>%
  mutate(mod = list(lm(mpg ~ disp, data = data)))
models %>% summarise(rsq = summary(mod)$r.squared)

# use broom to turn models into data
models %>% do(data.frame(
  var = names(coef(.$mod)),
  coef(summary(.$mod)))
)

# ->
models %>% reframe(broom::tidy(mod))

\end{ExampleCode}
\end{Examples}
\HeaderA{dplyr-locale}{Locale used by \code{arrange()}}{dplyr.Rdash.locale}
\keyword{internal}{dplyr-locale}
%
\begin{Description}
This page documents details about the locale used by \code{\LinkA{arrange()}{arrange}} when
ordering character vectors.
%
\begin{SubSection}{Default locale}

The default locale used by \code{arrange()} is the C locale. This is used when
\code{.locale = NULL} unless the \code{dplyr.legacy\_locale} global option is set to
\code{TRUE}. You can also force the C locale to be used unconditionally with
\code{.locale = "C"}.

The C locale is not exactly the same as English locales, such as \code{"en"}. The
main difference is that the C locale groups the English alphabet by \emph{case},
while most English locales group the alphabet by \emph{letter}. For example,
\code{c("a", "b", "C", "B", "c")} will sort as \code{c("B", "C", "a", "b", "c")} in the
C locale, with all uppercase letters coming before lowercase letters, but
will sort as \code{c("a", "b", "B", "c", "C")} in an English locale. This often
makes little practical difference during data analysis, because both return
identical results when case is consistent between observations.
\end{SubSection}


%
\begin{SubSection}{Reproducibility}

The C locale has the benefit of being completely reproducible across all
supported R versions and operating systems with no extra effort.

If you set \code{.locale} to an option from \code{\LinkA{stringi::stri\_locale\_list()}{stringi::stri.Rul.locale.Rul.list()}}, then
stringi must be installed by anyone who wants to run your code. If you
utilize this in a package, then stringi should be placed in \code{Imports}.
\end{SubSection}


%
\begin{SubSection}{Legacy behavior}

Prior to dplyr 1.1.0, character columns were ordered in the system locale. If
you need to temporarily revert to this behavior, you can set the global
option \code{dplyr.legacy\_locale} to \code{TRUE}, but this should be used sparingly and
you should expect this option to be removed in a future version of dplyr. It
is better to update existing code to explicitly use \code{.locale} instead. Note
that setting \code{dplyr.legacy\_locale} will also force calls to \code{\LinkA{group\_by()}{group.Rul.by}} to
use the system locale when internally ordering the groups.

Setting \code{.locale} will override any usage of \code{dplyr.legacy\_locale}.
\end{SubSection}

\end{Description}
%
\begin{Examples}
\begin{ExampleCode}

df <- tibble(x = c("a", "b", "C", "B", "c"))
df

# Default locale is C, which groups the English alphabet by case, placing
# uppercase letters before lowercase letters.
arrange(df, x)

# The American English locale groups the alphabet by letter.
# Explicitly override `.locale` with `"en"` for this ordering.
arrange(df, x, .locale = "en")

# This Danish letter is expected to sort after `z`
df <- tibble(x = c("o", "p", "\u00F8", "z"))
df

# The American English locale sorts it right after `o`
arrange(df, x, .locale = "en")

# Using `"da"` for Danish ordering gives the expected result
arrange(df, x, .locale = "da")

# If you need the legacy behavior of `arrange()`, which respected the
# system locale, then you can set the global option `dplyr.legacy_locale`,
# but expect this to be removed in the future. We recommend that you use
# the `.locale` argument instead.
rlang::with_options(dplyr.legacy_locale = TRUE, {
  arrange(df, x)
})

\end{ExampleCode}
\end{Examples}
\HeaderA{dplyr\_by}{Per-operation grouping with \code{.by}/\code{by}}{dplyr.Rul.by}
%
\begin{Description}
There are two ways to group in dplyr:
\begin{itemize}

\item{} Persistent grouping with \code{\LinkA{group\_by()}{group.Rul.by}}
\item{} Per-operation grouping with \code{.by}/\code{by}

\end{itemize}


This help page is dedicated to explaining where and why you might want to use the latter.

Depending on the dplyr verb, the per-operation grouping argument may be named \code{.by} or \code{by}.
The \emph{Supported verbs} section below outlines this on a case-by-case basis.
The remainder of this page will refer to \code{.by} for simplicity.

Grouping radically affects the computation of the dplyr verb you use it with, and one of the goals of \code{.by} is to allow you to place that grouping specification alongside the code that actually uses it.
As an added benefit, with \code{.by} you no longer need to remember to \code{\LinkA{ungroup()}{ungroup}} after \code{\LinkA{summarise()}{summarise}}, and \code{summarise()} won't ever message you about how it's handling the groups!

This idea comes from \Rhref{https://CRAN.R-project.org/package=data.table}{data.table}, which allows you to specify \code{by} alongside modifications in \code{j}, like: \code{dt[, .(x = mean(x)), by = g]}.
%
\begin{SubSection}{Supported verbs}
\begin{itemize}

\item{} \code{\LinkA{mutate(.by = )}{mutate}}
\item{} \code{\LinkA{summarise(.by = )}{summarise}}
\item{} \code{\LinkA{reframe(.by = )}{reframe}}
\item{} \code{\LinkA{filter(.by = )}{filter}}
\item{} \code{\LinkA{slice(.by = )}{slice}}
\item{} \code{\LinkA{slice\_head(by = )}{slice.Rul.head}} and \code{\LinkA{slice\_tail(by = )}{slice.Rul.tail}}
\item{} \code{\LinkA{slice\_min(by = )}{slice.Rul.min}} and \code{\LinkA{slice\_max(by = )}{slice.Rul.max}}
\item{} \code{\LinkA{slice\_sample(by = )}{slice.Rul.sample}}

\end{itemize}


Note that some dplyr verbs use \code{by} while others use \code{.by}.
This is a purely technical difference.
\end{SubSection}


%
\begin{SubSection}{Differences between \code{.by} and \code{group\_by()}}

\Tabular{ll}{
\code{.by} & \code{group\_by()} \\{}
Grouping only affects a single verb & Grouping is persistent across multiple verbs \\{}
Selects variables with \LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select} & Computes expressions with \LinkA{data-masking}{data.Rdash.masking} \\{}
Summaries use existing order of group keys & Summaries sort group keys in ascending order \\{}
}

\end{SubSection}


%
\begin{SubSection}{Using \code{.by}}

Let's take a look at the two grouping approaches using this \code{expenses} data set, which tracks costs accumulated across various \code{id}s and \code{region}s:

\begin{alltt}expenses <- tibble(
  id = c(1, 2, 1, 3, 1, 2, 3),
  region = c("A", "A", "A", "B", "B", "A", "A"),
  cost = c(25, 20, 19, 12, 9, 6, 6)
)
expenses
#> # A tibble: 7 x 3
#>      id region  cost
#>   <dbl> <chr>  <dbl>
#> 1     1 A         25
#> 2     2 A         20
#> 3     1 A         19
#> 4     3 B         12
#> 5     1 B          9
#> 6     2 A          6
#> 7     3 A          6
\end{alltt}


Imagine that you wanted to compute the average cost per region.
You'd probably write something like this:

\begin{alltt}expenses %>%
  group_by(region) %>%
  summarise(cost = mean(cost))
#> # A tibble: 2 x 2
#>   region  cost
#>   <chr>  <dbl>
#> 1 A       15.2
#> 2 B       10.5
\end{alltt}


Instead, you can now specify the grouping \emph{inline} within the verb:

\begin{alltt}expenses %>%
  summarise(cost = mean(cost), .by = region)
#> # A tibble: 2 x 2
#>   region  cost
#>   <chr>  <dbl>
#> 1 A       15.2
#> 2 B       10.5
\end{alltt}


\code{.by} applies to a single operation, meaning that since \code{expenses} was an ungrouped data frame, the result after applying \code{.by} will also always be an ungrouped data frame, regardless of the number of grouping columns.

\begin{alltt}expenses %>%
  summarise(cost = mean(cost), .by = c(id, region))
#> # A tibble: 5 x 3
#>      id region  cost
#>   <dbl> <chr>  <dbl>
#> 1     1 A         22
#> 2     2 A         13
#> 3     3 B         12
#> 4     1 B          9
#> 5     3 A          6
\end{alltt}


Compare that with \code{group\_by() \%>\% summarise()}, where \code{summarise()} generally peels off 1 layer of grouping by default, typically with a message that it is doing so:

\begin{alltt}expenses %>%
  group_by(id, region) %>%
  summarise(cost = mean(cost))
#> `summarise()` has grouped output by 'id'. You can override using the `.groups`
#> argument.
#> # A tibble: 5 x 3
#> # Groups:   id [3]
#>      id region  cost
#>   <dbl> <chr>  <dbl>
#> 1     1 A         22
#> 2     1 B          9
#> 3     2 A         13
#> 4     3 A          6
#> 5     3 B         12
\end{alltt}


Because \code{.by} grouping applies to a single operation, you don't need to worry about ungrouping, and it never needs to emit a message to remind you what it is doing with the groups.

Note that with \code{.by} we specified multiple columns to group by using the \LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select} syntax \code{c(id, region)}.
If you have a character vector of column names you'd like to group by, you can do so with \code{.by = all\_of(my\_cols)}.
It will group by the columns in the order they were provided.

To prevent surprising results, you can't use \code{.by} on an existing grouped data frame:

\begin{alltt}expenses %>% 
  group_by(id) %>%
  summarise(cost = mean(cost), .by = c(id, region))
#> Error in `summarise()`:
#> ! Can't supply `.by` when `.data` is a grouped data frame.
\end{alltt}


So far we've focused on the usage of \code{.by} with \code{summarise()}, but \code{.by} works with a number of other dplyr verbs.
For example, you could append the mean cost per region onto the original data frame as a new column rather than computing a summary:

\begin{alltt}expenses %>%
  mutate(cost_by_region = mean(cost), .by = region)
#> # A tibble: 7 x 4
#>      id region  cost cost_by_region
#>   <dbl> <chr>  <dbl>          <dbl>
#> 1     1 A         25           15.2
#> 2     2 A         20           15.2
#> 3     1 A         19           15.2
#> 4     3 B         12           10.5
#> 5     1 B          9           10.5
#> 6     2 A          6           15.2
#> 7     3 A          6           15.2
\end{alltt}


Or you could slice out the maximum cost per combination of id and region:

\begin{alltt}# Note that the argument is named `by` in `slice_max()`
expenses %>%
  slice_max(cost, n = 1, by = c(id, region))
#> # A tibble: 5 x 3
#>      id region  cost
#>   <dbl> <chr>  <dbl>
#> 1     1 A         25
#> 2     2 A         20
#> 3     3 B         12
#> 4     1 B          9
#> 5     3 A          6
\end{alltt}

\end{SubSection}


%
\begin{SubSection}{Result ordering}

When used with \code{.by}, \code{summarise()}, \code{reframe()}, and \code{slice()} all maintain the ordering of the existing data.
This is different from \code{group\_by()}, which has always sorted the group keys in ascending order.

\begin{alltt}df <- tibble(
  month = c("jan", "jan", "feb", "feb", "mar"),
  temp = c(20, 25, 18, 20, 40)
)

# Uses ordering by "first appearance" in the original data
df %>%
  summarise(average_temp = mean(temp), .by = month)
#> # A tibble: 3 x 2
#>   month average_temp
#>   <chr>        <dbl>
#> 1 jan           22.5
#> 2 feb           19  
#> 3 mar           40

# Sorts in ascending order
df %>%
  group_by(month) %>%
  summarise(average_temp = mean(temp))
#> # A tibble: 3 x 2
#>   month average_temp
#>   <chr>        <dbl>
#> 1 feb           19  
#> 2 jan           22.5
#> 3 mar           40
\end{alltt}


If you need sorted group keys, we recommend that you explicitly use \code{\LinkA{arrange()}{arrange}} either before or after the call to \code{summarise()}, \code{reframe()}, or \code{slice()}.
This also gives you full access to all of \code{arrange()}'s features, such as \code{desc()} and the \code{.locale} argument.
\end{SubSection}


%
\begin{SubSection}{Verbs without \code{.by} support}

If a dplyr verb doesn't support \code{.by}, then that typically means that the verb isn't inherently affected by grouping.
For example, \code{\LinkA{pull()}{pull}} and \code{\LinkA{rename()}{rename}} don't support \code{.by}, because specifying columns to group by would not affect their implementations.

That said, there are a few exceptions to this where sometimes a dplyr verb doesn't support \code{.by}, but \emph{does} have special support for grouped data frames created by \code{\LinkA{group\_by()}{group.Rul.by}}.
This is typically because the verbs are required to retain the grouping columns, for example:
\begin{itemize}

\item{} \code{\LinkA{select()}{select}} always retains grouping columns, with a message if any aren't specified in the \code{select()} call.
\item{} \code{\LinkA{distinct()}{distinct}} and \code{\LinkA{count()}{count}} place unspecified grouping columns at the front of the data frame before computing their results.
\item{} \code{\LinkA{arrange()}{arrange}} has a \code{.by\_group} argument to optionally order by grouping columns first.

\end{itemize}


If \code{group\_by()} didn't exist, then these verbs would not have special support for grouped data frames.
\end{SubSection}

\end{Description}
\HeaderA{dplyr\_data\_masking}{Data-masking}{dplyr.Rul.data.Rul.masking}
\keyword{internal}{dplyr\_data\_masking}
%
\begin{Description}
This page is now located at
\code{\LinkA{?rlang::args\_data\_masking}{?rlang::args.Rul.data.Rul.masking}}.
\end{Description}
\HeaderA{dplyr\_extending}{Extending dplyr with new data frame subclasses}{dplyr.Rul.extending}
\aliasA{dplyr\_col\_modify}{dplyr\_extending}{dplyr.Rul.col.Rul.modify}
\aliasA{dplyr\_reconstruct}{dplyr\_extending}{dplyr.Rul.reconstruct}
\aliasA{dplyr\_row\_slice}{dplyr\_extending}{dplyr.Rul.row.Rul.slice}
\keyword{internal}{dplyr\_extending}
%
\begin{Description}
\strong{[Experimental]}

These three functions, along with \AsIs{\texttt{names<-}} and 1d numeric \code{[}
(i.e. \code{x[loc]}) methods, provide a minimal interface for extending dplyr
to work with new data frame subclasses. This means that for simple cases
you should only need to provide a couple of methods, rather than a method
for every dplyr verb.

These functions are a stop-gap measure until we figure out how to solve
the problem more generally, but it's likely that any code you write to
implement them will find a home in what comes next.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
dplyr_row_slice(data, i, ...)

dplyr_col_modify(data, cols)

dplyr_reconstruct(data, template)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] A tibble. We use tibbles because they avoid some inconsistent
subset-assignment use cases.

\item[\code{i}] A numeric or logical vector that indexes the rows of \code{data}.

\item[\code{cols}] A named list used to modify columns. A \code{NULL} value should remove
an existing column.

\item[\code{template}] Template data frame to use for restoring attributes.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Basic advice}
This section gives you basic advice if you want to extend dplyr to work with
your custom data frame subclass, and you want the dplyr methods to behave
in basically the same way.
\begin{itemize}

\item{} If you have data frame attributes that don't depend on the rows or columns
(and should unconditionally be preserved), you don't need to do anything.
The one exception to this is if your subclass extends a data.frame
directly rather than extending a tibble. The \AsIs{\texttt{[.data.frame}} method does not
preserve attributes, so you'll need to write a \code{[} method for your subclass
that preserves attributes important for your class.
\item{} If you have \strong{scalar} attributes that depend on \strong{rows}, implement a
\code{dplyr\_reconstruct()} method. Your method should recompute the attribute
depending on rows now present.
\item{} If you have \strong{scalar} attributes that depend on \strong{columns}, implement a
\code{dplyr\_reconstruct()} method and a 1d \code{[} method. For example, if your
class requires that certain columns be present, your method should return
a data.frame or tibble when those columns are removed.
\item{} If your attributes are \strong{vectorised} over \strong{rows}, implement a
\code{dplyr\_row\_slice()} method. This gives you access to \code{i} so you can
modify the row attribute accordingly. You'll also need to think carefully
about how to recompute the attribute in \code{dplyr\_reconstruct()}, and
you will need to carefully verify the behaviour of each verb, and provide
additional methods as needed.
\item{} If your attributes that are \strong{vectorised} over \strong{columns}, implement
\code{dplyr\_col\_modify()}, 1d \code{[}, and \AsIs{\texttt{names<-}} methods. All of these methods
know which columns are being modified, so you can update the column
attribute according. You'll also need to think carefully about how to
recompute the attribute in \code{dplyr\_reconstruct()}, and you will need to
carefully verify the behaviour of each verb, and provide additional
methods as needed.

\end{itemize}

\end{Section}
%
\begin{Section}{Current usage}
\begin{itemize}

\item{} \code{arrange()}, \code{filter()}, \code{slice()} (and the rest of the \AsIs{\texttt{slice\_*()}}
family), \code{semi\_join()}, and \code{anti\_join()} work by generating a vector of
row indices, and then subsetting with \code{dplyr\_row\_slice()}.
\item{} \code{mutate()} generates a list of new column value (using \code{NULL} to indicate
when columns should be deleted), then passes that to \code{dplyr\_col\_modify()}.
It also uses 1d \code{[} to implement \code{.keep}, and will call \code{relocate()} if
either \code{.before} or \code{.after} are supplied.
\item{} \code{summarise()} and \code{reframe()} work similarly to \code{mutate()} but the data
modified by \code{dplyr\_col\_modify()} comes from \code{group\_data()} or is built
from \code{.by}.
\item{} \code{select()} uses 1d \code{[} to select columns, then \AsIs{\texttt{names<-}} to rename them.
\code{rename()} just uses \AsIs{\texttt{names<-}}. \code{relocate()} just uses 1d \code{[}.
\item{} \code{inner\_join()}, \code{left\_join()}, \code{right\_join()}, and \code{full\_join()}
coerce \code{x} to a tibble, modify the rows, then use \code{dplyr\_reconstruct()}
to convert back to the same type as \code{x}.
\item{} \code{nest\_join()} converts both \code{x} and \code{y} to tibbles, modifies the rows,
and uses \code{dplyr\_col\_modify()} to handle modified key variables and the
list-column that \code{y} becomes. It also uses \code{dplyr\_reconstruct()} to convert
the outer result back to the type of \code{x}, and to convert the nested tibbles
back to the type of \code{y}.
\item{} \code{distinct()} does a \code{mutate()} if any expressions are present, then
uses 1d \code{[} to select variables to keep, then \code{dplyr\_row\_slice()} to
select distinct rows.

\end{itemize}


Note that \code{group\_by()} and \code{ungroup()} don't use any of these generics and
you'll need to provide methods for them directly, or rely on \code{.by} for
per-operation grouping.
\end{Section}
\HeaderA{dplyr\_tidy\_select}{Argument type: tidy-select}{dplyr.Rul.tidy.Rul.select}
\keyword{internal}{dplyr\_tidy\_select}
%
\begin{Description}
This page describes the \AsIs{\texttt{<tidy-select>}} argument modifier which indicates
the argument supports \strong{tidy selections}. Tidy selection provides a concise
dialect of R for selecting variables based on their names or properties.

Tidy selection is a variant of tidy evaluation. This means that inside
functions, tidy-select arguments require special attention, as described in
the \emph{Indirection} section below. If you've never heard of tidy evaluation
before, start with \code{vignette("programming")}.
\end{Description}
%
\begin{Section}{Overview of selection features}
Tidyverse selections implement a dialect of R where operators make
it easy to select variables:
\begin{itemize}

\item{} \code{:} for selecting a range of consecutive variables.
\item{} \code{!} for taking the complement of a set of variables.
\item{} \code{\&} and \code{|} for selecting the intersection or the union of two
sets of variables.
\item{} \code{c()} for combining selections.

\end{itemize}


In addition, you can use \strong{selection helpers}. Some helpers select specific
columns:
\begin{itemize}

\item{} \code{\LinkA{everything()}{everything()}}: Matches all variables.
\item{} \code{\LinkA{last\_col()}{last.Rul.col()}}: Select last variable, possibly with an offset.
\item{} \code{\LinkA{group\_cols()}{group.Rul.cols}}: Select all grouping columns.

\end{itemize}


Other helpers select variables by matching patterns in their names:
\begin{itemize}

\item{} \code{\LinkA{starts\_with()}{starts.Rul.with()}}: Starts with a prefix.
\item{} \code{\LinkA{ends\_with()}{ends.Rul.with()}}: Ends with a suffix.
\item{} \code{\LinkA{contains()}{contains()}}: Contains a literal string.
\item{} \code{\LinkA{matches()}{matches()}}: Matches a regular expression.
\item{} \code{\LinkA{num\_range()}{num.Rul.range()}}: Matches a numerical range like x01, x02, x03.

\end{itemize}


Or from variables stored in a character vector:
\begin{itemize}

\item{} \code{\LinkA{all\_of()}{all.Rul.of()}}: Matches variable names in a character vector. All
names must be present, otherwise an out-of-bounds error is
thrown.
\item{} \code{\LinkA{any\_of()}{any.Rul.of()}}: Same as \code{all\_of()}, except that no error is thrown
for names that don't exist.

\end{itemize}


Or using a predicate function:
\begin{itemize}

\item{} \code{\LinkA{where()}{where()}}: Applies a function to all variables and selects those
for which the function returns \code{TRUE}.

\end{itemize}

\end{Section}
%
\begin{Section}{Indirection}
There are two main cases:
\begin{itemize}

\item{} If you have a character vector of column names, use \code{all\_of()}
or \code{any\_of()}, depending on whether or not you want unknown variable
names to cause an error, e.g. \code{select(df, all\_of(vars))},
\code{select(df, !any\_of(vars))}.
\item{} If you want the user to be able to supply a tidyselect specification in
a function argument, embrace the function argument, e.g.
\code{select(df, \{\{ vars \}\})}.

\end{itemize}

\end{Section}
\HeaderA{explain}{Explain details of a tbl}{explain}
\aliasA{show\_query}{explain}{show.Rul.query}
%
\begin{Description}
This is a generic function which gives more details about an object than
\code{\LinkA{print()}{print}}, and is more focused on human readable output than
\code{\LinkA{str()}{str}}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
explain(x, ...)

show_query(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] An object to explain

\item[\code{...}] Other parameters possibly used by generic
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The first argument, invisibly.
\end{Value}
%
\begin{Section}{Databases}

Explaining a \code{tbl\_sql} will run the SQL \code{EXPLAIN} command which
will describe the query plan. This requires a little bit of knowledge about
how \code{EXPLAIN} works for your database, but is very useful for
diagnosing performance problems.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}


lahman_s <- dbplyr::lahman_sqlite()
batting <- tbl(lahman_s, "Batting")
batting %>% show_query()
batting %>% explain()

# The batting database has indices on all ID variables:
# SQLite automatically picks the most restrictive index
batting %>% filter(lgID == "NL" & yearID == 2000L) %>% explain()

# OR's will use multiple indexes
batting %>% filter(lgID == "NL" | yearID == 2000) %>% explain()

# Joins will use indexes in both tables
teams <- tbl(lahman_s, "Teams")
batting %>% left_join(teams, c("yearID", "teamID")) %>% explain()


\end{ExampleCode}
\end{Examples}
\HeaderA{filter}{Keep rows that match a condition}{filter}
\keyword{single table verbs}{filter}
%
\begin{Description}
The \code{filter()} function is used to subset a data frame,
retaining all rows that satisfy your conditions.
To be retained, the row must produce a value of \code{TRUE} for all conditions.
Note that when a condition evaluates to \code{NA}
the row will be dropped, unlike base subsetting with \code{[}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
filter(.data, ..., .by = NULL, .preserve = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Expressions that
return a logical value, and are defined in terms of the variables in
\code{.data}. If multiple expressions are included, they are combined with the
\code{\&} operator. Only rows for which all conditions evaluate to \code{TRUE} are
kept.

\item[\code{.by}] \strong{[Experimental]}

<\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Optionally, a selection of columns to
group by for just this operation, functioning as an alternative to \code{\LinkA{group\_by()}{group.Rul.by}}. For
details and examples, see \LinkA{?dplyr\_by}{dplyr.Rul.by}.

\item[\code{.preserve}] Relevant when the \code{.data} input is grouped.
If \code{.preserve = FALSE} (the default), the grouping structure
is recalculated based on the resulting data, otherwise the grouping is kept as is.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
The \code{filter()} function is used to subset the rows of
\code{.data}, applying the expressions in \code{...} to the column values to determine which
rows should be retained. It can be applied to both grouped and ungrouped data (see \code{\LinkA{group\_by()}{group.Rul.by}} and
\code{\LinkA{ungroup()}{ungroup}}). However, dplyr is not yet smart enough to optimise the filtering
operation on grouped datasets that do not need grouped calculations. For this
reason, filtering is often considerably faster on ungrouped data.
\end{Details}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following properties:
\begin{itemize}

\item{} Rows are a subset of the input, but appear in the same order.
\item{} Columns are not modified.
\item{} The number of groups may be reduced (if \code{.preserve} is not \code{TRUE}).
\item{} Data frame attributes are preserved.

\end{itemize}

\end{Value}
%
\begin{Section}{Useful filter functions}


There are many functions and operators that are useful when constructing the
expressions used to filter the data:
\begin{itemize}

\item{} \code{\LinkA{==}{==}}, \code{\LinkA{>}{>}}, \code{\LinkA{>=}{>=}} etc
\item{} \code{\LinkA{\&}{.Ramp.}}, \code{\LinkA{|}{|}}, \code{\LinkA{!}{!}}, \code{\LinkA{xor()}{xor}}
\item{} \code{\LinkA{is.na()}{is.na}}
\item{} \code{\LinkA{between()}{between}}, \code{\LinkA{near()}{near}}

\end{itemize}

\end{Section}
%
\begin{Section}{Grouped tibbles}


Because filtering expressions are computed within groups, they may
yield different results on grouped tibbles. This will be the case
as soon as an aggregating, lagging, or ranking function is
involved. Compare this ungrouped filtering:

\begin{alltt}starwars %>% filter(mass > mean(mass, na.rm = TRUE))
\end{alltt}


With the grouped equivalent:

\begin{alltt}starwars %>% group_by(gender) %>% filter(mass > mean(mass, na.rm = TRUE))
\end{alltt}


In the ungrouped version, \code{filter()} compares the value of \code{mass} in each row to
the global average (taken over the whole data set), keeping only the rows with
\code{mass} greater than this global average. In contrast, the grouped version calculates
the average mass separately for each \code{gender} group, and keeps rows with \code{mass} greater
than the relevant within-gender average.
\end{Section}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{arrange}{arrange}()},
\code{\LinkA{mutate}{mutate}()},
\code{\LinkA{reframe}{reframe}()},
\code{\LinkA{rename}{rename}()},
\code{\LinkA{select}{select}()},
\code{\LinkA{slice}{slice}()},
\code{\LinkA{summarise}{summarise}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Filtering by one criterion
filter(starwars, species == "Human")
filter(starwars, mass > 1000)

# Filtering by multiple criteria within a single logical expression
filter(starwars, hair_color == "none" & eye_color == "black")
filter(starwars, hair_color == "none" | eye_color == "black")

# When multiple expressions are used, they are combined using &
filter(starwars, hair_color == "none", eye_color == "black")


# The filtering operation may yield different results on grouped
# tibbles because the expressions are computed within groups.
#
# The following filters rows where `mass` is greater than the
# global average:
starwars %>% filter(mass > mean(mass, na.rm = TRUE))

# Whereas this keeps rows with `mass` greater than the gender
# average:
starwars %>% group_by(gender) %>% filter(mass > mean(mass, na.rm = TRUE))


# To refer to column names that are stored as strings, use the `.data` pronoun:
vars <- c("mass", "height")
cond <- c(80, 150)
starwars %>%
  filter(
    .data[[vars[[1]]]] > cond[[1]],
    .data[[vars[[2]]]] > cond[[2]]
  )
# Learn more in ?rlang::args_data_masking
\end{ExampleCode}
\end{Examples}
\HeaderA{filter-joins}{Filtering joins}{filter.Rdash.joins}
\aliasA{anti\_join}{filter-joins}{anti.Rul.join}
\methaliasA{anti\_join.data.frame}{filter-joins}{anti.Rul.join.data.frame}
\aliasA{semi\_join}{filter-joins}{semi.Rul.join}
\methaliasA{semi\_join.data.frame}{filter-joins}{semi.Rul.join.data.frame}
\keyword{joins}{filter-joins}
%
\begin{Description}
Filtering joins filter rows from \code{x} based on the presence or absence
of matches in \code{y}:
\begin{itemize}

\item{} \code{semi\_join()} return all rows from \code{x} with a match in \code{y}.
\item{} \code{anti\_join()} return all rows from \code{x} with\strong{out} a match in \code{y}.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
semi_join(x, y, by = NULL, copy = FALSE, ...)

## S3 method for class 'data.frame'
semi_join(x, y, by = NULL, copy = FALSE, ..., na_matches = c("na", "never"))

anti_join(x, y, by = NULL, copy = FALSE, ...)

## S3 method for class 'data.frame'
anti_join(x, y, by = NULL, copy = FALSE, ..., na_matches = c("na", "never"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] A pair of data frames, data frame extensions (e.g. a tibble), or
lazy data frames (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{by}] A join specification created with \code{\LinkA{join\_by()}{join.Rul.by}}, or a character
vector of variables to join by.

If \code{NULL}, the default, \AsIs{\texttt{*\_join()}} will perform a natural join, using all
variables in common across \code{x} and \code{y}. A message lists the variables so
that you can check they're correct; suppress the message by supplying \code{by}
explicitly.

To join on different variables between \code{x} and \code{y}, use a \code{\LinkA{join\_by()}{join.Rul.by}}
specification. For example, \code{join\_by(a == b)} will match \code{x\$a} to \code{y\$b}.

To join by multiple variables, use a \code{\LinkA{join\_by()}{join.Rul.by}} specification with
multiple expressions. For example, \code{join\_by(a == b, c == d)} will match
\code{x\$a} to \code{y\$b} and \code{x\$c} to \code{y\$d}. If the column names are the same between
\code{x} and \code{y}, you can shorten this by listing only the variable names, like
\code{join\_by(a, c)}.

\code{\LinkA{join\_by()}{join.Rul.by}} can also be used to perform inequality, rolling, and overlap
joins. See the documentation at \LinkA{?join\_by}{join.Rul.by} for details on
these types of joins.

For simple equality joins, you can alternatively specify a character vector
of variable names to join by. For example, \code{by = c("a", "b")} joins \code{x\$a}
to \code{y\$a} and \code{x\$b} to \code{y\$b}. If variable names differ between \code{x} and \code{y},
use a named character vector like \code{by = c("x\_a" = "y\_a", "x\_b" = "y\_b")}.

To perform a cross-join, generating all combinations of \code{x} and \code{y}, see
\code{\LinkA{cross\_join()}{cross.Rul.join}}.

\item[\code{copy}] If \code{x} and \code{y} are not from the same data source,
and \code{copy} is \code{TRUE}, then \code{y} will be copied into the
same src as \code{x}.  This allows you to join tables across srcs, but
it is a potentially expensive operation so you must opt into it.

\item[\code{...}] Other parameters passed onto methods.

\item[\code{na\_matches}] Should two \code{NA} or two \code{NaN} values match?
\begin{itemize}

\item{} \code{"na"}, the default, treats two \code{NA} or two \code{NaN} values as equal, like
\code{\%in\%}, \code{\LinkA{match()}{match}}, and \code{\LinkA{merge()}{merge}}.
\item{} \code{"never"} treats two \code{NA} or two \code{NaN} values as different, and will
never match them together or to any other values. This is similar to joins
for database sources and to \code{base::merge(incomparables = NA)}.

\end{itemize}

\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{x}. The output has the following properties:
\begin{itemize}

\item{} Rows are a subset of the input, but appear in the same order.
\item{} Columns are not modified.
\item{} Data frame attributes are preserved.
\item{} Groups are taken from \code{x}. The number of groups may be reduced.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

These function are \strong{generic}s, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
\begin{itemize}

\item{} \code{semi\_join()}: no methods found.
\item{} \code{anti\_join()}: no methods found.

\end{itemize}

\end{Section}
%
\begin{SeeAlso}
Other joins: 
\code{\LinkA{cross\_join}{cross.Rul.join}()},
\code{\LinkA{mutate-joins}{mutate.Rdash.joins}},
\code{\LinkA{nest\_join}{nest.Rul.join}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# "Filtering" joins keep cases from the LHS
band_members %>% semi_join(band_instruments)
band_members %>% anti_join(band_instruments)

# To suppress the message about joining variables, supply `by`
band_members %>% semi_join(band_instruments, by = join_by(name))
# This is good practice in production code
\end{ExampleCode}
\end{Examples}
\HeaderA{filter\_all}{Filter within a selection of variables}{filter.Rul.all}
\aliasA{filter\_at}{filter\_all}{filter.Rul.at}
\aliasA{filter\_if}{filter\_all}{filter.Rul.if}
\keyword{internal}{filter\_all}
%
\begin{Description}
\strong{[Superseded]}

Scoped verbs (\AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}}, \AsIs{\texttt{\_all}}) have been superseded by the use of
\code{\LinkA{if\_all()}{if.Rul.all}} or \code{\LinkA{if\_any()}{if.Rul.any}} in an existing verb. See \code{vignette("colwise")} for
details.

These \LinkA{scoped}{scoped} filtering verbs apply a predicate expression to a
selection of variables. The predicate expression should be quoted
with \code{\LinkA{all\_vars()}{all.Rul.vars}} or \code{\LinkA{any\_vars()}{any.Rul.vars}} and should mention the pronoun
\code{.} to refer to variables.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
filter_all(.tbl, .vars_predicate, .preserve = FALSE)

filter_if(.tbl, .predicate, .vars_predicate, .preserve = FALSE)

filter_at(.tbl, .vars, .vars_predicate, .preserve = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.vars\_predicate}] A quoted predicate expression as returned by
\code{\LinkA{all\_vars()}{all.Rul.vars}} or \code{\LinkA{any\_vars()}{any.Rul.vars}}.

Can also be a function or purrr-like formula. In this case, the
intersection of the results is taken by default and there's
currently no way to request the union.

\item[\code{.preserve}] when \code{FALSE} (the default), the grouping structure
is recalculated based on the resulting data, otherwise it is kept as is.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Grouping variables}


The grouping variables that are part of the selection are taken
into account to determine filtered rows.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
# While filter() accepts expressions with specific variables, the
# scoped filter verbs take an expression with the pronoun `.` and
# replicate it over all variables. This expression should be quoted
# with all_vars() or any_vars():
all_vars(is.na(.))
any_vars(is.na(.))


# You can take the intersection of the replicated expressions:
filter_all(mtcars, all_vars(. > 150))
# ->
filter(mtcars, if_all(everything(), ~ .x > 150))

# Or the union:
filter_all(mtcars, any_vars(. > 150))
# ->
filter(mtcars, if_any(everything(), ~ . > 150))


# You can vary the selection of columns on which to apply the
# predicate. filter_at() takes a vars() specification:
filter_at(mtcars, vars(starts_with("d")), any_vars((. %% 2) == 0))
# ->
filter(mtcars, if_any(starts_with("d"), ~ (.x %% 2) == 0))

# And filter_if() selects variables with a predicate function:
filter_if(mtcars, ~ all(floor(.) == .), all_vars(. != 0))
# ->
is_int <- function(x) all(floor(x) == x)
filter(mtcars, if_all(where(is_int), ~ .x != 0))
\end{ExampleCode}
\end{Examples}
\HeaderA{funs}{Create a list of function calls}{funs}
\keyword{internal}{funs}
%
\begin{Description}
\strong{[Deprecated]}

\code{funs()} is deprecated; please use \code{list()} instead. We deprecated this
function because it provided a unique way of specifying anonymous functions,
rather than adopting the conventions used by purrr and other packages
in the tidyverse.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
funs(..., .args = list())
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> A list of functions
specified by:
\begin{itemize}

\item{} Their name, \code{"mean"}
\item{} The function itself, \code{mean}
\item{} A call to the function with \code{.} as a dummy argument,
\code{mean(., na.rm = TRUE)}

\end{itemize}


The following notations are \strong{not} supported, see examples:
\begin{itemize}

\item{} An anonymous function, \code{function(x) mean(x, na.rm = TRUE)}
\item{} An anonymous function in \pkg{purrr} notation, \code{\textasciitilde{}mean(., na.rm = TRUE)}

\end{itemize}


\item[\code{.args}, \code{args}] A named list of additional arguments to be added to all
function calls. As \code{funs()} is being deprecated, use other methods to
supply arguments: \code{...} argument in \LinkA{scoped verbs}{summarise.Rul.at} or make
own functions with \code{\LinkA{purrr::partial()}{purrr::partial()}}.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
funs("mean", mean(., na.rm = TRUE))
# ->
list(mean = mean, mean = ~ mean(.x, na.rm = TRUE))

funs(m1 = mean, m2 = "mean", m3 = mean(., na.rm = TRUE))
# ->
list(m1 = mean, m2 = "mean", m3 = ~ mean(.x, na.rm = TRUE))
\end{ExampleCode}
\end{Examples}
\HeaderA{glimpse}{Get a glimpse of your data}{glimpse}
%
\begin{Description}
\code{glimpse()} is like a transposed version of \code{print()}:
columns run down the page, and data runs across.
This makes it possible to see every column in a data frame.
It's a little like \code{\LinkA{str()}{str}} applied to a data frame
but it tries to show you as much data as possible.
(And it always shows the underlying data, even when applied
to a remote data source.)

\code{glimpse()} is provided by the pillar package, and re-exported
by dplyr. See \code{\LinkA{pillar::glimpse()}{pillar::glimpse()}} for more details.
\end{Description}
%
\begin{Value}
x original x is (invisibly) returned, allowing \code{glimpse()} to be
used within a data pipeline.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
glimpse(mtcars)

# Note that original x is (invisibly) returned, allowing `glimpse()` to be
# used within a pipeline.
mtcars %>%
  glimpse() %>%
  select(1:3)

glimpse(starwars)
\end{ExampleCode}
\end{Examples}
\HeaderA{grouped\_df}{A grouped data frame.}{grouped.Rul.df}
\aliasA{is.grouped\_df}{grouped\_df}{is.grouped.Rul.df}
\aliasA{is\_grouped\_df}{grouped\_df}{is.Rul.grouped.Rul.df}
\keyword{internal}{grouped\_df}
%
\begin{Description}
The easiest way to create a grouped data frame is to call the \code{group\_by()}
method on a data frame or tbl: this will take care of capturing
the unevaluated expressions for you.

These functions are designed for programmatic use. For data analysis
purposes see \code{\LinkA{group\_data()}{group.Rul.data}} for the accessor functions that retrieve
various metadata from a grouped data frames.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
grouped_df(data, vars, drop = group_by_drop_default(data))

is.grouped_df(x)

is_grouped_df(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] a tbl or data frame.

\item[\code{vars}] A character vector.

\item[\code{drop}] When \code{.drop = TRUE}, empty groups are dropped.
\end{ldescription}
\end{Arguments}
\HeaderA{group\_by}{Group by one or more variables}{group.Rul.by}
\aliasA{ungroup}{group\_by}{ungroup}
\keyword{grouping functions}{group\_by}
%
\begin{Description}
Most data operations are done on groups defined by variables.
\code{group\_by()} takes an existing tbl and converts it into a grouped tbl
where operations are performed "by group". \code{ungroup()} removes grouping.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_by(.data, ..., .add = FALSE, .drop = group_by_drop_default(.data))

ungroup(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] In \code{group\_by()}, variables or computations to group by.
Computations are always done on the ungrouped data frame.
To perform computations on the grouped data, you need to use
a separate \code{mutate()} step before the \code{group\_by()}.
Computations are not allowed in \code{nest\_by()}.
In \code{ungroup()}, variables to remove from the grouping.

\item[\code{.add}] When \code{FALSE}, the default, \code{group\_by()} will
override existing groups. To add to the existing groups, use
\code{.add = TRUE}.

This argument was previously called \code{add}, but that prevented
creating a new grouping variable called \code{add}, and conflicts with
our naming conventions.

\item[\code{.drop}] Drop groups formed by factor levels that don't appear in the
data? The default is \code{TRUE} except when \code{.data} has been previously
grouped with \code{.drop = FALSE}. See \code{\LinkA{group\_by\_drop\_default()}{group.Rul.by.Rul.drop.Rul.default}} for details.

\item[\code{x}] A \code{\LinkA{tbl()}{tbl}}
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A grouped data frame with class \code{\LinkA{grouped\_df}{grouped.Rul.df}},
unless the combination of \code{...} and \code{add} yields a empty set of
grouping columns, in which case a tibble will be returned.
\end{Value}
%
\begin{Section}{Methods}

These function are \strong{generic}s, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
\begin{itemize}

\item{} \code{group\_by()}: no methods found.
\item{} \code{ungroup()}: no methods found.

\end{itemize}

\end{Section}
%
\begin{Section}{Ordering}

Currently, \code{group\_by()} internally orders the groups in ascending order. This
results in ordered output from functions that aggregate groups, such as
\code{\LinkA{summarise()}{summarise}}.

When used as grouping columns, character vectors are ordered in the C locale
for performance and reproducibility across R sessions. If the resulting
ordering of your grouped operation matters and is dependent on the locale,
you should follow up the grouped operation with an explicit call to
\code{\LinkA{arrange()}{arrange}} and set the \code{.locale} argument. For example:

\begin{alltt}data %>%
  group_by(chr) %>%
  summarise(avg = mean(x)) %>%
  arrange(chr, .locale = "en")
\end{alltt}


This is often useful as a preliminary step before generating content intended
for humans, such as an HTML table.
%
\begin{SubSection}{Legacy behavior}

Prior to dplyr 1.1.0, character vector grouping columns were ordered in the
system locale. If you need to temporarily revert to this behavior, you can
set the global option \code{dplyr.legacy\_locale} to \code{TRUE}, but this should be
used sparingly and you should expect this option to be removed in a future
version of dplyr. It is better to update existing code to explicitly call
\code{arrange(.locale = )} instead. Note that setting \code{dplyr.legacy\_locale} will
also force calls to \code{\LinkA{arrange()}{arrange}} to use the system locale.
\end{SubSection}

\end{Section}
%
\begin{SeeAlso}
Other grouping functions: 
\code{\LinkA{group\_map}{group.Rul.map}()},
\code{\LinkA{group\_nest}{group.Rul.nest}()},
\code{\LinkA{group\_split}{group.Rul.split}()},
\code{\LinkA{group\_trim}{group.Rul.trim}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
by_cyl <- mtcars %>% group_by(cyl)

# grouping doesn't change how the data looks (apart from listing
# how it's grouped):
by_cyl

# It changes how it acts with the other dplyr verbs:
by_cyl %>% summarise(
  disp = mean(disp),
  hp = mean(hp)
)
by_cyl %>% filter(disp == max(disp))

# Each call to summarise() removes a layer of grouping
by_vs_am <- mtcars %>% group_by(vs, am)
by_vs <- by_vs_am %>% summarise(n = n())
by_vs
by_vs %>% summarise(n = sum(n))

# To removing grouping, use ungroup
by_vs %>%
  ungroup() %>%
  summarise(n = sum(n))

# By default, group_by() overrides existing grouping
by_cyl %>%
  group_by(vs, am) %>%
  group_vars()

# Use add = TRUE to instead append
by_cyl %>%
  group_by(vs, am, .add = TRUE) %>%
  group_vars()

# You can group by expressions: this is a short-hand
# for a mutate() followed by a group_by()
mtcars %>%
  group_by(vsam = vs + am)

# The implicit mutate() step is always performed on the
# ungrouped data. Here we get 3 groups:
mtcars %>%
  group_by(vs) %>%
  group_by(hp_cut = cut(hp, 3))

# If you want it to be performed by groups,
# you have to use an explicit mutate() call.
# Here we get 3 groups per value of vs
mtcars %>%
  group_by(vs) %>%
  mutate(hp_cut = cut(hp, 3)) %>%
  group_by(hp_cut)

# when factors are involved and .drop = FALSE, groups can be empty
tbl <- tibble(
  x = 1:10,
  y = factor(rep(c("a", "c"), each  = 5), levels = c("a", "b", "c"))
)
tbl %>%
  group_by(y, .drop = FALSE) %>%
  group_rows()

\end{ExampleCode}
\end{Examples}
\HeaderA{group\_by\_all}{Group by a selection of variables}{group.Rul.by.Rul.all}
\aliasA{group\_by\_at}{group\_by\_all}{group.Rul.by.Rul.at}
\aliasA{group\_by\_if}{group\_by\_all}{group.Rul.by.Rul.if}
\keyword{internal}{group\_by\_all}
%
\begin{Description}
\strong{[Superseded]}

Scoped verbs (\AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}}, \AsIs{\texttt{\_all}}) have been superseded by the use of
\code{\LinkA{pick()}{pick}} or \code{\LinkA{across()}{across}} in an existing verb. See \code{vignette("colwise")} for
details.

These \LinkA{scoped}{scoped} variants of \code{\LinkA{group\_by()}{group.Rul.by}} group a data frame by a
selection of variables. Like \code{\LinkA{group\_by()}{group.Rul.by}}, they have optional
\LinkA{mutate}{mutate} semantics.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_by_all(
  .tbl,
  .funs = list(),
  ...,
  .add = FALSE,
  .drop = group_by_drop_default(.tbl)
)

group_by_at(
  .tbl,
  .vars,
  .funs = list(),
  ...,
  .add = FALSE,
  .drop = group_by_drop_default(.tbl)
)

group_by_if(
  .tbl,
  .predicate,
  .funs = list(),
  ...,
  .add = FALSE,
  .drop = group_by_drop_default(.tbl)
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.funs}] A function \code{fun}, a quosure style lambda \code{\textasciitilde{} fun(.)} or a list of either form.

\item[\code{...}] Additional arguments for the function calls in
\code{.funs}. These are evaluated only once, with \LinkA{tidy dots}{tidy dots} support.

\item[\code{.add}] See \code{\LinkA{group\_by()}{group.Rul.by}}

\item[\code{.drop}] Drop groups formed by factor levels that don't appear in the
data? The default is \code{TRUE} except when \code{.data} has been previously
grouped with \code{.drop = FALSE}. See \code{\LinkA{group\_by\_drop\_default()}{group.Rul.by.Rul.drop.Rul.default}} for details.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Grouping variables}


Existing grouping variables are maintained, even if not included in
the selection.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
# Group a data frame by all variables:
group_by_all(mtcars)
# ->
mtcars %>% group_by(pick(everything()))

# Group by variables selected with a predicate:
group_by_if(iris, is.factor)
# ->
iris %>% group_by(pick(where(is.factor)))

# Group by variables selected by name:
group_by_at(mtcars, vars(vs, am))
# ->
mtcars %>% group_by(pick(vs, am))

# Like group_by(), the scoped variants have optional mutate
# semantics. This provide a shortcut for group_by() + mutate():
d <- tibble(x=c(1,1,2,2), y=c(1,2,1,2))
group_by_all(d, as.factor)
# ->
d %>% group_by(across(everything(), as.factor))

group_by_if(iris, is.factor, as.character)
# ->
iris %>% group_by(across(where(is.factor), as.character))
\end{ExampleCode}
\end{Examples}
\HeaderA{group\_by\_drop\_default}{Default value for .drop argument of group\_by}{group.Rul.by.Rul.drop.Rul.default}
\keyword{internal}{group\_by\_drop\_default}
%
\begin{Description}
Default value for .drop argument of group\_by
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_by_drop_default(.tbl)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A data frame
\end{ldescription}
\end{Arguments}
%
\begin{Value}
\code{TRUE} unless \code{.tbl} is a grouped data frame that was previously
obtained by \code{group\_by(.drop = FALSE)}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
group_by_drop_default(iris)

iris %>%
  group_by(Species) %>%
  group_by_drop_default()

iris %>%
  group_by(Species, .drop = FALSE) %>%
  group_by_drop_default()

\end{ExampleCode}
\end{Examples}
\HeaderA{group\_cols}{Select grouping variables}{group.Rul.cols}
%
\begin{Description}
This selection helpers matches grouping variables. It can be used
in \code{\LinkA{select()}{select}} or \code{\LinkA{vars()}{vars}} selections.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_cols(vars = NULL, data = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{vars}] Deprecated; please use data instead.

\item[\code{data}] For advanced use only. The default \code{NULL} automatically
finds the "current" data frames.
\end{ldescription}
\end{Arguments}
%
\begin{SeeAlso}
\code{\LinkA{groups()}{groups}} and \code{\LinkA{group\_vars()}{group.Rul.vars}} for retrieving the grouping
variables outside selection contexts.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
gdf <- iris %>% group_by(Species)
gdf %>% select(group_cols())

# Remove the grouping variables from mutate selections:
gdf %>% mutate_at(vars(-group_cols()), `/`, 100)
# -> No longer necessary with across()
gdf %>% mutate(across(everything(), ~ . / 100))
\end{ExampleCode}
\end{Examples}
\HeaderA{group\_data}{Grouping metadata}{group.Rul.data}
\aliasA{groups}{group\_data}{groups}
\aliasA{group\_indices}{group\_data}{group.Rul.indices}
\aliasA{group\_keys}{group\_data}{group.Rul.keys}
\aliasA{group\_rows}{group\_data}{group.Rul.rows}
\aliasA{group\_size}{group\_data}{group.Rul.size}
\aliasA{group\_vars}{group\_data}{group.Rul.vars}
\aliasA{n\_groups}{group\_data}{n.Rul.groups}
\keyword{internal}{group\_data}
%
\begin{Description}
This collection of functions accesses data about grouped data frames in
various ways:
\begin{itemize}

\item{} \code{group\_data()} returns a data frame that defines the grouping structure.
The columns give the values of the grouping variables. The last column,
always called \code{.rows}, is a list of integer vectors that gives the
location of the rows in each group.
\item{} \code{group\_keys()} returns a data frame describing the groups.
\item{} \code{group\_rows()} returns a list of integer vectors giving the rows that
each group contains.
\item{} \code{group\_indices()} returns an integer vector the same length as \code{.data}
that gives the group that each row belongs to.
\item{} \code{group\_vars()} gives names of grouping variables as character vector.
\item{} \code{groups()} gives the names of the grouping variables as a list of symbols.
\item{} \code{group\_size()} gives the size of each group.
\item{} \code{n\_groups()} gives the total number of groups.

\end{itemize}


See \LinkA{context}{context} for equivalent functions that return values for the \emph{current}
group.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_data(.data)

group_keys(.tbl, ...)

group_rows(.data)

group_indices(.data, ...)

group_vars(x)

groups(x)

group_size(x)

n_groups(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}, \code{.tbl}, \code{x}] A data frame or extension (like a tibble or grouped
tibble).

\item[\code{...}] Use of \code{...} is now deprecated; please use \code{group\_by()} first
instead.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(x = c(1,1,2,2))
group_vars(df)
group_rows(df)
group_data(df)
group_indices(df)

gf <- group_by(df, x)
group_vars(gf)
group_rows(gf)
group_data(gf)
group_indices(gf)
\end{ExampleCode}
\end{Examples}
\HeaderA{group\_map}{Apply a function to each group}{group.Rul.map}
\aliasA{group\_modify}{group\_map}{group.Rul.modify}
\aliasA{group\_walk}{group\_map}{group.Rul.walk}
\keyword{grouping functions}{group\_map}
%
\begin{Description}
\strong{[Experimental]}

\code{group\_map()}, \code{group\_modify()} and \code{group\_walk()} are purrr-style functions that can
be used to iterate on grouped tibbles.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_map(.data, .f, ..., .keep = FALSE)

group_modify(.data, .f, ..., .keep = FALSE)

group_walk(.data, .f, ..., .keep = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A grouped tibble

\item[\code{.f}] A function or formula to apply to each group.

If a \strong{function}, it is used as is. It should have at least 2 formal arguments.

If a \strong{formula}, e.g. \code{\textasciitilde{} head(.x)}, it is converted to a function.

In the formula, you can use
\begin{itemize}

\item{} \code{.} or \code{.x} to refer to the subset of rows of \code{.tbl}
for the given group
\item{} \code{.y} to refer to the key, a one row tibble with one column per grouping variable
that identifies the group

\end{itemize}


\item[\code{...}] Additional arguments passed on to \code{.f}

\item[\code{.keep}] are the grouping variables kept in \code{.x}
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Use \code{group\_modify()} when \code{summarize()} is too limited, in terms of what you need
to do and return for each group. \code{group\_modify()} is good for "data frame in, data frame out".
If that is too limited, you need to use a \LinkA{nested}{group.Rul.nest} or \LinkA{split}{group.Rul.split} workflow.
\code{group\_modify()} is an evolution of \code{\LinkA{do()}{do}}, if you have used that before.

Each conceptual group of the data frame is exposed to the function \code{.f} with two pieces of information:
\begin{itemize}

\item{} The subset of the data for the group, exposed as \code{.x}.
\item{} The key, a tibble with exactly one row and columns for each grouping variable, exposed as \code{.y}.

\end{itemize}


For completeness, \code{group\_modify()}, \code{group\_map} and \code{group\_walk()} also work on
ungrouped data frames, in that case the function is applied to the
entire data frame (exposed as \code{.x}), and \code{.y} is a one row tibble with no
column, consistently with \code{\LinkA{group\_keys()}{group.Rul.keys}}.
\end{Details}
%
\begin{Value}
\begin{itemize}

\item{} \code{group\_modify()} returns a grouped tibble. In that case \code{.f} must return a data frame.
\item{} \code{group\_map()} returns a list of results from calling \code{.f} on each group.
\item{} \code{group\_walk()} calls \code{.f} for side effects and returns the input \code{.tbl}, invisibly.

\end{itemize}

\end{Value}
%
\begin{SeeAlso}
Other grouping functions: 
\code{\LinkA{group\_by}{group.Rul.by}()},
\code{\LinkA{group\_nest}{group.Rul.nest}()},
\code{\LinkA{group\_split}{group.Rul.split}()},
\code{\LinkA{group\_trim}{group.Rul.trim}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

# return a list
mtcars %>%
  group_by(cyl) %>%
  group_map(~ head(.x, 2L))

# return a tibble grouped by `cyl` with 2 rows per group
# the grouping data is recalculated
mtcars %>%
  group_by(cyl) %>%
  group_modify(~ head(.x, 2L))


# a list of tibbles
iris %>%
  group_by(Species) %>%
  group_map(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x)))

# a restructured grouped tibble
iris %>%
  group_by(Species) %>%
  group_modify(~ broom::tidy(lm(Petal.Length ~ Sepal.Length, data = .x)))


# a list of vectors
iris %>%
  group_by(Species) %>%
  group_map(~ quantile(.x$Petal.Length, probs = c(0.25, 0.5, 0.75)))

# to use group_modify() the lambda must return a data frame
iris %>%
  group_by(Species) %>%
  group_modify(~ {
     quantile(.x$Petal.Length, probs = c(0.25, 0.5, 0.75)) %>%
     tibble::enframe(name = "prob", value = "quantile")
  })

iris %>%
  group_by(Species) %>%
  group_modify(~ {
    .x %>%
      purrr::map_dfc(fivenum) %>%
      mutate(nms = c("min", "Q1", "median", "Q3", "max"))
  })

# group_walk() is for side effects
dir.create(temp <- tempfile())
iris %>%
  group_by(Species) %>%
  group_walk(~ write.csv(.x, file = file.path(temp, paste0(.y$Species, ".csv"))))
list.files(temp, pattern = "csv$")
unlink(temp, recursive = TRUE)

# group_modify() and ungrouped data frames
mtcars %>%
  group_modify(~ head(.x, 2L))

\end{ExampleCode}
\end{Examples}
\HeaderA{group\_nest}{Nest a tibble using a grouping specification}{group.Rul.nest}
\keyword{grouping functions}{group\_nest}
\keyword{internal}{group\_nest}
%
\begin{Description}
\strong{[Experimental]}

Nest a tibble using a grouping specification
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_nest(.tbl, ..., .key = "data", keep = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A tbl

\item[\code{...}] Grouping specification, forwarded to \code{\LinkA{group\_by()}{group.Rul.by}}

\item[\code{.key}] the name of the list column

\item[\code{keep}] Should the grouping columns be kept in the list column.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A tbl with one row per unique combination of the grouping variables.
The first columns are the grouping variables, followed by a list column of tibbles
with matching rows of the remaining columns.
\end{Value}
%
\begin{Section}{Lifecycle}

\code{group\_nest()} is not stable because \code{\LinkA{tidyr::nest(.by =)}{tidyr::nest(.by =)}}
provides very similar behavior. It may be deprecated in the future.
\end{Section}
%
\begin{Section}{Grouped data frames}


The primary use case for \code{\LinkA{group\_nest()}{group.Rul.nest}} is with already grouped data frames,
typically a result of \code{\LinkA{group\_by()}{group.Rul.by}}. In this case \code{\LinkA{group\_nest()}{group.Rul.nest}} only uses
the first argument, the grouped tibble, and warns when \code{...} is used.
\end{Section}
%
\begin{Section}{Ungrouped data frames}


When used on ungrouped data frames, \code{\LinkA{group\_nest()}{group.Rul.nest}} forwards the \code{...} to
\code{\LinkA{group\_by()}{group.Rul.by}} before nesting, therefore the \code{...} are subject to the data mask.
\end{Section}
%
\begin{SeeAlso}
Other grouping functions: 
\code{\LinkA{group\_by}{group.Rul.by}()},
\code{\LinkA{group\_map}{group.Rul.map}()},
\code{\LinkA{group\_split}{group.Rul.split}()},
\code{\LinkA{group\_trim}{group.Rul.trim}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

#----- use case 1: a grouped data frame
iris %>%
  group_by(Species) %>%
  group_nest()

# this can be useful if the grouped data has been altered before nesting
iris %>%
  group_by(Species) %>%
  filter(Sepal.Length > mean(Sepal.Length)) %>%
  group_nest()

#----- use case 2: using group_nest() on a ungrouped data frame with
#                  a grouping specification that uses the data mask
starwars %>%
  group_nest(species, homeworld)
\end{ExampleCode}
\end{Examples}
\HeaderA{group\_split}{Split data frame by groups}{group.Rul.split}
\keyword{grouping functions}{group\_split}
\keyword{internal}{group\_split}
%
\begin{Description}
\strong{[Experimental]}

\code{\LinkA{group\_split()}{group.Rul.split}} works like \code{\LinkA{base::split()}{base::split()}} but:
\begin{itemize}

\item{} It uses the grouping structure from \code{\LinkA{group\_by()}{group.Rul.by}} and therefore is subject
to the data mask
\item{} It does not name the elements of the list based on the grouping as this
only works well for a single character grouping variable. Instead,
use \code{\LinkA{group\_keys()}{group.Rul.keys}} to access a data frame that defines the groups.

\end{itemize}


\code{group\_split()} is primarily designed to work with grouped data frames.
You can pass \code{...} to group and split an ungrouped data frame, but this
is generally not very useful as you want have easy access to the group
metadata.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_split(.tbl, ..., .keep = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A tbl.

\item[\code{...}] If \code{.tbl} is an ungrouped data frame, a grouping specification,
forwarded to \code{\LinkA{group\_by()}{group.Rul.by}}.

\item[\code{.keep}] Should the grouping columns be kept?
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A list of tibbles. Each tibble contains the rows of \code{.tbl} for the
associated group and all the columns, including the grouping variables.
Note that this returns a \LinkA{list\_of}{list.Rul.of} which is slightly
stricter than a simple list but is useful for representing lists where
every element has the same type.
\end{Value}
%
\begin{Section}{Lifecycle}

\code{group\_split()} is not stable because you can achieve very similar results by
manipulating the nested column returned from
\code{\LinkA{tidyr::nest(.by =)}{tidyr::nest(.by =)}}. That also retains the group keys all
within a single data structure. \code{group\_split()} may be deprecated in the
future.
\end{Section}
%
\begin{SeeAlso}
Other grouping functions: 
\code{\LinkA{group\_by}{group.Rul.by}()},
\code{\LinkA{group\_map}{group.Rul.map}()},
\code{\LinkA{group\_nest}{group.Rul.nest}()},
\code{\LinkA{group\_trim}{group.Rul.trim}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
ir <- iris %>% group_by(Species)

group_split(ir)
group_keys(ir)
\end{ExampleCode}
\end{Examples}
\HeaderA{group\_trim}{Trim grouping structure}{group.Rul.trim}
\keyword{grouping functions}{group\_trim}
%
\begin{Description}
\strong{[Experimental]}
Drop unused levels of all factors that are used as grouping variables,
then recalculates the grouping structure.

\code{group\_trim()} is particularly useful after a \code{\LinkA{filter()}{filter}} that is intended
to select a subset of groups.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
group_trim(.tbl, .drop = group_by_drop_default(.tbl))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \LinkA{grouped data frame}{grouped.Rul.df}

\item[\code{.drop}] See \code{\LinkA{group\_by()}{group.Rul.by}}
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A \LinkA{grouped data frame}{grouped.Rul.df}
\end{Value}
%
\begin{SeeAlso}
Other grouping functions: 
\code{\LinkA{group\_by}{group.Rul.by}()},
\code{\LinkA{group\_map}{group.Rul.map}()},
\code{\LinkA{group\_nest}{group.Rul.nest}()},
\code{\LinkA{group\_split}{group.Rul.split}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
iris %>%
  group_by(Species) %>%
  filter(Species == "setosa", .preserve = TRUE) %>%
  group_trim()
\end{ExampleCode}
\end{Examples}
\HeaderA{ident}{Flag a character vector as SQL identifiers}{ident}
%
\begin{Description}
\code{ident()} takes unquoted strings and flags them as identifiers.
\code{ident\_q()} assumes its input has already been quoted, and ensures
it does not get quoted again. This is currently used only for
\code{schema.table}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ident(...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] A character vector, or name-value pairs
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# Identifiers are escaped with "

ident("x")

\end{ExampleCode}
\end{Examples}
\HeaderA{if\_else}{Vectorised if-else}{if.Rul.else}
%
\begin{Description}
\code{if\_else()} is a vectorized \LinkA{if-else}{if}. Compared to the base R equivalent,
\code{\LinkA{ifelse()}{ifelse}}, this function allows you to handle missing values in the
\code{condition} with \code{missing} and always takes \code{true}, \code{false}, and \code{missing}
into account when determining what the output type should be.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
if_else(condition, true, false, missing = NULL, ..., ptype = NULL, size = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{condition}] A logical vector

\item[\code{true}, \code{false}] Vectors to use for \code{TRUE} and \code{FALSE} values of
\code{condition}.

Both \code{true} and \code{false} will be \LinkA{recycled}{recycled}
to the size of \code{condition}.

\code{true}, \code{false}, and \code{missing} (if used) will be cast to their common type.

\item[\code{missing}] If not \code{NULL}, will be used as the value for \code{NA} values of
\code{condition}. Follows the same size and type rules as \code{true} and \code{false}.

\item[\code{...}] These dots are for future extensions and must be empty.

\item[\code{ptype}] An optional prototype declaring the desired output type. If
supplied, this overrides the common type of \code{true}, \code{false}, and \code{missing}.

\item[\code{size}] An optional size declaring the desired output size. If supplied,
this overrides the size of \code{condition}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector with the same size as \code{condition} and the same type as the common
type of \code{true}, \code{false}, and \code{missing}.

Where \code{condition} is \code{TRUE}, the matching values from \code{true}, where it is
\code{FALSE}, the matching values from \code{false}, and where it is \code{NA}, the matching
values from \code{missing}, if provided, otherwise a missing value will be used.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
x <- c(-5:5, NA)
if_else(x < 0, NA, x)

# Explicitly handle `NA` values in the `condition` with `missing`
if_else(x < 0, "negative", "positive", missing = "missing")

# Unlike `ifelse()`, `if_else()` preserves types
x <- factor(sample(letters[1:5], 10, replace = TRUE))
ifelse(x %in% c("a", "b", "c"), x, NA)
if_else(x %in% c("a", "b", "c"), x, NA)

# `if_else()` is often useful for creating new columns inside of `mutate()`
starwars %>%
  mutate(category = if_else(height < 100, "short", "tall"), .keep = "used")
\end{ExampleCode}
\end{Examples}
\HeaderA{join\_by}{Join specifications}{join.Rul.by}
\aliasA{closest}{join\_by}{closest}
\aliasA{overlaps}{join\_by}{overlaps}
\aliasA{within}{join\_by}{within}
%
\begin{Description}
\code{join\_by()} constructs a specification that describes how to join two tables
using a small domain specific language. The result can be supplied as the
\code{by} argument to any of the join functions (such as \code{\LinkA{left\_join()}{left.Rul.join}}).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
join_by(...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] Expressions specifying the join.

Each expression should consist of one of the following:
\begin{itemize}

\item{} Equality condition: \code{==}
\item{} Inequality conditions: \code{>=}, \code{>}, \code{<=}, or \code{<}
\item{} Rolling helper: \code{closest()}
\item{} Overlap helpers: \code{between()}, \code{within()}, or \code{overlaps()}

\end{itemize}


Other expressions are not supported. If you need to perform a join on
a computed variable, e.g. \code{join\_by(sales\_date - 40 >= promo\_date)},
you'll need to precompute and store it in a separate column.

Column names should be specified as quoted or unquoted names. By default,
the name on the left-hand side of a join condition refers to the left-hand
table, unless overridden by explicitly prefixing the column name with
either \AsIs{\texttt{x\$}} or \AsIs{\texttt{y\$}}.

If a single column name is provided without any join conditions, it is
interpreted as if that column name was duplicated on each side of \code{==},
i.e. \code{x} is interpreted as \code{x == x}.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Join types}
The following types of joins are supported by dplyr:
\begin{itemize}

\item{} Equality joins
\item{} Inequality joins
\item{} Rolling joins
\item{} Overlap joins
\item{} Cross joins

\end{itemize}


Equality, inequality, rolling, and overlap joins are discussed in more detail
below. Cross joins are implemented through \code{\LinkA{cross\_join()}{cross.Rul.join}}.
%
\begin{SubSection}{Equality joins}

Equality joins require keys to be equal between one or more pairs of columns,
and are the most common type of join. To construct an equality join using
\code{join\_by()}, supply two column names to join with separated by \code{==}.
Alternatively, supplying a single name will be interpreted as an equality
join between two columns of the same name. For example, \code{join\_by(x)} is
equivalent to \code{join\_by(x == x)}.
\end{SubSection}


%
\begin{SubSection}{Inequality joins}

Inequality joins match on an inequality, such as \code{>}, \code{>=}, \code{<}, or \code{<=}, and
are common in time series analysis and genomics. To construct an inequality
join using \code{join\_by()}, supply two column names separated by one of the above
mentioned inequalities.

Note that inequality joins will match a single row in \code{x} to a potentially
large number of rows in \code{y}. Be extra careful when constructing inequality
join specifications!
\end{SubSection}


%
\begin{SubSection}{Rolling joins}

Rolling joins are a variant of inequality joins that limit the results
returned from an inequality join condition. They are useful for "rolling" the
closest match forward/backwards when there isn't an exact match. To construct
a rolling join, wrap an inequality with \code{closest()}.
\begin{itemize}

\item{} \code{closest(expr)}

\code{expr} must be an inequality involving one of: \code{>}, \code{>=}, \code{<}, or \code{<=}.

For example, \code{closest(x >= y)} is interpreted as: For each value in \code{x},
find the closest value in \code{y} that is less than or equal to that \code{x} value.

\end{itemize}


\code{closest()} will always use the left-hand table (\code{x}) as the primary table,
and the right-hand table (\code{y}) as the one to find the closest match in,
regardless of how the inequality is specified. For example,
\code{closest(y\$a >= x\$b)} will always be interpreted as \code{closest(x\$b <= y\$a)}.
\end{SubSection}


%
\begin{SubSection}{Overlap joins}

Overlap joins are a special case of inequality joins involving one or two
columns from the left-hand table \emph{overlapping} a range defined by two columns
from the right-hand table. There are three helpers that \code{join\_by()}
recognizes to assist with constructing overlap joins, all of which can be
constructed from simpler inequalities.
\begin{itemize}

\item{} \code{between(x, y\_lower, y\_upper, ..., bounds = "[]")}

For each value in \code{x}, this finds everywhere that value falls between
\AsIs{\texttt{[y\_lower, y\_upper]}}. Equivalent to \AsIs{\texttt{x >= y\_lower, x <= y\_upper}} by
default.

\code{bounds} can be one of \code{"[]"}, \code{"[)"}, \code{"(]"}, or
\code{"()"} to alter the inclusiveness of the lower and upper bounds. This
changes whether \code{>=} or \code{>} and \code{<=} or \code{<} are used to build the
inequalities shown above.

Dots are for future extensions and must be empty.
\item{} \code{within(x\_lower, x\_upper, y\_lower, y\_upper)}

For each range in \AsIs{\texttt{[x\_lower, x\_upper]}}, this finds everywhere that range
falls completely within \AsIs{\texttt{[y\_lower, y\_upper]}}. Equivalent to \AsIs{\texttt{x\_lower >= y\_lower, x\_upper <= y\_upper}}.

The inequalities used to build \code{within()} are the same regardless of the
inclusiveness of the supplied ranges.
\item{} \code{overlaps(x\_lower, x\_upper, y\_lower, y\_upper, ..., bounds = "[]")}

For each range in \AsIs{\texttt{[x\_lower, x\_upper]}}, this finds everywhere that range
overlaps \AsIs{\texttt{[y\_lower, y\_upper]}} in any capacity. Equivalent to \AsIs{\texttt{x\_lower <= y\_upper, x\_upper >= y\_lower}} by default.

\code{bounds} can be one of \code{"[]"}, \code{"[)"}, \code{"(]"}, or
\code{"()"} to alter the inclusiveness of the lower and upper bounds.
\code{"[]"} uses \code{<=} and \code{>=}, but the 3 other options use \code{<} and \code{>}
and generate the exact same inequalities.

Dots are for future extensions and must be empty.

\end{itemize}


These conditions assume that the ranges are well-formed and non-empty, i.e.
\code{x\_lower <= x\_upper} when bounds are treated as \code{"[]"}, and
\code{x\_lower < x\_upper} otherwise.
\end{SubSection}

\end{Section}
%
\begin{Section}{Column referencing}
When specifying join conditions, \code{join\_by()} assumes that column names on the
left-hand side of the condition refer to the left-hand table (\code{x}), and names
on the right-hand side of the condition refer to the right-hand table (\code{y}).
Occasionally, it is clearer to be able to specify a right-hand table name on
the left-hand side of the condition, and vice versa. To support this, column
names can be prefixed by \AsIs{\texttt{x\$}} or \AsIs{\texttt{y\$}} to explicitly specify which table they
come from.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
sales <- tibble(
  id = c(1L, 1L, 1L, 2L, 2L),
  sale_date = as.Date(c("2018-12-31", "2019-01-02", "2019-01-05", "2019-01-04", "2019-01-01"))
)
sales

promos <- tibble(
  id = c(1L, 1L, 2L),
  promo_date = as.Date(c("2019-01-01", "2019-01-05", "2019-01-02"))
)
promos

# Match `id` to `id`, and `sale_date` to `promo_date`
by <- join_by(id, sale_date == promo_date)
left_join(sales, promos, by)

# For each `sale_date` within a particular `id`,
# find all `promo_date`s that occurred before that particular sale
by <- join_by(id, sale_date >= promo_date)
left_join(sales, promos, by)

# For each `sale_date` within a particular `id`,
# find only the closest `promo_date` that occurred before that sale
by <- join_by(id, closest(sale_date >= promo_date))
left_join(sales, promos, by)

# If you want to disallow exact matching in rolling joins, use `>` rather
# than `>=`. Note that the promo on `2019-01-05` is no longer considered the
# closest match for the sale on the same date.
by <- join_by(id, closest(sale_date > promo_date))
left_join(sales, promos, by)

# Same as before, but also require that the promo had to occur at most 1
# day before the sale was made. We'll use a full join to see that id 2's
# promo on `2019-01-02` is no longer matched to the sale on `2019-01-04`.
sales <- mutate(sales, sale_date_lower = sale_date - 1)
by <- join_by(id, closest(sale_date >= promo_date), sale_date_lower <= promo_date)
full_join(sales, promos, by)

# ---------------------------------------------------------------------------

segments <- tibble(
  segment_id = 1:4,
  chromosome = c("chr1", "chr2", "chr2", "chr1"),
  start = c(140, 210, 380, 230),
  end = c(150, 240, 415, 280)
)
segments

reference <- tibble(
  reference_id = 1:4,
  chromosome = c("chr1", "chr1", "chr2", "chr2"),
  start = c(100, 200, 300, 415),
  end = c(150, 250, 399, 450)
)
reference

# Find every time a segment `start` falls between the reference
# `[start, end]` range.
by <- join_by(chromosome, between(start, start, end))
full_join(segments, reference, by)

# If you wanted the reference columns first, supply `reference` as `x`
# and `segments` as `y`, then explicitly refer to their columns using `x$`
# and `y$`.
by <- join_by(chromosome, between(y$start, x$start, x$end))
full_join(reference, segments, by)

# Find every time a segment falls completely within a reference.
# Sometimes using `x$` and `y$` makes your intentions clearer, even if they
# match the default behavior.
by <- join_by(chromosome, within(x$start, x$end, y$start, y$end))
inner_join(segments, reference, by)

# Find every time a segment overlaps a reference in any way.
by <- join_by(chromosome, overlaps(x$start, x$end, y$start, y$end))
full_join(segments, reference, by)

# It is common to have right-open ranges with bounds like `[)`, which would
# mean an end value of `415` would no longer overlap a start value of `415`.
# Setting `bounds` allows you to compute overlaps with those kinds of ranges.
by <- join_by(chromosome, overlaps(x$start, x$end, y$start, y$end, bounds = "[)"))
full_join(segments, reference, by)
\end{ExampleCode}
\end{Examples}
\HeaderA{last\_dplyr\_warnings}{Show warnings from the last command}{last.Rul.dplyr.Rul.warnings}
\keyword{internal}{last\_dplyr\_warnings}
%
\begin{Description}
Warnings that occur inside a dplyr verb like \code{mutate()} are caught
and stashed away instead of being emitted to the console. This
prevents rowwise and grouped data frames from flooding the console
with warnings. To see the original warnings, use
\code{last\_dplyr\_warnings()}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
last_dplyr_warnings(n = 5)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n}] Passed to \code{\LinkA{head()}{head}} so that only the first \code{n} warnings are
displayed.
\end{ldescription}
\end{Arguments}
\HeaderA{lead-lag}{Compute lagged or leading values}{lead.Rdash.lag}
\aliasA{lag}{lead-lag}{lag}
\aliasA{lead}{lead-lag}{lead}
%
\begin{Description}
Find the "previous" (\code{lag()}) or "next" (\code{lead()}) values in a vector. Useful
for comparing values behind of or ahead of the current values.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
lag(x, n = 1L, default = NULL, order_by = NULL, ...)

lead(x, n = 1L, default = NULL, order_by = NULL, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A vector

\item[\code{n}] Positive integer of length 1, giving the number of positions to
lag or lead by

\item[\code{default}] The value used to pad \code{x} back to its original size after the
lag or lead has been applied. The default, \code{NULL}, pads with a missing
value. If supplied, this must be a vector with size 1, which will be cast
to the type of \code{x}.

\item[\code{order\_by}] An optional secondary vector that defines the ordering to use
when applying the lag or lead to \code{x}. If supplied, this must be the same
size as \code{x}.

\item[\code{...}] Not used.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector with the same type and size as \code{x}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
lag(1:5)
lead(1:5)

x <- 1:5
tibble(behind = lag(x), x, ahead = lead(x))

# If you want to look more rows behind or ahead, use `n`
lag(1:5, n = 1)
lag(1:5, n = 2)

lead(1:5, n = 1)
lead(1:5, n = 2)

# If you want to define a value to pad with, use `default`
lag(1:5)
lag(1:5, default = 0)

lead(1:5)
lead(1:5, default = 6)

# If the data are not already ordered, use `order_by`
scrambled <- slice_sample(
  tibble(year = 2000:2005, value = (0:5) ^ 2),
  prop = 1
)

wrong <- mutate(scrambled, previous_year_value = lag(value))
arrange(wrong, year)

right <- mutate(scrambled, previous_year_value = lag(value, order_by = year))
arrange(right, year)
\end{ExampleCode}
\end{Examples}
\HeaderA{make\_tbl}{Create a "tbl" object}{make.Rul.tbl}
\keyword{internal}{make\_tbl}
%
\begin{Description}
\code{tbl()} is the standard constructor for tbls. \code{as.tbl()} coerces,
and \code{is.tbl()} tests.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
make_tbl(subclass, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{subclass}] name of subclass. "tbl" is an abstract base class, so you
must supply this value. \code{tbl\_} is automatically prepended to the
class name

\item[\code{...}] For \code{tbl()}, other fields used by class. For \code{as.tbl()},
other arguments passed to methods.
\end{ldescription}
\end{Arguments}
\HeaderA{mutate}{Create, modify, and delete columns}{mutate}
\methaliasA{mutate.data.frame}{mutate}{mutate.data.frame}
\keyword{single table verbs}{mutate}
%
\begin{Description}
\code{mutate()} creates new columns that are functions of existing variables.
It can also modify (if the name is the same as an existing
column) and delete columns (by setting their value to \code{NULL}).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mutate(.data, ...)

## S3 method for class 'data.frame'
mutate(
  .data,
  ...,
  .by = NULL,
  .keep = c("all", "used", "unused", "none"),
  .before = NULL,
  .after = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Name-value pairs.
The name gives the name of the column in the output.

The value can be:
\begin{itemize}

\item{} A vector of length 1, which will be recycled to the correct length.
\item{} A vector the same length as the current group (or the whole data frame
if ungrouped).
\item{} \code{NULL}, to remove the column.
\item{} A data frame or tibble, to create multiple columns in the output.

\end{itemize}


\item[\code{.by}] \strong{[Experimental]}

<\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Optionally, a selection of columns to
group by for just this operation, functioning as an alternative to \code{\LinkA{group\_by()}{group.Rul.by}}. For
details and examples, see \LinkA{?dplyr\_by}{dplyr.Rul.by}.

\item[\code{.keep}] Control which columns from \code{.data} are retained in the output. Grouping
columns and columns created by \code{...} are always kept.
\begin{itemize}

\item{} \code{"all"} retains all columns from \code{.data}. This is the default.
\item{} \code{"used"} retains only the columns used in \code{...} to create new
columns. This is useful for checking your work, as it displays inputs
and outputs side-by-side.
\item{} \code{"unused"} retains only the columns \emph{not} used in \code{...} to create new
columns. This is useful if you generate new columns, but no longer need
the columns used to generate them.
\item{} \code{"none"} doesn't retain any extra columns from \code{.data}. Only the grouping
variables and columns created by \code{...} are kept.

\end{itemize}


\item[\code{.before}, \code{.after}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Optionally, control where new columns
should appear (the default is to add to the right hand side). See
\code{\LinkA{relocate()}{relocate}} for more details.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} Columns from \code{.data} will be preserved according to the \code{.keep} argument.
\item{} Existing columns that are modified by \code{...} will always be returned in
their original location.
\item{} New columns created through \code{...} will be placed according to the
\code{.before} and \code{.after} arguments.
\item{} The number of rows is not affected.
\item{} Columns given the value \code{NULL} will be removed.
\item{} Groups will be recomputed if a grouping variable is mutated.
\item{} Data frame attributes are preserved.

\end{itemize}

\end{Value}
%
\begin{Section}{Useful mutate functions}

\begin{itemize}

\item{} \code{\LinkA{+}{+}}, \code{\LinkA{-}{.Rdash.}}, \code{\LinkA{log()}{log}}, etc., for their usual mathematical meanings
\item{} \code{\LinkA{lead()}{lead}}, \code{\LinkA{lag()}{lag}}
\item{} \code{\LinkA{dense\_rank()}{dense.Rul.rank}}, \code{\LinkA{min\_rank()}{min.Rul.rank}}, \code{\LinkA{percent\_rank()}{percent.Rul.rank}}, \code{\LinkA{row\_number()}{row.Rul.number}},
\code{\LinkA{cume\_dist()}{cume.Rul.dist}}, \code{\LinkA{ntile()}{ntile}}
\item{} \code{\LinkA{cumsum()}{cumsum}}, \code{\LinkA{cummean()}{cummean}}, \code{\LinkA{cummin()}{cummin}}, \code{\LinkA{cummax()}{cummax}}, \code{\LinkA{cumany()}{cumany}}, \code{\LinkA{cumall()}{cumall}}
\item{} \code{\LinkA{na\_if()}{na.Rul.if}}, \code{\LinkA{coalesce()}{coalesce}}
\item{} \code{\LinkA{if\_else()}{if.Rul.else}}, \code{\LinkA{recode()}{recode}}, \code{\LinkA{case\_when()}{case.Rul.when}}

\end{itemize}

\end{Section}
%
\begin{Section}{Grouped tibbles}


Because mutating expressions are computed within groups, they may
yield different results on grouped tibbles. This will be the case
as soon as an aggregating, lagging, or ranking function is
involved. Compare this ungrouped mutate:

\begin{alltt}starwars %>%
  select(name, mass, species) %>%
  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))
\end{alltt}


With the grouped equivalent:

\begin{alltt}starwars %>%
  select(name, mass, species) %>%
  group_by(species) %>%
  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))
\end{alltt}


The former normalises \code{mass} by the global average whereas the
latter normalises by the averages within species levels.
\end{Section}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{arrange}{arrange}()},
\code{\LinkA{filter}{filter}()},
\code{\LinkA{reframe}{reframe}()},
\code{\LinkA{rename}{rename}()},
\code{\LinkA{select}{select}()},
\code{\LinkA{slice}{slice}()},
\code{\LinkA{summarise}{summarise}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Newly created variables are available immediately
starwars %>%
  select(name, mass) %>%
  mutate(
    mass2 = mass * 2,
    mass2_squared = mass2 * mass2
  )

# As well as adding new variables, you can use mutate() to
# remove variables and modify existing variables.
starwars %>%
  select(name, height, mass, homeworld) %>%
  mutate(
    mass = NULL,
    height = height * 0.0328084 # convert to feet
  )

# Use across() with mutate() to apply a transformation
# to multiple columns in a tibble.
starwars %>%
  select(name, homeworld, species) %>%
  mutate(across(!name, as.factor))
# see more in ?across

# Window functions are useful for grouped mutates:
starwars %>%
  select(name, mass, homeworld) %>%
  group_by(homeworld) %>%
  mutate(rank = min_rank(desc(mass)))
# see `vignette("window-functions")` for more details

# By default, new columns are placed on the far right.
df <- tibble(x = 1, y = 2)
df %>% mutate(z = x + y)
df %>% mutate(z = x + y, .before = 1)
df %>% mutate(z = x + y, .after = x)

# By default, mutate() keeps all columns from the input data.
df <- tibble(x = 1, y = 2, a = "a", b = "b")
df %>% mutate(z = x + y, .keep = "all") # the default
df %>% mutate(z = x + y, .keep = "used")
df %>% mutate(z = x + y, .keep = "unused")
df %>% mutate(z = x + y, .keep = "none")

# Grouping ----------------------------------------
# The mutate operation may yield different results on grouped
# tibbles because the expressions are computed within groups.
# The following normalises `mass` by the global average:
starwars %>%
  select(name, mass, species) %>%
  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))

# Whereas this normalises `mass` by the averages within species
# levels:
starwars %>%
  select(name, mass, species) %>%
  group_by(species) %>%
  mutate(mass_norm = mass / mean(mass, na.rm = TRUE))

# Indirection ----------------------------------------
# Refer to column names stored as strings with the `.data` pronoun:
vars <- c("mass", "height")
mutate(starwars, prod = .data[[vars[[1]]]] * .data[[vars[[2]]]])
# Learn more in ?rlang::args_data_masking
\end{ExampleCode}
\end{Examples}
\HeaderA{mutate-joins}{Mutating joins}{mutate.Rdash.joins}
\aliasA{full\_join}{mutate-joins}{full.Rul.join}
\methaliasA{full\_join.data.frame}{mutate-joins}{full.Rul.join.data.frame}
\aliasA{inner\_join}{mutate-joins}{inner.Rul.join}
\methaliasA{inner\_join.data.frame}{mutate-joins}{inner.Rul.join.data.frame}
\aliasA{join}{mutate-joins}{join}
\methaliasA{join.data.frame}{mutate-joins}{join.data.frame}
\aliasA{left\_join}{mutate-joins}{left.Rul.join}
\methaliasA{left\_join.data.frame}{mutate-joins}{left.Rul.join.data.frame}
\aliasA{right\_join}{mutate-joins}{right.Rul.join}
\methaliasA{right\_join.data.frame}{mutate-joins}{right.Rul.join.data.frame}
\keyword{joins}{mutate-joins}
%
\begin{Description}
Mutating joins add columns from \code{y} to \code{x}, matching observations based on
the keys. There are four mutating joins: the inner join, and the three outer
joins.
%
\begin{SubSection}{Inner join}

An \code{inner\_join()} only keeps observations from \code{x} that have a matching key
in \code{y}.

The most important property of an inner join is that unmatched rows in either
input are not included in the result. This means that generally inner joins
are not appropriate in most analyses, because it is too easy to lose
observations.
\end{SubSection}


%
\begin{SubSection}{Outer joins}

The three outer joins keep observations that appear in at least one of the
data frames:
\begin{itemize}

\item{} A \code{left\_join()} keeps all observations in \code{x}.
\item{} A \code{right\_join()} keeps all observations in \code{y}.
\item{} A \code{full\_join()} keeps all observations in \code{x} and \code{y}.

\end{itemize}

\end{SubSection}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
inner_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL
)

## S3 method for class 'data.frame'
inner_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL,
  na_matches = c("na", "never"),
  multiple = "all",
  unmatched = "drop",
  relationship = NULL
)

left_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL
)

## S3 method for class 'data.frame'
left_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL,
  na_matches = c("na", "never"),
  multiple = "all",
  unmatched = "drop",
  relationship = NULL
)

right_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL
)

## S3 method for class 'data.frame'
right_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL,
  na_matches = c("na", "never"),
  multiple = "all",
  unmatched = "drop",
  relationship = NULL
)

full_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL
)

## S3 method for class 'data.frame'
full_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  suffix = c(".x", ".y"),
  ...,
  keep = NULL,
  na_matches = c("na", "never"),
  multiple = "all",
  relationship = NULL
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] A pair of data frames, data frame extensions (e.g. a tibble), or
lazy data frames (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{by}] A join specification created with \code{\LinkA{join\_by()}{join.Rul.by}}, or a character
vector of variables to join by.

If \code{NULL}, the default, \AsIs{\texttt{*\_join()}} will perform a natural join, using all
variables in common across \code{x} and \code{y}. A message lists the variables so
that you can check they're correct; suppress the message by supplying \code{by}
explicitly.

To join on different variables between \code{x} and \code{y}, use a \code{\LinkA{join\_by()}{join.Rul.by}}
specification. For example, \code{join\_by(a == b)} will match \code{x\$a} to \code{y\$b}.

To join by multiple variables, use a \code{\LinkA{join\_by()}{join.Rul.by}} specification with
multiple expressions. For example, \code{join\_by(a == b, c == d)} will match
\code{x\$a} to \code{y\$b} and \code{x\$c} to \code{y\$d}. If the column names are the same between
\code{x} and \code{y}, you can shorten this by listing only the variable names, like
\code{join\_by(a, c)}.

\code{\LinkA{join\_by()}{join.Rul.by}} can also be used to perform inequality, rolling, and overlap
joins. See the documentation at \LinkA{?join\_by}{join.Rul.by} for details on
these types of joins.

For simple equality joins, you can alternatively specify a character vector
of variable names to join by. For example, \code{by = c("a", "b")} joins \code{x\$a}
to \code{y\$a} and \code{x\$b} to \code{y\$b}. If variable names differ between \code{x} and \code{y},
use a named character vector like \code{by = c("x\_a" = "y\_a", "x\_b" = "y\_b")}.

To perform a cross-join, generating all combinations of \code{x} and \code{y}, see
\code{\LinkA{cross\_join()}{cross.Rul.join}}.

\item[\code{copy}] If \code{x} and \code{y} are not from the same data source,
and \code{copy} is \code{TRUE}, then \code{y} will be copied into the
same src as \code{x}.  This allows you to join tables across srcs, but
it is a potentially expensive operation so you must opt into it.

\item[\code{suffix}] If there are non-joined duplicate variables in \code{x} and
\code{y}, these suffixes will be added to the output to disambiguate them.
Should be a character vector of length 2.

\item[\code{...}] Other parameters passed onto methods.

\item[\code{keep}] Should the join keys from both \code{x} and \code{y} be preserved in the
output?
\begin{itemize}

\item{} If \code{NULL}, the default, joins on equality retain only the keys from \code{x},
while joins on inequality retain the keys from both inputs.
\item{} If \code{TRUE}, all keys from both inputs are retained.
\item{} If \code{FALSE}, only keys from \code{x} are retained. For right and full joins,
the data in key columns corresponding to rows that only exist in \code{y} are
merged into the key columns from \code{x}. Can't be used when joining on
inequality conditions.

\end{itemize}


\item[\code{na\_matches}] Should two \code{NA} or two \code{NaN} values match?
\begin{itemize}

\item{} \code{"na"}, the default, treats two \code{NA} or two \code{NaN} values as equal, like
\code{\%in\%}, \code{\LinkA{match()}{match}}, and \code{\LinkA{merge()}{merge}}.
\item{} \code{"never"} treats two \code{NA} or two \code{NaN} values as different, and will
never match them together or to any other values. This is similar to joins
for database sources and to \code{base::merge(incomparables = NA)}.

\end{itemize}


\item[\code{multiple}] Handling of rows in \code{x} with multiple matches in \code{y}.
For each row of \code{x}:
\begin{itemize}

\item{} \code{"all"}, the default, returns every match detected in \code{y}. This is the
same behavior as SQL.
\item{} \code{"any"} returns one match detected in \code{y}, with no guarantees on which
match will be returned. It is often faster than \code{"first"} and \code{"last"}
if you just need to detect if there is at least one match.
\item{} \code{"first"} returns the first match detected in \code{y}.
\item{} \code{"last"} returns the last match detected in \code{y}.

\end{itemize}


\item[\code{unmatched}] How should unmatched keys that would result in dropped rows
be handled?
\begin{itemize}

\item{} \code{"drop"} drops unmatched keys from the result.
\item{} \code{"error"} throws an error if unmatched keys are detected.

\end{itemize}


\code{unmatched} is intended to protect you from accidentally dropping rows
during a join. It only checks for unmatched keys in the input that could
potentially drop rows.
\begin{itemize}

\item{} For left joins, it checks \code{y}.
\item{} For right joins, it checks \code{x}.
\item{} For inner joins, it checks both \code{x} and \code{y}. In this case, \code{unmatched} is
also allowed to be a character vector of length 2 to specify the behavior
for \code{x} and \code{y} independently.

\end{itemize}


\item[\code{relationship}] Handling of the expected relationship between the keys of
\code{x} and \code{y}. If the expectations chosen from the list below are
invalidated, an error is thrown.
\begin{itemize}

\item{} \code{NULL}, the default, doesn't expect there to be any relationship between
\code{x} and \code{y}. However, for equality joins it will check for a many-to-many
relationship (which is typically unexpected) and will warn if one occurs,
encouraging you to either take a closer look at your inputs or make this
relationship explicit by specifying \code{"many-to-many"}.

See the \emph{Many-to-many relationships} section for more details.
\item{} \code{"one-to-one"} expects:
\begin{itemize}

\item{} Each row in \code{x} matches at most 1 row in \code{y}.
\item{} Each row in \code{y} matches at most 1 row in \code{x}.

\end{itemize}

\item{} \code{"one-to-many"} expects:
\begin{itemize}

\item{} Each row in \code{y} matches at most 1 row in \code{x}.

\end{itemize}

\item{} \code{"many-to-one"} expects:
\begin{itemize}

\item{} Each row in \code{x} matches at most 1 row in \code{y}.

\end{itemize}

\item{} \code{"many-to-many"} doesn't perform any relationship checks, but is provided
to allow you to be explicit about this relationship if you know it
exists.

\end{itemize}


\code{relationship} doesn't handle cases where there are zero matches. For that,
see \code{unmatched}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{x} (including the same groups). The order of
the rows and columns of \code{x} is preserved as much as possible. The output has
the following properties:
\begin{itemize}

\item{} The rows are affect by the join type.
\begin{itemize}

\item{} \code{inner\_join()} returns matched \code{x} rows.
\item{} \code{left\_join()} returns all \code{x} rows.
\item{} \code{right\_join()}  returns matched of \code{x} rows, followed by unmatched \code{y} rows.
\item{} \code{full\_join()}  returns all \code{x} rows, followed by unmatched \code{y} rows.

\end{itemize}

\item{} Output columns include all columns from \code{x} and all non-key columns from
\code{y}. If \code{keep = TRUE}, the key columns from \code{y} are included as well.
\item{} If non-key columns in \code{x} and \code{y} have the same name, \code{suffix}es are added
to disambiguate. If \code{keep = TRUE} and key columns in \code{x} and \code{y} have
the same name, \code{suffix}es are added to disambiguate these as well.
\item{} If \code{keep = FALSE}, output columns included in \code{by} are coerced to their
common type between \code{x} and \code{y}.

\end{itemize}

\end{Value}
%
\begin{Section}{Many-to-many relationships}


By default, dplyr guards against many-to-many relationships in equality joins
by throwing a warning. These occur when both of the following are true:
\begin{itemize}

\item{} A row in \code{x} matches multiple rows in \code{y}.
\item{} A row in \code{y} matches multiple rows in \code{x}.

\end{itemize}


This is typically surprising, as most joins involve a relationship of
one-to-one, one-to-many, or many-to-one, and is often the result of an
improperly specified join. Many-to-many relationships are particularly
problematic because they can result in a Cartesian explosion of the number of
rows returned from the join.

If a many-to-many relationship is expected, silence this warning by
explicitly setting \code{relationship = "many-to-many"}.

In production code, it is best to preemptively set \code{relationship} to whatever
relationship you expect to exist between the keys of \code{x} and \code{y}, as this
forces an error to occur immediately if the data doesn't align with your
expectations.

Inequality joins typically result in many-to-many relationships by nature, so
they don't warn on them by default, but you should still take extra care when
specifying an inequality join, because they also have the capability to
return a large number of rows.

Rolling joins don't warn on many-to-many relationships either, but many
rolling joins follow a many-to-one relationship, so it is often useful to
set \code{relationship = "many-to-one"} to enforce this.

Note that in SQL, most database providers won't let you specify a
many-to-many relationship between two tables, instead requiring that you
create a third \emph{junction table} that results in two one-to-many relationships
instead.
\end{Section}
%
\begin{Section}{Methods}

These functions are \strong{generic}s, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
\begin{itemize}

\item{} \code{inner\_join()}: no methods found.
\item{} \code{left\_join()}: no methods found.
\item{} \code{right\_join()}: no methods found.
\item{} \code{full\_join()}: no methods found.

\end{itemize}

\end{Section}
%
\begin{SeeAlso}
Other joins: 
\code{\LinkA{cross\_join}{cross.Rul.join}()},
\code{\LinkA{filter-joins}{filter.Rdash.joins}},
\code{\LinkA{nest\_join}{nest.Rul.join}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
band_members %>% inner_join(band_instruments)
band_members %>% left_join(band_instruments)
band_members %>% right_join(band_instruments)
band_members %>% full_join(band_instruments)

# To suppress the message about joining variables, supply `by`
band_members %>% inner_join(band_instruments, by = join_by(name))
# This is good practice in production code

# Use an equality expression if the join variables have different names
band_members %>% full_join(band_instruments2, by = join_by(name == artist))
# By default, the join keys from `x` and `y` are coalesced in the output; use
# `keep = TRUE` to keep the join keys from both `x` and `y`
band_members %>%
  full_join(band_instruments2, by = join_by(name == artist), keep = TRUE)

# If a row in `x` matches multiple rows in `y`, all the rows in `y` will be
# returned once for each matching row in `x`.
df1 <- tibble(x = 1:3)
df2 <- tibble(x = c(1, 1, 2), y = c("first", "second", "third"))
df1 %>% left_join(df2)

# If a row in `y` also matches multiple rows in `x`, this is known as a
# many-to-many relationship, which is typically a result of an improperly
# specified join or some kind of messy data. In this case, a warning is
# thrown by default:
df3 <- tibble(x = c(1, 1, 1, 3))
df3 %>% left_join(df2)

# In the rare case where a many-to-many relationship is expected, set
# `relationship = "many-to-many"` to silence this warning
df3 %>% left_join(df2, relationship = "many-to-many")

# Use `join_by()` with a condition other than `==` to perform an inequality
# join. Here we match on every instance where `df1$x > df2$x`.
df1 %>% left_join(df2, join_by(x > x))

# By default, NAs match other NAs so that there are two
# rows in the output of this join:
df1 <- data.frame(x = c(1, NA), y = 2)
df2 <- data.frame(x = c(1, NA), z = 3)
left_join(df1, df2)

# You can optionally request that NAs don't match, giving a
# a result that more closely resembles SQL joins
left_join(df1, df2, na_matches = "never")
\end{ExampleCode}
\end{Examples}
\HeaderA{mutate\_all}{Mutate multiple columns}{mutate.Rul.all}
\aliasA{mutate\_at}{mutate\_all}{mutate.Rul.at}
\aliasA{mutate\_if}{mutate\_all}{mutate.Rul.if}
\aliasA{transmute\_all}{mutate\_all}{transmute.Rul.all}
\aliasA{transmute\_at}{mutate\_all}{transmute.Rul.at}
\aliasA{transmute\_if}{mutate\_all}{transmute.Rul.if}
\keyword{internal}{mutate\_all}
%
\begin{Description}
\strong{[Superseded]}

Scoped verbs (\AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}}, \AsIs{\texttt{\_all}}) have been superseded by the use of
\code{\LinkA{pick()}{pick}} or \code{\LinkA{across()}{across}} in an existing verb. See \code{vignette("colwise")} for
details.

The \LinkA{scoped}{scoped} variants of \code{\LinkA{mutate()}{mutate}} and \code{\LinkA{transmute()}{transmute}} make it easy to apply
the same transformation to multiple variables. There are three variants:
\begin{itemize}

\item{} \_all affects every variable
\item{} \_at affects variables selected with a character vector or vars()
\item{} \_if affects variables selected with a predicate function:

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
mutate_all(.tbl, .funs, ...)

mutate_if(.tbl, .predicate, .funs, ...)

mutate_at(.tbl, .vars, .funs, ..., .cols = NULL)

transmute_all(.tbl, .funs, ...)

transmute_if(.tbl, .predicate, .funs, ...)

transmute_at(.tbl, .vars, .funs, ..., .cols = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.funs}] A function \code{fun}, a quosure style lambda \code{\textasciitilde{} fun(.)} or a list of either form.

\item[\code{...}] Additional arguments for the function calls in
\code{.funs}. These are evaluated only once, with \LinkA{tidy dots}{tidy dots} support.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.

\item[\code{.cols}] This argument has been renamed to \code{.vars} to fit
dplyr's terminology and is deprecated.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame. By default, the newly created columns have the shortest
names needed to uniquely identify the output. To force inclusion of a name,
even when not needed, name the input (see examples for details).
\end{Value}
%
\begin{Section}{Grouping variables}


If applied on a grouped tibble, these operations are \emph{not} applied
to the grouping variables. The behaviour depends on whether the
selection is \strong{implicit} (\code{all} and \code{if} selections) or
\strong{explicit} (\code{at} selections).
\begin{itemize}

\item{} Grouping variables covered by explicit selections in
\code{mutate\_at()} and \code{transmute\_at()} are always an error. Add
\code{-group\_cols()} to the \code{\LinkA{vars()}{vars}} selection to avoid this:

\begin{alltt}data %>% mutate_at(vars(-group_cols(), ...), myoperation)
\end{alltt}


Or remove \code{group\_vars()} from the character vector of column names:

\begin{alltt}nms <- setdiff(nms, group_vars(data))
data %>% mutate_at(vars, myoperation)
\end{alltt}

\item{} Grouping variables covered by implicit selections are ignored by
\code{mutate\_all()}, \code{transmute\_all()}, \code{mutate\_if()}, and
\code{transmute\_if()}.

\end{itemize}

\end{Section}
%
\begin{Section}{Naming}


The names of the new columns are derived from the names of the
input variables and the names of the functions.
\begin{itemize}

\item{} if there is only one unnamed function (i.e. if \code{.funs} is an unnamed list
of length one),
the names of the input variables are used to name the new columns;
\item{} for \AsIs{\texttt{\_at}} functions, if there is only one unnamed variable (i.e.,
if \code{.vars} is of the form \code{vars(a\_single\_column)}) and \code{.funs} has length
greater than one,
the names of the functions are used to name the new columns;
\item{} otherwise, the new names are created by
concatenating the names of the input variables and the names of the
functions, separated with an underscore \code{"\_"}.

\end{itemize}


The \code{.funs} argument can be a named or unnamed list.
If a function is unnamed and the name cannot be derived automatically,
a name of the form "fn\#" is used.
Similarly, \code{\LinkA{vars()}{vars}} accepts named and unnamed arguments.
If a variable in \code{.vars} is named, a new column by that name will be created.

Name collisions in the new columns are disambiguated using a unique suffix.
\end{Section}
%
\begin{SeeAlso}
\LinkA{The other scoped verbs}{scoped}, \code{\LinkA{vars()}{vars}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
iris <- as_tibble(iris)

# All variants can be passed functions and additional arguments,
# purrr-style. The _at() variants directly support strings. Here
# we'll scale the variables `height` and `mass`:
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
starwars %>% mutate_at(c("height", "mass"), scale2)
# ->
starwars %>% mutate(across(c("height", "mass"), scale2))

# You can pass additional arguments to the function:
starwars %>% mutate_at(c("height", "mass"), scale2, na.rm = TRUE)
starwars %>% mutate_at(c("height", "mass"), ~scale2(., na.rm = TRUE))
# ->
starwars %>% mutate(across(c("height", "mass"), ~ scale2(.x, na.rm = TRUE)))

# You can also supply selection helpers to _at() functions but you have
# to quote them with vars():
iris %>% mutate_at(vars(matches("Sepal")), log)
iris %>% mutate(across(matches("Sepal"), log))

# The _if() variants apply a predicate function (a function that
# returns TRUE or FALSE) to determine the relevant subset of
# columns. Here we divide all the numeric columns by 100:
starwars %>% mutate_if(is.numeric, scale2, na.rm = TRUE)
starwars %>% mutate(across(where(is.numeric), ~ scale2(.x, na.rm = TRUE)))

# mutate_if() is particularly useful for transforming variables from
# one type to another
iris %>% mutate_if(is.factor, as.character)
iris %>% mutate_if(is.double, as.integer)
# ->
iris %>% mutate(across(where(is.factor), as.character))
iris %>% mutate(across(where(is.double), as.integer))

# Multiple transformations ----------------------------------------

# If you want to apply multiple transformations, pass a list of
# functions. When there are multiple functions, they create new
# variables instead of modifying the variables in place:
iris %>% mutate_if(is.numeric, list(scale2, log))
iris %>% mutate_if(is.numeric, list(~scale2(.), ~log(.)))
iris %>% mutate_if(is.numeric, list(scale = scale2, log = log))
# ->
iris %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), list(scale = scale2, log = log)))

# When there's only one function in the list, it modifies existing
# variables in place. Give it a name to instead create new variables:
iris %>% mutate_if(is.numeric, list(scale2))
iris %>% mutate_if(is.numeric, list(scale = scale2))
\end{ExampleCode}
\end{Examples}
\HeaderA{na\_if}{Convert values to \code{NA}}{na.Rul.if}
%
\begin{Description}
This is a translation of the SQL command \code{NULLIF}. It is useful if you want
to convert an annoying value to \code{NA}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
na_if(x, y)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Vector to modify

\item[\code{y}] Value or vector to compare against. When \code{x} and \code{y} are equal, the
value in \code{x} will be replaced with \code{NA}.

\code{y} is \LinkA{cast}{cast} to the type of \code{x} before
comparison.

\code{y} is \LinkA{recycled}{recycled} to the size of \code{x} before
comparison. This means that \code{y} can be a vector with the same size as \code{x},
but most of the time this will be a single value.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A modified version of \code{x} that replaces any values that
are equal to \code{y} with \code{NA}.
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{coalesce()}{coalesce}} to replace missing values with a specified
value.

\code{\LinkA{tidyr::replace\_na()}{tidyr::replace.Rul.na()}} to replace \code{NA} with a value.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
na_if(1:5, 5:1)

x <- c(1, -1, 0, 10)
100 / x
100 / na_if(x, 0)

y <- c("abc", "def", "", "ghi")
na_if(y, "")

# `na_if()` allows you to replace `NaN` with `NA`,
# even though `NaN == NaN` returns `NA`
z <- c(1, NaN, NA, 2, NaN)
na_if(z, NaN)

# `na_if()` is particularly useful inside `mutate()`,
# and is meant for use with vectors rather than entire data frames
starwars %>%
  select(name, eye_color) %>%
  mutate(eye_color = na_if(eye_color, "unknown"))

# `na_if()` can also be used with `mutate()` and `across()`
# to alter multiple columns
starwars %>%
   mutate(across(where(is.character), ~na_if(., "unknown")))
\end{ExampleCode}
\end{Examples}
\HeaderA{near}{Compare two numeric vectors}{near}
%
\begin{Description}
This is a safe way of comparing if two vectors of floating point numbers
are (pairwise) equal.  This is safer than using \code{==}, because it has
a built in tolerance
\end{Description}
%
\begin{Usage}
\begin{verbatim}
near(x, y, tol = .Machine$double.eps^0.5)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] Numeric vectors to compare

\item[\code{tol}] Tolerance of comparison.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
sqrt(2) ^ 2 == 2
near(sqrt(2) ^ 2, 2)
\end{ExampleCode}
\end{Examples}
\HeaderA{nest\_by}{Nest by one or more variables}{nest.Rul.by}
\keyword{internal}{nest\_by}
%
\begin{Description}
\strong{[Experimental]}

\code{nest\_by()} is closely related to \code{\LinkA{group\_by()}{group.Rul.by}}. However, instead of storing
the group structure in the metadata, it is made explicit in the data,
giving each group key a single row along with a list-column of data frames
that contain all the other data.

\code{nest\_by()} returns a \LinkA{rowwise}{rowwise} data frame, which makes operations on the
grouped data particularly elegant. See \code{vignette("rowwise")} for more
details.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
nest_by(.data, ..., .key = "data", .keep = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] In \code{group\_by()}, variables or computations to group by.
Computations are always done on the ungrouped data frame.
To perform computations on the grouped data, you need to use
a separate \code{mutate()} step before the \code{group\_by()}.
Computations are not allowed in \code{nest\_by()}.
In \code{ungroup()}, variables to remove from the grouping.

\item[\code{.key}] Name of the list column

\item[\code{.keep}] Should the grouping columns be kept in the list column.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Note that \code{df \%>\% nest\_by(x, y)} is roughly equivalent to

\begin{alltt}df %>%
  group_by(x, y) %>%
  summarise(data = list(pick(everything()))) %>%
  rowwise()
\end{alltt}


If you want to unnest a nested data frame, you can either use
\code{tidyr::unnest()} or take advantage of \code{reframe()}s multi-row behaviour:

\begin{alltt}nested %>%
  reframe(data)
\end{alltt}

\end{Details}
%
\begin{Value}
A \LinkA{rowwise}{rowwise} data frame. The output has the following properties:
\begin{itemize}

\item{} The rows come from the underlying \code{\LinkA{group\_keys()}{group.Rul.keys}}.
\item{} The columns are the grouping keys plus one list-column of data frames.
\item{} Data frame attributes are \strong{not} preserved, because \code{nest\_by()}
fundamentally creates a new data frame.

\end{itemize}


A tbl with one row per unique combination of the grouping variables.
The first columns are the grouping variables, followed by a list column of tibbles
with matching rows of the remaining columns.
\end{Value}
%
\begin{Section}{Lifecycle}

\code{nest\_by()} is not stable because \code{\LinkA{tidyr::nest(.by =)}{tidyr::nest(.by =)}}
provides very similar behavior. It may be deprecated in the future.
\end{Section}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
# After nesting, you get one row per group
iris %>% nest_by(Species)
starwars %>% nest_by(species)

# The output is grouped by row, which makes modelling particularly easy
models <- mtcars %>%
  nest_by(cyl) %>%
  mutate(model = list(lm(mpg ~ wt, data = data)))
models

models %>% summarise(rsq = summary(model)$r.squared)


# This is particularly elegant with the broom functions
models %>% summarise(broom::glance(model))
models %>% reframe(broom::tidy(model))


# Note that you can also `reframe()` to unnest the data
models %>% reframe(data)
\end{ExampleCode}
\end{Examples}
\HeaderA{nest\_join}{Nest join}{nest.Rul.join}
\methaliasA{nest\_join.data.frame}{nest\_join}{nest.Rul.join.data.frame}
\keyword{joins}{nest\_join}
%
\begin{Description}
A nest join leaves \code{x} almost unchanged, except that it adds a new
list-column, where each element contains the rows from \code{y} that match the
corresponding row in \code{x}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
nest_join(x, y, by = NULL, copy = FALSE, keep = NULL, name = NULL, ...)

## S3 method for class 'data.frame'
nest_join(
  x,
  y,
  by = NULL,
  copy = FALSE,
  keep = NULL,
  name = NULL,
  ...,
  na_matches = c("na", "never"),
  unmatched = "drop"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] A pair of data frames, data frame extensions (e.g. a tibble), or
lazy data frames (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{by}] A join specification created with \code{\LinkA{join\_by()}{join.Rul.by}}, or a character
vector of variables to join by.

If \code{NULL}, the default, \AsIs{\texttt{*\_join()}} will perform a natural join, using all
variables in common across \code{x} and \code{y}. A message lists the variables so
that you can check they're correct; suppress the message by supplying \code{by}
explicitly.

To join on different variables between \code{x} and \code{y}, use a \code{\LinkA{join\_by()}{join.Rul.by}}
specification. For example, \code{join\_by(a == b)} will match \code{x\$a} to \code{y\$b}.

To join by multiple variables, use a \code{\LinkA{join\_by()}{join.Rul.by}} specification with
multiple expressions. For example, \code{join\_by(a == b, c == d)} will match
\code{x\$a} to \code{y\$b} and \code{x\$c} to \code{y\$d}. If the column names are the same between
\code{x} and \code{y}, you can shorten this by listing only the variable names, like
\code{join\_by(a, c)}.

\code{\LinkA{join\_by()}{join.Rul.by}} can also be used to perform inequality, rolling, and overlap
joins. See the documentation at \LinkA{?join\_by}{join.Rul.by} for details on
these types of joins.

For simple equality joins, you can alternatively specify a character vector
of variable names to join by. For example, \code{by = c("a", "b")} joins \code{x\$a}
to \code{y\$a} and \code{x\$b} to \code{y\$b}. If variable names differ between \code{x} and \code{y},
use a named character vector like \code{by = c("x\_a" = "y\_a", "x\_b" = "y\_b")}.

To perform a cross-join, generating all combinations of \code{x} and \code{y}, see
\code{\LinkA{cross\_join()}{cross.Rul.join}}.

\item[\code{copy}] If \code{x} and \code{y} are not from the same data source,
and \code{copy} is \code{TRUE}, then \code{y} will be copied into the
same src as \code{x}.  This allows you to join tables across srcs, but
it is a potentially expensive operation so you must opt into it.

\item[\code{keep}] Should the new list-column contain join keys? The default
will preserve the join keys for inequality joins.

\item[\code{name}] The name of the list-column created by the join. If \code{NULL},
the default, the name of \code{y} is used.

\item[\code{...}] Other parameters passed onto methods.

\item[\code{na\_matches}] Should two \code{NA} or two \code{NaN} values match?
\begin{itemize}

\item{} \code{"na"}, the default, treats two \code{NA} or two \code{NaN} values as equal, like
\code{\%in\%}, \code{\LinkA{match()}{match}}, and \code{\LinkA{merge()}{merge}}.
\item{} \code{"never"} treats two \code{NA} or two \code{NaN} values as different, and will
never match them together or to any other values. This is similar to joins
for database sources and to \code{base::merge(incomparables = NA)}.

\end{itemize}


\item[\code{unmatched}] How should unmatched keys that would result in dropped rows
be handled?
\begin{itemize}

\item{} \code{"drop"} drops unmatched keys from the result.
\item{} \code{"error"} throws an error if unmatched keys are detected.

\end{itemize}


\code{unmatched} is intended to protect you from accidentally dropping rows
during a join. It only checks for unmatched keys in the input that could
potentially drop rows.
\begin{itemize}

\item{} For left joins, it checks \code{y}.
\item{} For right joins, it checks \code{x}.
\item{} For inner joins, it checks both \code{x} and \code{y}. In this case, \code{unmatched} is
also allowed to be a character vector of length 2 to specify the behavior
for \code{x} and \code{y} independently.

\end{itemize}

\end{ldescription}
\end{Arguments}
%
\begin{Value}
The output:
\begin{itemize}

\item{} Is same type as \code{x} (including having the same groups).
\item{} Has exactly the same number of rows as \code{x}.
\item{} Contains all the columns of \code{x} in the same order with the same values.
They are only modified (slightly) if \code{keep = FALSE}, when columns listed
in \code{by} will be coerced to their common type across \code{x} and \code{y}.
\item{} Gains one new column called \code{\{name\}} on the far right, a list column
containing data frames the same type as \code{y}.

\end{itemize}

\end{Value}
%
\begin{Section}{Relationship to other joins}
You can recreate many other joins from the result of a nest join:
\begin{itemize}

\item{} \code{\LinkA{inner\_join()}{inner.Rul.join}} is a \code{nest\_join()} plus \code{\LinkA{tidyr::unnest()}{tidyr::unnest()}}.
\item{} \code{\LinkA{left\_join()}{left.Rul.join}} is a \code{nest\_join()} plus \code{tidyr::unnest(keep\_empty = TRUE)}.
\item{} \code{\LinkA{semi\_join()}{semi.Rul.join}} is a \code{nest\_join()} plus a \code{filter()} where you check
that every element of data has at least one row.
\item{} \code{\LinkA{anti\_join()}{anti.Rul.join}} is a \code{nest\_join()} plus a \code{filter()} where you check that every
element has zero rows.

\end{itemize}

\end{Section}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other joins: 
\code{\LinkA{cross\_join}{cross.Rul.join}()},
\code{\LinkA{filter-joins}{filter.Rdash.joins}},
\code{\LinkA{mutate-joins}{mutate.Rdash.joins}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
df1 <- tibble(x = 1:3)
df2 <- tibble(x = c(2, 3, 3), y = c("a", "b", "c"))

out <- nest_join(df1, df2)
out
out$df2
\end{ExampleCode}
\end{Examples}
\HeaderA{new\_grouped\_df}{Low-level construction and validation for the grouped\_df and rowwise\_df classes}{new.Rul.grouped.Rul.df}
\aliasA{new\_rowwise\_df}{new\_grouped\_df}{new.Rul.rowwise.Rul.df}
\aliasA{validate\_grouped\_df}{new\_grouped\_df}{validate.Rul.grouped.Rul.df}
\aliasA{validate\_rowwise\_df}{new\_grouped\_df}{validate.Rul.rowwise.Rul.df}
\keyword{internal}{new\_grouped\_df}
%
\begin{Description}
\code{new\_grouped\_df()} and \code{new\_rowwise\_df()} are constructors designed to be high-performance so only
check types, not values. This means it is the caller's responsibility
to create valid values, and hence this is for expert use only.

\code{validate\_grouped\_df()} and \code{validate\_rowwise\_df()} validate the attributes
of a \code{grouped\_df} or a \code{rowwise\_df}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
new_grouped_df(x, groups, ..., class = character())

validate_grouped_df(x, check_bounds = FALSE)

new_rowwise_df(data, group_data = NULL, ..., class = character())

validate_rowwise_df(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A data frame

\item[\code{groups}] The grouped structure, \code{groups} should be a data frame.
Its last column should be called \code{.rows} and be
a list of 1 based integer vectors that all are between 1 and the number of rows of \code{.data}.

\item[\code{...}] additional attributes

\item[\code{class}] additional class, will be prepended to canonical classes.

\item[\code{check\_bounds}] whether to check all indices for out of bounds problems in \code{grouped\_df} objects
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# 5 bootstrap samples
tbl <- new_grouped_df(
  tibble(x = rnorm(10)),
  groups = tibble(".rows" := replicate(5, sample(1:10, replace = TRUE), simplify = FALSE))
)
# mean of each bootstrap sample
summarise(tbl, x = mean(x))

\end{ExampleCode}
\end{Examples}
\HeaderA{nth}{Extract the first, last, or nth value from a vector}{nth}
\aliasA{first}{nth}{first}
\aliasA{last}{nth}{last}
%
\begin{Description}
These are useful helpers for extracting a single value from a vector. They
are guaranteed to return a meaningful value, even when the input is shorter
than expected. You can also provide an optional secondary vector that defines
the ordering.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
nth(x, n, order_by = NULL, default = NULL, na_rm = FALSE)

first(x, order_by = NULL, default = NULL, na_rm = FALSE)

last(x, order_by = NULL, default = NULL, na_rm = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A vector

\item[\code{n}] For \code{nth()}, a single integer specifying the position.
Negative integers index from the end (i.e. \code{-1L} will return the
last value in the vector).

\item[\code{order\_by}] An optional vector the same size as \code{x} used to determine the
order.

\item[\code{default}] A default value to use if the position does not exist in \code{x}.

If \code{NULL}, the default, a missing value is used.

If supplied, this must be a single value, which will be cast to the type of
\code{x}.

When \code{x} is a list , \code{default} is allowed to be any value. There are no
type or size restrictions in this case.

\item[\code{na\_rm}] Should missing values in \code{x} be removed before extracting the
value?
\end{ldescription}
\end{Arguments}
%
\begin{Details}
For most vector types, \code{first(x)}, \code{last(x)}, and \code{nth(x, n)} work like
\code{x[[1]]}, \AsIs{\texttt{x[[length(x)]}}, and \code{x[[n]]}, respectively. The primary exception
is data frames, where they instead retrieve rows, i.e. \code{x[1, ]}, \code{x[nrow(x), ]}, and \code{x[n, ]}. This is consistent with the tidyverse/vctrs principle which
treats data frames as a vector of rows, rather than a vector of columns.
\end{Details}
%
\begin{Value}
If \code{x} is a list, a single element from that list. Otherwise, a vector the
same type as \code{x} with size 1.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
x <- 1:10
y <- 10:1

first(x)
last(y)

nth(x, 1)
nth(x, 5)
nth(x, -2)

# `first()` and `last()` are often useful in `summarise()`
df <- tibble(x = x, y = y)
df %>%
  summarise(
    across(x:y, first, .names = "{col}_first"),
    y_last = last(y)
  )

# Selecting a position that is out of bounds returns a default value
nth(x, 11)
nth(x, 0)

# This out of bounds behavior also applies to empty vectors
first(integer())

# You can customize the default value with `default`
nth(x, 11, default = -1L)
first(integer(), default = 0L)

# `order_by` provides optional ordering
last(x)
last(x, order_by = y)

# `na_rm` removes missing values before extracting the value
z <- c(NA, NA, 1, 3, NA, 5, NA)
first(z)
first(z, na_rm = TRUE)
last(z, na_rm = TRUE)
nth(z, 3, na_rm = TRUE)

# For data frames, these select entire rows
df <- tibble(a = 1:5, b = 6:10)
first(df)
nth(df, 4)
\end{ExampleCode}
\end{Examples}
\HeaderA{ntile}{Bucket a numeric vector into \code{n} groups}{ntile}
\keyword{ranking functions}{ntile}
%
\begin{Description}
\code{ntile()} is a sort of very rough rank, which breaks the input vector into
\code{n} buckets. If \code{length(x)} is not an integer multiple of \code{n}, the size of
the buckets will differ by up to one, with larger buckets coming first.

Unlike other ranking functions, \code{ntile()} ignores ties: it will create
evenly sized buckets even if the same value of \code{x} ends up in different
buckets.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ntile(x = row_number(), n)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A vector to rank

By default, the smallest values will get the smallest ranks. Use \code{\LinkA{desc()}{desc}}
to reverse the direction so the largest values get the smallest ranks.

Missing values will be given rank \code{NA}. Use \code{coalesce(x, Inf)} or
\code{coalesce(x, -Inf)} if you want to treat them as the largest or smallest
values respectively.

To rank by multiple columns at once, supply a data frame.

\item[\code{n}] Number of groups to bucket into
\end{ldescription}
\end{Arguments}
%
\begin{SeeAlso}
Other ranking functions: 
\code{\LinkA{percent\_rank}{percent.Rul.rank}()},
\code{\LinkA{row\_number}{row.Rul.number}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x <- c(5, 1, 3, 2, 2, NA)
ntile(x, 2)
ntile(x, 4)

# If the bucket sizes are uneven, the larger buckets come first
ntile(1:8, 3)

# Ties are ignored
ntile(rep(1, 8), 3)
\end{ExampleCode}
\end{Examples}
\HeaderA{n\_distinct}{Count unique combinations}{n.Rul.distinct}
%
\begin{Description}
\code{n\_distinct()} counts the number of unique/distinct combinations in a set
of one or more vectors. It's a faster and more concise equivalent to
\code{nrow(unique(data.frame(...)))}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
n_distinct(..., na.rm = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] Unnamed vectors. If multiple vectors are supplied, then they should
have the same length.

\item[\code{na.rm}] If \code{TRUE}, exclude missing observations from the count.
If there are multiple vectors in \code{...}, an observation will
be excluded if \emph{any} of the values are missing.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A single number.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
x <- c(1, 1, 2, 2, 2)
n_distinct(x)

y <- c(3, 3, NA, 3, 3)
n_distinct(y)
n_distinct(y, na.rm = TRUE)

# Pairs (1, 3), (2, 3), and (2, NA) are distinct
n_distinct(x, y)

# (2, NA) is dropped, leaving 2 distinct combinations
n_distinct(x, y, na.rm = TRUE)

# Also works with data frames
n_distinct(data.frame(x, y))
\end{ExampleCode}
\end{Examples}
\HeaderA{order\_by}{A helper function for ordering window function output}{order.Rul.by}
%
\begin{Description}
This function makes it possible to control the ordering of window functions
in R that don't have a specific ordering parameter. When translated to SQL
it will modify the order clause of the OVER function.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
order_by(order_by, call)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{order\_by}] a vector to order\_by

\item[\code{call}] a function call to a window function, where the first argument
is the vector being operated on
\end{ldescription}
\end{Arguments}
%
\begin{Details}
This function works by changing the \code{call} to instead call
\code{\LinkA{with\_order()}{with.Rul.order}} with the appropriate arguments.
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
order_by(10:1, cumsum(1:10))
x <- 10:1
y <- 1:10
order_by(x, cumsum(y))

df <- data.frame(year = 2000:2005, value = (0:5) ^ 2)
scrambled <- df[sample(nrow(df)), ]

wrong <- mutate(scrambled, running = cumsum(value))
arrange(wrong, year)

right <- mutate(scrambled, running = order_by(year, cumsum(value)))
arrange(right, year)
\end{ExampleCode}
\end{Examples}
\HeaderA{percent\_rank}{Proportional ranking functions}{percent.Rul.rank}
\aliasA{cume\_dist}{percent\_rank}{cume.Rul.dist}
\keyword{ranking functions}{percent\_rank}
%
\begin{Description}
These two ranking functions implement two slightly different ways to
compute a percentile. For each \code{x\_i} in \code{x}:
\begin{itemize}

\item{} \code{cume\_dist(x)} counts the total number of values less than
or equal to \code{x\_i}, and divides it by the number of observations.
\item{} \code{percent\_rank(x)} counts the total number of values less than
\code{x\_i}, and divides it by the number of observations minus 1.

\end{itemize}


In both cases, missing values are ignored when counting the number
of observations.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
percent_rank(x)

cume_dist(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A vector to rank

By default, the smallest values will get the smallest ranks. Use \code{\LinkA{desc()}{desc}}
to reverse the direction so the largest values get the smallest ranks.

Missing values will be given rank \code{NA}. Use \code{coalesce(x, Inf)} or
\code{coalesce(x, -Inf)} if you want to treat them as the largest or smallest
values respectively.

To rank by multiple columns at once, supply a data frame.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A numeric vector containing a proportion.
\end{Value}
%
\begin{SeeAlso}
Other ranking functions: 
\code{\LinkA{ntile}{ntile}()},
\code{\LinkA{row\_number}{row.Rul.number}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x <- c(5, 1, 3, 2, 2)

cume_dist(x)
percent_rank(x)

# You can understand what's going on by computing it by hand
sapply(x, function(xi) sum(x <= xi) / length(x))
sapply(x, function(xi) sum(x < xi)  / (length(x) - 1))
# The real computations are a little more complex in order to
# correctly deal with missing values
\end{ExampleCode}
\end{Examples}
\HeaderA{pick}{Select a subset of columns}{pick}
%
\begin{Description}
\code{pick()} provides a way to easily select a subset of columns from your data
using \code{\LinkA{select()}{select}} semantics while inside a
\LinkA{"data-masking"}{"data.Rdash.masking"} function like \code{\LinkA{mutate()}{mutate}} or
\code{\LinkA{summarise()}{summarise}}. \code{pick()} returns a data frame containing the selected columns
for the current group.

\code{pick()} is complementary to \code{\LinkA{across()}{across}}:
\begin{itemize}

\item{} With \code{pick()}, you typically apply a function to the full data frame.
\item{} With \code{across()}, you typically apply a function to each column.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
pick(...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}>

Columns to pick.

You can't pick grouping columns because they are already automatically
handled by the verb (i.e. \code{\LinkA{summarise()}{summarise}} or \code{\LinkA{mutate()}{mutate}}).
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Theoretically, \code{pick()} is intended to be replaceable with an equivalent call
to \code{tibble()}. For example, \code{pick(a, c)} could be replaced with
\code{tibble(a = a, c = c)}, and \code{pick(everything())} on a data frame with cols
\code{a}, \code{b}, and \code{c} could be replaced with \code{tibble(a = a, b = b, c = c)}.
\code{pick()} specially handles the case of an empty selection by returning a 1
row, 0 column tibble, so an exact replacement is more like:

\begin{alltt}size <- vctrs::vec_size_common(..., .absent = 1L)
out <- vctrs::vec_recycle_common(..., .size = size)
tibble::new_tibble(out, nrow = size)
\end{alltt}

\end{Details}
%
\begin{Value}
A tibble containing the selected columns for the current group.
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{across()}{across}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(
  x = c(3, 2, 2, 2, 1),
  y = c(0, 2, 1, 1, 4),
  z1 = c("a", "a", "a", "b", "a"),
  z2 = c("c", "d", "d", "a", "c")
)
df

# `pick()` provides a way to select a subset of your columns using
# tidyselect. It returns a data frame.
df %>% mutate(cols = pick(x, y))

# This is useful for functions that take data frames as inputs.
# For example, you can compute a joint rank between `x` and `y`.
df %>% mutate(rank = dense_rank(pick(x, y)))

# `pick()` is also useful as a bridge between data-masking functions (like
# `mutate()` or `group_by()`) and functions with tidy-select behavior (like
# `select()`). For example, you can use `pick()` to create a wrapper around
# `group_by()` that takes a tidy-selection of columns to group on. For more
# bridge patterns, see
# https://rlang.r-lib.org/reference/topic-data-mask-programming.html#bridge-patterns.
my_group_by <- function(data, cols) {
  group_by(data, pick({{ cols }}))
}

df %>% my_group_by(c(x, starts_with("z")))

# Or you can use it to dynamically select columns to `count()` by
df %>% count(pick(starts_with("z")))
\end{ExampleCode}
\end{Examples}
\HeaderA{progress\_estimated}{Progress bar with estimated time.}{progress.Rul.estimated}
\keyword{internal}{progress\_estimated}
%
\begin{Description}
\strong{[Deprecated]}

This progress bar has been deprecated since providing progress bars is not
the responsibility of dplyr. Instead, you might try the more powerful
\Rhref{https://github.com/r-lib/progress}{progress} package.

This reference class represents a text progress bar displayed estimated
time remaining. When finished, it displays the total duration.  The
automatic progress bar can be disabled by setting option
\code{dplyr.show\_progress} to \code{FALSE}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
progress_estimated(n, min_time = 0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n}] Total number of items

\item[\code{min\_time}] Progress bar will wait until at least \code{min\_time}
seconds have elapsed before displaying any results.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A ref class with methods \code{tick()}, \code{print()},
\code{pause()}, and \code{stop()}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
p <- progress_estimated(3)
p$tick()
p$tick()
p$tick()

p <- progress_estimated(3)
for (i in 1:3) p$pause(0.1)$tick()$print()

p <- progress_estimated(3)
p$tick()$print()$
 pause(1)$stop()

# If min_time is set, progress bar not shown until that many
# seconds have elapsed
p <- progress_estimated(3, min_time = 3)
for (i in 1:3) p$pause(0.1)$tick()$print()

## Not run: 
p <- progress_estimated(10, min_time = 3)
for (i in 1:10) p$pause(0.5)$tick()$print()

## End(Not run)
\end{ExampleCode}
\end{Examples}
\HeaderA{pull}{Extract a single column}{pull}
%
\begin{Description}
\code{pull()} is similar to \code{\$}. It's mostly useful because it looks a little
nicer in pipes, it also works with remote data frames, and it can optionally
name the output.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
pull(.data, var = -1, name = NULL, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{var}] A variable specified as:
\begin{itemize}

\item{} a literal variable name
\item{} a positive integer, giving the position counting from the left
\item{} a negative integer, giving the position counting from the right.

\end{itemize}


The default returns the last column (on the assumption that's the
column you've created most recently).

This argument is taken by expression and supports
\LinkA{quasiquotation}{quasiquotation} (you can unquote column
names and column locations).

\item[\code{name}] An optional parameter that specifies the column to be used
as names for a named vector. Specified in a similar manner as \code{var}.

\item[\code{...}] For use by methods.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector the same size as \code{.data}.
\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
mtcars %>% pull(-1)
mtcars %>% pull(1)
mtcars %>% pull(cyl)


# Also works for remote sources
df <- dbplyr::memdb_frame(x = 1:10, y = 10:1, .name = "pull-ex")
df %>%
  mutate(z = x * y) %>%
  pull()


# Pull a named vector
starwars %>% pull(height, name)
\end{ExampleCode}
\end{Examples}
\HeaderA{recode}{Recode values}{recode}
\aliasA{recode\_factor}{recode}{recode.Rul.factor}
%
\begin{Description}
\strong{[Superseded]}

\code{recode()} is superseded in favor of \code{\LinkA{case\_match()}{case.Rul.match}}, which handles the most
important cases of \code{recode()} with a more elegant interface.
\code{recode\_factor()} is also superseded, however, its direct replacement is not
currently available but will eventually live in
\Rhref{https://forcats.tidyverse.org/}{forcats}. For creating new variables based
on logical vectors, use \code{\LinkA{if\_else()}{if.Rul.else}}. For even more complicated criteria, use
\code{\LinkA{case\_when()}{case.Rul.when}}.

\code{recode()} is a vectorised version of \code{\LinkA{switch()}{switch}}: you can replace numeric
values based on their position or their name, and character or factor values
only by their name. This is an S3 generic: dplyr provides methods for
numeric, character, and factors. You can use \code{recode()} directly with
factors; it will preserve the existing order of levels while changing the
values. Alternatively, you can use \code{recode\_factor()}, which will change the
order of levels to match the order of replacements.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
recode(.x, ..., .default = NULL, .missing = NULL)

recode_factor(.x, ..., .default = NULL, .missing = NULL, .ordered = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.x}] A vector to modify

\item[\code{...}] <\code{\LinkA{dynamic-dots}{dynamic.Rdash.dots}}> Replacements. For character and factor \code{.x}, these should be named
and replacement is based only on their name. For numeric \code{.x}, these can be
named or not. If not named, the replacement is done based on position i.e.
\code{.x} represents positions to look for in replacements. See examples.

When named, the argument names should be the current values to be replaced, and the
argument values should be the new (replacement) values.

All replacements must be the same type, and must have either
length one or the same length as \code{.x}.

\item[\code{.default}] If supplied, all values not otherwise matched will
be given this value. If not supplied and if the replacements are
the same type as the original values in \code{.x}, unmatched
values are not changed. If not supplied and if the replacements
are not compatible, unmatched values are replaced with \code{NA}.

\code{.default} must be either length 1 or the same length as
\code{.x}.

\item[\code{.missing}] If supplied, any missing values in \code{.x} will be
replaced by this value. Must be either length 1 or the same length as
\code{.x}.

\item[\code{.ordered}] If \code{TRUE}, \code{recode\_factor()} creates an
ordered factor.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A vector the same length as \code{.x}, and the same type as
the first of \code{...}, \code{.default}, or \code{.missing}.
\code{recode\_factor()} returns a factor whose levels are in the same order as
in \code{...}. The levels in \code{.default} and \code{.missing} come last.
\end{Value}
%
\begin{SeeAlso}
\code{\LinkA{na\_if()}{na.Rul.if}} to replace specified values with a \code{NA}.

\code{\LinkA{coalesce()}{coalesce}} to replace missing values with a specified value.

\code{\LinkA{tidyr::replace\_na()}{tidyr::replace.Rul.na()}} to replace \code{NA} with a value.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
char_vec <- sample(c("a", "b", "c"), 10, replace = TRUE)

# `recode()` is superseded by `case_match()`
recode(char_vec, a = "Apple", b = "Banana")
case_match(char_vec, "a" ~ "Apple", "b" ~ "Banana", .default = char_vec)

# With `case_match()`, you don't need typed missings like `NA_character_`
recode(char_vec, a = "Apple", b = "Banana", .default = NA_character_)
case_match(char_vec, "a" ~ "Apple", "b" ~ "Banana", .default = NA)

# Throws an error as `NA` is logical, not character.
try(recode(char_vec, a = "Apple", b = "Banana", .default = NA))

# `case_match()` is easier to use with numeric vectors, because you don't
# need to turn the numeric values into names
num_vec <- c(1:4, NA)
recode(num_vec, `2` = 20L, `4` = 40L)
case_match(num_vec, 2 ~ 20, 4 ~ 40, .default = num_vec)

# `case_match()` doesn't have the ability to match by position like
# `recode()` does with numeric vectors
recode(num_vec, "a", "b", "c", "d")
recode(c(1,5,3), "a", "b", "c", "d", .default = "nothing")

# For `case_match()`, incompatible types are an error rather than a warning
recode(num_vec, `2` = "b", `4` = "d")
try(case_match(num_vec, 2 ~ "b", 4 ~ "d", .default = num_vec))

# The factor method of `recode()` can generally be replaced with
# `forcats::fct_recode()`
factor_vec <- factor(c("a", "b", "c"))
recode(factor_vec, a = "Apple")

# `recode_factor()` does not currently have a direct replacement, but we
# plan to add one to forcats. In the meantime, you can use the `.ptype`
# argument to `case_match()`.
recode_factor(
  num_vec,
  `1` = "z",
  `2` = "y",
  `3` = "x",
  .default = "D",
  .missing = "M"
)
case_match(
  num_vec,
  1 ~ "z",
  2 ~ "y",
  3 ~ "x",
  NA ~ "M",
  .default = "D",
  .ptype = factor(levels = c("z", "y", "x", "D", "M"))
)
\end{ExampleCode}
\end{Examples}
\HeaderA{reexports}{Objects exported from other packages}{reexports}
\aliasA{\%>\%}{reexports}{.Rpcent.>.Rpcent.}
\aliasA{add\_row}{reexports}{add.Rul.row}
\aliasA{all\_of}{reexports}{all.Rul.of}
\aliasA{any\_of}{reexports}{any.Rul.of}
\aliasA{as\_data\_frame}{reexports}{as.Rul.data.Rul.frame}
\aliasA{as\_tibble}{reexports}{as.Rul.tibble}
\aliasA{contains}{reexports}{contains}
\aliasA{data\_frame}{reexports}{data.Rul.frame}
\aliasA{ends\_with}{reexports}{ends.Rul.with}
\aliasA{everything}{reexports}{everything}
\aliasA{last\_col}{reexports}{last.Rul.col}
\aliasA{lst}{reexports}{lst}
\aliasA{matches}{reexports}{matches}
\aliasA{num\_range}{reexports}{num.Rul.range}
\aliasA{one\_of}{reexports}{one.Rul.of}
\aliasA{select\_helpers}{reexports}{select.Rul.helpers}
\aliasA{starts\_with}{reexports}{starts.Rul.with}
\aliasA{tibble}{reexports}{tibble}
\aliasA{tribble}{reexports}{tribble}
\aliasA{type\_sum}{reexports}{type.Rul.sum}
\aliasA{view}{reexports}{view}
\aliasA{where}{reexports}{where}
\keyword{internal}{reexports}
%
\begin{Description}
These objects are imported from other packages. Follow the links
below to see their documentation.

\begin{description}

\item[magrittr] \code{\LinkA{\Rpercent{}>\Rpercent{}}{.Rpcent.>.Rpcent.}}

\item[pillar] \code{\LinkA{type\_sum}{type.Rul.sum}}

\item[tibble] \code{\LinkA{add\_row}{add.Rul.row}}, \code{\LinkA{as\_data\_frame}{as.Rul.data.Rul.frame}}, \code{\LinkA{as\_tibble}{as.Rul.tibble}}, \code{\LinkA{data\_frame}{data.Rul.frame}}, \code{\LinkA{lst}{lst}}, \code{\LinkA{tibble}{tibble}}, \code{\LinkA{tribble}{tribble}}, \code{\LinkA{view}{view}}

\item[tidyselect] \code{\LinkA{all\_of}{all.Rul.of}}, \code{\LinkA{any\_of}{any.Rul.of}}, \code{\LinkA{contains}{contains}}, \code{\LinkA{ends\_with}{ends.Rul.with}}, \code{\LinkA{everything}{everything}}, \code{\LinkA{last\_col}{last.Rul.col}}, \code{\LinkA{matches}{matches}}, \code{\LinkA{num\_range}{num.Rul.range}}, \code{\LinkA{one\_of}{one.Rul.of}}, \code{\LinkA{starts\_with}{starts.Rul.with}}, \code{\LinkA{where}{where}}

\end{description}
\end{Description}
\HeaderA{reframe}{Transform each group to an arbitrary number of rows}{reframe}
\keyword{single table verbs}{reframe}
%
\begin{Description}
\strong{[Experimental]}

While \code{\LinkA{summarise()}{summarise}} requires that each argument returns a single value, and
\code{\LinkA{mutate()}{mutate}} requires that each argument returns the same number of rows as the
input, \code{reframe()} is a more general workhorse with no requirements on the
number of rows returned per group.

\code{reframe()} creates a new data frame by applying functions to columns of an
existing data frame. It is most similar to \code{summarise()}, with two big
differences:
\begin{itemize}

\item{} \code{reframe()} can return an arbitrary number of rows per group, while
\code{summarise()} reduces each group down to a single row.
\item{} \code{reframe()} always returns an ungrouped data frame, while \code{summarise()}
might return a grouped or rowwise data frame, depending on the scenario.

\end{itemize}


We expect that you'll use \code{summarise()} much more often than \code{reframe()}, but
\code{reframe()} can be particularly helpful when you need to apply a complex
function that doesn't return a single summary value.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
reframe(.data, ..., .by = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}>

Name-value pairs of functions. The name will be the name of the variable in
the result. The value can be a vector of any length.

Unnamed data frame values add multiple columns from a single expression.

\item[\code{.by}] \strong{[Experimental]}

<\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Optionally, a selection of columns to
group by for just this operation, functioning as an alternative to \code{\LinkA{group\_by()}{group.Rul.by}}. For
details and examples, see \LinkA{?dplyr\_by}{dplyr.Rul.by}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
If \code{.data} is a tibble, a tibble. Otherwise, a data.frame.
\begin{itemize}

\item{} The rows originate from the underlying grouping keys.
\item{} The columns are a combination of the grouping keys and the
expressions that you provide.
\item{} The output is always ungrouped.
\item{} Data frame attributes are \strong{not} preserved, because \code{reframe()}
fundamentally creates a new data frame.

\end{itemize}

\end{Value}
%
\begin{Section}{Connection to tibble}

\code{reframe()} is theoretically connected to two functions in tibble,
\code{\LinkA{tibble::enframe()}{tibble::enframe()}} and \code{\LinkA{tibble::deframe()}{tibble::deframe()}}:
\begin{itemize}

\item{} \code{enframe()}: vector -> data frame
\item{} \code{deframe()}: data frame -> vector
\item{} \code{reframe()}: data frame -> data frame

\end{itemize}

\end{Section}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{arrange}{arrange}()},
\code{\LinkA{filter}{filter}()},
\code{\LinkA{mutate}{mutate}()},
\code{\LinkA{rename}{rename}()},
\code{\LinkA{select}{select}()},
\code{\LinkA{slice}{slice}()},
\code{\LinkA{summarise}{summarise}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
table <- c("a", "b", "d", "f")

df <- tibble(
  g = c(1, 1, 1, 2, 2, 2, 2),
  x = c("e", "a", "b", "c", "f", "d", "a")
)

# `reframe()` allows you to apply functions that return
# an arbitrary number of rows
df %>%
  reframe(x = intersect(x, table))

# Functions are applied per group, and each group can return a
# different number of rows.
df %>%
  reframe(x = intersect(x, table), .by = g)

# The output is always ungrouped, even when using `group_by()`
df %>%
  group_by(g) %>%
  reframe(x = intersect(x, table))

# You can add multiple columns at once using a single expression by returning
# a data frame.
quantile_df <- function(x, probs = c(0.25, 0.5, 0.75)) {
  tibble(
    val = quantile(x, probs, na.rm = TRUE),
    quant = probs
  )
}

x <- c(10, 15, 18, 12)
quantile_df(x)

starwars %>%
  reframe(quantile_df(height))

starwars %>%
  reframe(quantile_df(height), .by = homeworld)

starwars %>%
  reframe(
    across(c(height, mass), quantile_df, .unpack = TRUE),
    .by = homeworld
  )
\end{ExampleCode}
\end{Examples}
\HeaderA{relocate}{Change column order}{relocate}
%
\begin{Description}
Use \code{relocate()} to change column positions, using the same syntax as
\code{select()} to make it easy to move blocks of columns at once.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
relocate(.data, ..., .before = NULL, .after = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Columns to move.

\item[\code{.before}, \code{.after}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Destination of
columns selected by \code{...}. Supplying neither will move columns to the
left-hand side; specifying both is an error.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} Rows are not affected.
\item{} The same columns appear in the output, but (usually) in a different place
and possibly renamed.
\item{} Data frame attributes are preserved.
\item{} Groups are not affected.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(a = 1, b = 1, c = 1, d = "a", e = "a", f = "a")
df %>% relocate(f)
df %>% relocate(a, .after = c)
df %>% relocate(f, .before = b)
df %>% relocate(a, .after = last_col())

# relocated columns can change name
df %>% relocate(ff = f)

# Can also select variables based on their type
df %>% relocate(where(is.character))
df %>% relocate(where(is.numeric), .after = last_col())
# Or with any other select helper
df %>% relocate(any_of(c("a", "e", "i", "o", "u")))

# When .before or .after refers to multiple variables they will be
# moved to be immediately before/after the selected variables.
df2 <- tibble(a = 1, b = "a", c = 1, d = "a")
df2 %>% relocate(where(is.numeric), .after = where(is.character))
df2 %>% relocate(where(is.numeric), .before = where(is.character))
\end{ExampleCode}
\end{Examples}
\HeaderA{rename}{Rename columns}{rename}
\aliasA{rename\_with}{rename}{rename.Rul.with}
\keyword{single table verbs}{rename}
%
\begin{Description}
\code{rename()} changes the names of individual variables using
\code{new\_name = old\_name} syntax; \code{rename\_with()} renames columns using a
function.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
rename(.data, ...)

rename_with(.data, .fn, .cols = everything(), ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] For \code{rename()}: <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Use
\code{new\_name = old\_name} to rename selected variables.

For \code{rename\_with()}: additional arguments passed onto \code{.fn}.

\item[\code{.fn}] A function used to transform the selected \code{.cols}. Should
return a character vector the same length as the input.

\item[\code{.cols}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Columns to rename;
defaults to all columns.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} Rows are not affected.
\item{} Column names are changed; column order is preserved.
\item{} Data frame attributes are preserved.
\item{} Groups are updated to reflect new names.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{arrange}{arrange}()},
\code{\LinkA{filter}{filter}()},
\code{\LinkA{mutate}{mutate}()},
\code{\LinkA{reframe}{reframe}()},
\code{\LinkA{select}{select}()},
\code{\LinkA{slice}{slice}()},
\code{\LinkA{summarise}{summarise}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
iris <- as_tibble(iris) # so it prints a little nicer
rename(iris, petal_length = Petal.Length)

# Rename using a named vector and `all_of()`
lookup <- c(pl = "Petal.Length", sl = "Sepal.Length")
rename(iris, all_of(lookup))

# If your named vector might contain names that don't exist in the data,
# use `any_of()` instead
lookup <- c(lookup, new = "unknown")
try(rename(iris, all_of(lookup)))
rename(iris, any_of(lookup))

rename_with(iris, toupper)
rename_with(iris, toupper, starts_with("Petal"))
rename_with(iris, ~ tolower(gsub(".", "_", .x, fixed = TRUE)))


# If your renaming function uses `paste0()`, make sure to set
# `recycle0 = TRUE` to ensure that empty selections are recycled correctly
try(rename_with(
  iris,
  ~ paste0("prefix_", .x),
  starts_with("nonexistent")
))

rename_with(
  iris,
  ~ paste0("prefix_", .x, recycle0 = TRUE),
  starts_with("nonexistent")
)

\end{ExampleCode}
\end{Examples}
\HeaderA{rows}{Manipulate individual rows}{rows}
\aliasA{rows\_append}{rows}{rows.Rul.append}
\aliasA{rows\_delete}{rows}{rows.Rul.delete}
\aliasA{rows\_insert}{rows}{rows.Rul.insert}
\aliasA{rows\_patch}{rows}{rows.Rul.patch}
\aliasA{rows\_update}{rows}{rows.Rul.update}
\aliasA{rows\_upsert}{rows}{rows.Rul.upsert}
%
\begin{Description}
These functions provide a framework for modifying rows in a table using a
second table of data. The two tables are matched \code{by} a set of key variables
whose values typically uniquely identify each row. The functions are inspired
by SQL's \code{INSERT}, \code{UPDATE}, and \code{DELETE}, and can optionally modify
\code{in\_place} for selected backends.
\begin{itemize}

\item{} \code{rows\_insert()} adds new rows (like \code{INSERT}). By default, key values in
\code{y} must not exist in \code{x}.
\item{} \code{rows\_append()} works like \code{rows\_insert()} but ignores keys.
\item{} \code{rows\_update()} modifies existing rows (like \code{UPDATE}). Key values in \code{y}
must be unique, and, by default, key values in \code{y} must exist in \code{x}.
\item{} \code{rows\_patch()} works like \code{rows\_update()} but only overwrites \code{NA} values.
\item{} \code{rows\_upsert()} inserts or updates depending on whether or not the
key value in \code{y} already exists in \code{x}. Key values in \code{y} must be unique.
\item{} \code{rows\_delete()} deletes rows (like \code{DELETE}). By default, key values in \code{y}
must exist in \code{x}.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
rows_insert(
  x,
  y,
  by = NULL,
  ...,
  conflict = c("error", "ignore"),
  copy = FALSE,
  in_place = FALSE
)

rows_append(x, y, ..., copy = FALSE, in_place = FALSE)

rows_update(
  x,
  y,
  by = NULL,
  ...,
  unmatched = c("error", "ignore"),
  copy = FALSE,
  in_place = FALSE
)

rows_patch(
  x,
  y,
  by = NULL,
  ...,
  unmatched = c("error", "ignore"),
  copy = FALSE,
  in_place = FALSE
)

rows_upsert(x, y, by = NULL, ..., copy = FALSE, in_place = FALSE)

rows_delete(
  x,
  y,
  by = NULL,
  ...,
  unmatched = c("error", "ignore"),
  copy = FALSE,
  in_place = FALSE
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] A pair of data frames or data frame extensions (e.g. a tibble).
\code{y} must have the same columns of \code{x} or a subset.

\item[\code{by}] An unnamed character vector giving the key columns. The key columns
must exist in both \code{x} and \code{y}. Keys typically uniquely identify each row,
but this is only enforced for the key values of \code{y} when \code{rows\_update()},
\code{rows\_patch()}, or \code{rows\_upsert()} are used.

By default, we use the first column in \code{y}, since the first column is
a reasonable place to put an identifier variable.

\item[\code{...}] Other parameters passed onto methods.

\item[\code{conflict}] For \code{rows\_insert()}, how should keys in \code{y} that conflict
with keys in \code{x} be handled? A conflict arises if there is a key in \code{y}
that already exists in \code{x}.

One of:
\begin{itemize}

\item{} \code{"error"}, the default, will error if there are any keys in \code{y} that
conflict with keys in \code{x}.
\item{} \code{"ignore"} will ignore rows in \code{y} with keys that conflict with keys in
\code{x}.

\end{itemize}


\item[\code{copy}] If \code{x} and \code{y} are not from the same data source,
and \code{copy} is \code{TRUE}, then \code{y} will be copied into the
same src as \code{x}.  This allows you to join tables across srcs, but
it is a potentially expensive operation so you must opt into it.

\item[\code{in\_place}] Should \code{x} be modified in place? This argument is only
relevant for mutable backends (e.g. databases, data.tables).

When \code{TRUE}, a modified version of \code{x} is returned invisibly;
when \code{FALSE}, a new object representing the resulting changes is returned.

\item[\code{unmatched}] For \code{rows\_update()}, \code{rows\_patch()}, and \code{rows\_delete()},
how should keys in \code{y} that are unmatched by the keys in \code{x} be handled?

One of:
\begin{itemize}

\item{} \code{"error"}, the default, will error if there are any keys in \code{y} that
are unmatched by the keys in \code{x}.
\item{} \code{"ignore"} will ignore rows in \code{y} with keys that are unmatched by the
keys in \code{x}.

\end{itemize}

\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{x}. The order of the rows and columns of \code{x}
is preserved as much as possible. The output has the following properties:
\begin{itemize}

\item{} \code{rows\_update()} and \code{rows\_patch()} preserve the number of rows;
\code{rows\_insert()}, \code{rows\_append()}, and \code{rows\_upsert()} return all existing
rows and potentially new rows; \code{rows\_delete()} returns a subset of the
rows.
\item{} Columns are not added, removed, or relocated, though the data may be
updated.
\item{} Groups are taken from \code{x}.
\item{} Data frame attributes are taken from \code{x}.

\end{itemize}


If \code{in\_place = TRUE}, the result will be returned invisibly.
\end{Value}
%
\begin{Section}{Methods}

These function are \strong{generic}s, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
\begin{itemize}

\item{} \code{rows\_insert()}: no methods found.
\item{} \code{rows\_append()}: no methods found.
\item{} \code{rows\_update()}: no methods found.
\item{} \code{rows\_patch()}: no methods found.
\item{} \code{rows\_upsert()}: no methods found.
\item{} \code{rows\_delete()}: no methods found.

\end{itemize}

\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
data <- tibble(a = 1:3, b = letters[c(1:2, NA)], c = 0.5 + 0:2)
data

# Insert
rows_insert(data, tibble(a = 4, b = "z"))

# By default, if a key in `y` matches a key in `x`, then it can't be inserted
# and will throw an error. Alternatively, you can ignore rows in `y`
# containing keys that conflict with keys in `x` with `conflict = "ignore"`,
# or you can use `rows_append()` to ignore keys entirely.
try(rows_insert(data, tibble(a = 3, b = "z")))
rows_insert(data, tibble(a = 3, b = "z"), conflict = "ignore")
rows_append(data, tibble(a = 3, b = "z"))

# Update
rows_update(data, tibble(a = 2:3, b = "z"))
rows_update(data, tibble(b = "z", a = 2:3), by = "a")

# Variants: patch and upsert
rows_patch(data, tibble(a = 2:3, b = "z"))
rows_upsert(data, tibble(a = 2:4, b = "z"))

# Delete and truncate
rows_delete(data, tibble(a = 2:3))
rows_delete(data, tibble(a = 2:3, b = "b"))

# By default, for update, patch, and delete it is an error if a key in `y`
# doesn't exist in `x`. You can ignore rows in `y` that have unmatched keys
# with `unmatched = "ignore"`.
y <- tibble(a = 3:4, b = "z")
try(rows_update(data, y, by = "a"))
rows_update(data, y, by = "a", unmatched = "ignore")
rows_patch(data, y, by = "a", unmatched = "ignore")
rows_delete(data, y, by = "a", unmatched = "ignore")
\end{ExampleCode}
\end{Examples}
\HeaderA{rowwise}{Group input by rows}{rowwise}
%
\begin{Description}
\code{rowwise()} allows you to compute on a data frame a row-at-a-time.
This is most useful when a vectorised function doesn't exist.

Most dplyr verbs preserve row-wise grouping. The exception is \code{\LinkA{summarise()}{summarise}},
which return a \LinkA{grouped\_df}{grouped.Rul.df}. You can explicitly ungroup with \code{\LinkA{ungroup()}{ungroup}}
or \code{\LinkA{as\_tibble()}{as.Rul.tibble}}, or convert to a \LinkA{grouped\_df}{grouped.Rul.df} with \code{\LinkA{group\_by()}{group.Rul.by}}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
rowwise(data, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] Input data frame.

\item[\code{...}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Variables to be preserved
when calling \code{\LinkA{summarise()}{summarise}}. This is typically a set of variables whose
combination uniquely identify each row.

\strong{NB}: unlike \code{group\_by()} you can not create new variables here but
instead you can select multiple variables with (e.g.) \code{everything()}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A row-wise data frame with class \code{rowwise\_df}. Note that a
\code{rowwise\_df} is implicitly grouped by row, but is not a \code{grouped\_df}.
\end{Value}
%
\begin{Section}{List-columns}

Because a rowwise has exactly one row per group it offers a small
convenience for working with list-columns. Normally, \code{summarise()} and
\code{mutate()} extract a groups worth of data with \code{[}. But when you index
a list in this way, you get back another list. When you're working with
a \code{rowwise} tibble, then dplyr will use \code{[[} instead of \code{[} to make your
life a little easier.
\end{Section}
%
\begin{SeeAlso}
\code{\LinkA{nest\_by()}{nest.Rul.by}} for a convenient way of creating rowwise data frames
with nested data.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(x = runif(6), y = runif(6), z = runif(6))
# Compute the mean of x, y, z in each row
df %>% rowwise() %>% mutate(m = mean(c(x, y, z)))
# use c_across() to more easily select many variables
df %>% rowwise() %>% mutate(m = mean(c_across(x:z)))

# Compute the minimum of x and y in each row
df %>% rowwise() %>% mutate(m = min(c(x, y, z)))
# In this case you can use an existing vectorised function:
df %>% mutate(m = pmin(x, y, z))
# Where these functions exist they'll be much faster than rowwise
# so be on the lookout for them.

# rowwise() is also useful when doing simulations
params <- tribble(
 ~sim, ~n, ~mean, ~sd,
    1,  1,     1,   1,
    2,  2,     2,   4,
    3,  3,    -1,   2
)
# Here I supply variables to preserve after the computation
params %>%
  rowwise(sim) %>%
  reframe(z = rnorm(n, mean, sd))

# If you want one row per simulation, put the results in a list()
params %>%
  rowwise(sim) %>%
  summarise(z = list(rnorm(n, mean, sd)), .groups = "keep")
\end{ExampleCode}
\end{Examples}
\HeaderA{row\_number}{Integer ranking functions}{row.Rul.number}
\aliasA{dense\_rank}{row\_number}{dense.Rul.rank}
\aliasA{min\_rank}{row\_number}{min.Rul.rank}
\keyword{ranking functions}{row\_number}
%
\begin{Description}
Three ranking functions inspired by SQL2003. They differ primarily in how
they handle ties:
\begin{itemize}

\item{} \code{row\_number()} gives every input a unique rank, so that \code{c(10, 20, 20, 30)}
would get ranks \code{c(1, 2, 3, 4)}. It's equivalent to
\code{rank(ties.method = "first")}.
\item{} \code{min\_rank()} gives every tie the same (smallest) value so that
\code{c(10, 20, 20, 30)} gets ranks \code{c(1, 2, 2, 4)}. It's the way that ranks
are usually computed in sports and is equivalent to
\code{rank(ties.method = "min")}.
\item{} \code{dense\_rank()} works like \code{min\_rank()}, but doesn't leave any gaps,
so that \code{c(10, 20, 20, 30)} gets ranks \code{c(1, 2, 2, 3)}.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
row_number(x)

min_rank(x)

dense_rank(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A vector to rank

By default, the smallest values will get the smallest ranks. Use \code{\LinkA{desc()}{desc}}
to reverse the direction so the largest values get the smallest ranks.

Missing values will be given rank \code{NA}. Use \code{coalesce(x, Inf)} or
\code{coalesce(x, -Inf)} if you want to treat them as the largest or smallest
values respectively.

To rank by multiple columns at once, supply a data frame.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An integer vector.
\end{Value}
%
\begin{SeeAlso}
Other ranking functions: 
\code{\LinkA{ntile}{ntile}()},
\code{\LinkA{percent\_rank}{percent.Rul.rank}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x <- c(5, 1, 3, 2, 2, NA)
row_number(x)
min_rank(x)
dense_rank(x)

# Ranking functions can be used in `filter()` to select top/bottom rows
df <- data.frame(
  grp = c(1, 1, 1, 2, 2, 2, 3, 3, 3),
  x = c(3, 2, 1, 1, 2, 2, 1, 1, 1),
  y = c(1, 3, 2, 3, 2, 2, 4, 1, 2),
  id = 1:9
)
# Always gives exactly 1 row per group
df %>% group_by(grp) %>% filter(row_number(x) == 1)
# May give more than 1 row if ties
df %>% group_by(grp) %>% filter(min_rank(x) == 1)
# Rank by multiple columns (to break ties) by selecting them with `pick()`
df %>% group_by(grp) %>% filter(min_rank(pick(x, y)) == 1)
# See slice_min() and slice_max() for another way to tackle the same problem

# You can use row_number() without an argument to refer to the "current"
# row number.
df %>% group_by(grp) %>% filter(row_number() == 1)

# It's easiest to see what this does with mutate():
df %>% group_by(grp) %>% mutate(grp_id = row_number())
\end{ExampleCode}
\end{Examples}
\HeaderA{same\_src}{Figure out if two sources are the same (or two tbl have the same source)}{same.Rul.src}
\keyword{internal}{same\_src}
%
\begin{Description}
Figure out if two sources are the same (or two tbl have the same source)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
same_src(x, y)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] src or tbls to test
\end{ldescription}
\end{Arguments}
%
\begin{Value}
a logical flag
\end{Value}
\HeaderA{sample\_n}{Sample n rows from a table}{sample.Rul.n}
\aliasA{sample\_frac}{sample\_n}{sample.Rul.frac}
\keyword{internal}{sample\_n}
%
\begin{Description}
\strong{[Superseded]}
\code{sample\_n()} and \code{sample\_frac()} have been superseded in favour of
\code{\LinkA{slice\_sample()}{slice.Rul.sample}}. While they will not be deprecated in the near future,
retirement means that we will only perform critical bug fixes, so we recommend
moving to the newer alternative.

These functions were superseded because we realised it was more convenient to
have two mutually exclusive arguments to one function, rather than two
separate functions. This also made it to clean up a few other smaller
design issues with \code{sample\_n()}/\code{sample\_frac}:
\begin{itemize}

\item{} The connection to \code{slice()} was not obvious.
\item{} The name of the first argument, \code{tbl}, is inconsistent with other
single table verbs which use \code{.data}.
\item{} The \code{size} argument uses tidy evaluation, which is surprising and
undocumented.
\item{} It was easier to remove the deprecated \code{.env} argument.
\item{} \code{...} was in a suboptimal position.

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
sample_n(tbl, size, replace = FALSE, weight = NULL, .env = NULL, ...)

sample_frac(tbl, size = 1, replace = FALSE, weight = NULL, .env = NULL, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{tbl}] A data.frame.

\item[\code{size}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}>
For \code{sample\_n()}, the number of rows to select.
For \code{sample\_frac()}, the fraction of rows to select.
If \code{tbl} is grouped, \code{size} applies to each group.

\item[\code{replace}] Sample with or without replacement?

\item[\code{weight}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Sampling weights.
This must evaluate to a vector of non-negative numbers the same length as
the input. Weights are automatically standardised to sum to 1.

\item[\code{.env}] DEPRECATED.

\item[\code{...}] ignored
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(x = 1:5, w = c(0.1, 0.1, 0.1, 2, 2))

# sample_n() -> slice_sample() ----------------------------------------------
# Was:
sample_n(df, 3)
sample_n(df, 10, replace = TRUE)
sample_n(df, 3, weight = w)

# Now:
slice_sample(df, n = 3)
slice_sample(df, n = 10, replace = TRUE)
slice_sample(df, n = 3, weight_by = w)

# Note that sample_n() would error if n was bigger than the group size
# slice_sample() will just use the available rows for consistency with
# the other slice helpers like slice_head()
try(sample_n(df, 10))
slice_sample(df, n = 10)

# sample_frac() -> slice_sample() -------------------------------------------
# Was:
sample_frac(df, 0.25)
sample_frac(df, 2, replace = TRUE)

# Now:
slice_sample(df, prop = 0.25)
slice_sample(df, prop = 2, replace = TRUE)
\end{ExampleCode}
\end{Examples}
\HeaderA{scoped}{Operate on a selection of variables}{scoped}
%
\begin{Description}
\strong{[Superseded]}

Scoped verbs (\AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}}, \AsIs{\texttt{\_all}}) have been superseded by the use of
\code{\LinkA{pick()}{pick}} or \code{\LinkA{across()}{across}} in an existing verb. See \code{vignette("colwise")} for
details.

The variants suffixed with \AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}} or \AsIs{\texttt{\_all}} apply an
expression (sometimes several) to all variables within a specified
subset. This subset can contain all variables (\AsIs{\texttt{\_all}} variants), a
\code{\LinkA{vars()}{vars}} selection (\AsIs{\texttt{\_at}} variants), or variables selected with a
predicate (\AsIs{\texttt{\_if}} variants).

The verbs with scoped variants are:
\begin{itemize}

\item{} \code{\LinkA{mutate()}{mutate}}, \code{\LinkA{transmute()}{transmute}} and \code{\LinkA{summarise()}{summarise}}. See \code{\LinkA{summarise\_all()}{summarise.Rul.all}}.
\item{} \code{\LinkA{filter()}{filter}}. See \code{\LinkA{filter\_all()}{filter.Rul.all}}.
\item{} \code{\LinkA{group\_by()}{group.Rul.by}}. See \code{\LinkA{group\_by\_all()}{group.Rul.by.Rul.all}}.
\item{} \code{\LinkA{rename()}{rename}} and \code{\LinkA{select()}{select}}. See \code{\LinkA{select\_all()}{select.Rul.all}}.
\item{} \code{\LinkA{arrange()}{arrange}}. See \code{\LinkA{arrange\_all()}{arrange.Rul.all}}

\end{itemize}


There are three kinds of scoped variants. They differ in the scope
of the variable selection on which operations are applied:
\begin{itemize}

\item{} Verbs suffixed with \AsIs{\texttt{\_all()}} apply an operation on all variables.
\item{} Verbs suffixed with \AsIs{\texttt{\_at()}} apply an operation on a subset of
variables specified with the quoting function \code{\LinkA{vars()}{vars}}. This
quoting function accepts \code{\LinkA{tidyselect::vars\_select()}{tidyselect::vars.Rul.select()}} helpers like
\code{\LinkA{starts\_with()}{starts.Rul.with}}. Instead of a \code{\LinkA{vars()}{vars}} selection, you can also
supply an \LinkA{integerish}{integerish} vector of column
positions or a character vector of column names.
\item{} Verbs suffixed with \AsIs{\texttt{\_if()}} apply an operation on the subset of
variables for which a predicate function returns \code{TRUE}. Instead
of a predicate function, you can also supply a logical vector.

\end{itemize}

\end{Description}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.funs}] A function \code{fun}, a quosure style lambda \code{\textasciitilde{} fun(.)} or a list of either form.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.

\item[\code{...}] Additional arguments for the function calls in
\code{.funs}. These are evaluated only once, with \LinkA{tidy dots}{tidy dots} support.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Grouping variables}


Most of these operations also apply on the grouping variables when
they are part of the selection. This includes:
\begin{itemize}

\item{} \code{\LinkA{arrange\_all()}{arrange.Rul.all}}, \code{\LinkA{arrange\_at()}{arrange.Rul.at}}, and \code{\LinkA{arrange\_if()}{arrange.Rul.if}}
\item{} \code{\LinkA{distinct\_all()}{distinct.Rul.all}}, \code{\LinkA{distinct\_at()}{distinct.Rul.at}}, and \code{\LinkA{distinct\_if()}{distinct.Rul.if}}
\item{} \code{\LinkA{filter\_all()}{filter.Rul.all}}, \code{\LinkA{filter\_at()}{filter.Rul.at}}, and \code{\LinkA{filter\_if()}{filter.Rul.if}}
\item{} \code{\LinkA{group\_by\_all()}{group.Rul.by.Rul.all}}, \code{\LinkA{group\_by\_at()}{group.Rul.by.Rul.at}}, and \code{\LinkA{group\_by\_if()}{group.Rul.by.Rul.if}}
\item{} \code{\LinkA{select\_all()}{select.Rul.all}}, \code{\LinkA{select\_at()}{select.Rul.at}}, and \code{\LinkA{select\_if()}{select.Rul.if}}

\end{itemize}


This is not the case for summarising and mutating variants where
operations are \emph{not} applied on grouping variables. The behaviour
depends on whether the selection is \strong{implicit} (\code{all} and \code{if}
selections) or \strong{explicit} (\code{at} selections). Grouping variables
covered by explicit selections (with \code{\LinkA{summarise\_at()}{summarise.Rul.at}},
\code{\LinkA{mutate\_at()}{mutate.Rul.at}}, and \code{\LinkA{transmute\_at()}{transmute.Rul.at}}) are always an error. For
implicit selections, the grouping variables are always ignored. In
this case, the level of verbosity depends on the kind of operation:
\begin{itemize}

\item{} Summarising operations (\code{\LinkA{summarise\_all()}{summarise.Rul.all}} and \code{\LinkA{summarise\_if()}{summarise.Rul.if}})
ignore grouping variables silently because it is obvious that
operations are not applied on grouping variables.
\item{} On the other hand it isn't as obvious in the case of mutating
operations (\code{\LinkA{mutate\_all()}{mutate.Rul.all}}, \code{\LinkA{mutate\_if()}{mutate.Rul.if}}, \code{\LinkA{transmute\_all()}{transmute.Rul.all}}, and
\code{\LinkA{transmute\_if()}{transmute.Rul.if}}). For this reason, they issue a message
indicating which grouping variables are ignored.

\end{itemize}

\end{Section}
\HeaderA{se-deprecated}{Deprecated SE versions of main verbs.}{se.Rdash.deprecated}
\aliasA{add\_count\_}{se-deprecated}{add.Rul.count.Rul.}
\aliasA{add\_tally\_}{se-deprecated}{add.Rul.tally.Rul.}
\aliasA{arrange\_}{se-deprecated}{arrange.Rul.}
\aliasA{count\_}{se-deprecated}{count.Rul.}
\aliasA{distinct\_}{se-deprecated}{distinct.Rul.}
\aliasA{do\_}{se-deprecated}{do.Rul.}
\aliasA{filter\_}{se-deprecated}{filter.Rul.}
\aliasA{funs\_}{se-deprecated}{funs.Rul.}
\aliasA{group\_by\_}{se-deprecated}{group.Rul.by.Rul.}
\aliasA{group\_indices\_}{se-deprecated}{group.Rul.indices.Rul.}
\aliasA{mutate\_}{se-deprecated}{mutate.Rul.}
\aliasA{rename\_}{se-deprecated}{rename.Rul.}
\aliasA{rename\_vars\_}{se-deprecated}{rename.Rul.vars.Rul.}
\aliasA{select\_}{se-deprecated}{select.Rul.}
\aliasA{select\_vars\_}{se-deprecated}{select.Rul.vars.Rul.}
\aliasA{slice\_}{se-deprecated}{slice.Rul.}
\aliasA{summarise\_}{se-deprecated}{summarise.Rul.}
\aliasA{summarize\_}{se-deprecated}{summarize.Rul.}
\aliasA{tally\_}{se-deprecated}{tally.Rul.}
\aliasA{transmute\_}{se-deprecated}{transmute.Rul.}
\keyword{internal}{se-deprecated}
%
\begin{Description}
\strong{[Deprecated]}

dplyr used to offer twin versions of each verb suffixed with an
underscore. These versions had standard evaluation (SE) semantics:
rather than taking arguments by code, like NSE verbs, they took
arguments by value. Their purpose was to make it possible to
program with dplyr. However, dplyr now uses tidy evaluation
semantics. NSE verbs still capture their arguments, but you can now
unquote parts of these arguments. This offers full programmability
with NSE verbs. Thus, the underscored versions are now superfluous.

Unquoting triggers immediate evaluation of its operand and inlines
the result within the captured expression. This result can be a
value or an expression to be evaluated later with the rest of the
argument. See \code{vignette("programming")} for more information.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
add_count_(x, vars, wt = NULL, sort = FALSE)

add_tally_(x, wt, sort = FALSE)

arrange_(.data, ..., .dots = list())

count_(x, vars, wt = NULL, sort = FALSE, .drop = group_by_drop_default(x))

distinct_(.data, ..., .dots, .keep_all = FALSE)

do_(.data, ..., .dots = list())

filter_(.data, ..., .dots = list())

funs_(dots, args = list(), env = base_env())

group_by_(.data, ..., .dots = list(), add = FALSE)

group_indices_(.data, ..., .dots = list())

mutate_(.data, ..., .dots = list())

tally_(x, wt, sort = FALSE)

transmute_(.data, ..., .dots = list())

rename_(.data, ..., .dots = list())

rename_vars_(vars, args)

select_(.data, ..., .dots = list())

select_vars_(vars, args, include = chr(), exclude = chr())

slice_(.data, ..., .dots = list())

summarise_(.data, ..., .dots = list())

summarize_(.data, ..., .dots = list())
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A \code{\LinkA{tbl()}{tbl}}

\item[\code{vars}] Various meanings depending on the verb.

\item[\code{wt}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Frequency weights.
Can be \code{NULL} or a variable:
\begin{itemize}

\item{} If \code{NULL} (the default), counts the number of rows in each group.
\item{} If a variable, computes \code{sum(wt)} for each group.

\end{itemize}


\item[\code{sort}] If \code{TRUE}, will show the largest groups at the top.

\item[\code{.data}] A data frame.

\item[\code{.drop}] Drop groups formed by factor levels that don't appear in the
data? The default is \code{TRUE} except when \code{.data} has been previously
grouped with \code{.drop = FALSE}. See \code{\LinkA{group\_by\_drop\_default()}{group.Rul.by.Rul.drop.Rul.default}} for details.

\item[\code{.keep\_all}] If \code{TRUE}, keep all variables in \code{.data}.
If a combination of \code{...} is not distinct, this keeps the
first row of values.

\item[\code{dots}, \code{.dots}, \code{...}] Pair/values of expressions coercible to lazy objects.

\item[\code{args}] Various meanings depending on the verb.

\item[\code{env}] The environment in which functions should be evaluated.

\item[\code{add}] When \code{FALSE}, the default, \code{group\_by()} will
override existing groups. To add to the existing groups, use
\code{.add = TRUE}.

This argument was previously called \code{add}, but that prevented
creating a new grouping variable called \code{add}, and conflicts with
our naming conventions.

\item[\code{include}, \code{exclude}] Character vector of column names to always
include/exclude.
\end{ldescription}
\end{Arguments}
\HeaderA{select}{Keep or drop columns using their names and types}{select}
\keyword{single table verbs}{select}
%
\begin{Description}
Select (and optionally rename) variables in a data frame, using a concise
mini-language that makes it easy to refer to variables based on their name
(e.g. \code{a:f} selects all columns from \code{a} on the left to \code{f} on the
right) or type (e.g. \code{where(is.numeric)} selects all numeric columns).
%
\begin{SubSection}{Overview of selection features}

Tidyverse selections implement a dialect of R where operators make
it easy to select variables:
\begin{itemize}

\item{} \code{:} for selecting a range of consecutive variables.
\item{} \code{!} for taking the complement of a set of variables.
\item{} \code{\&} and \code{|} for selecting the intersection or the union of two
sets of variables.
\item{} \code{c()} for combining selections.

\end{itemize}


In addition, you can use \strong{selection helpers}. Some helpers select specific
columns:
\begin{itemize}

\item{} \code{\LinkA{everything()}{everything()}}: Matches all variables.
\item{} \code{\LinkA{last\_col()}{last.Rul.col()}}: Select last variable, possibly with an offset.
\item{} \code{\LinkA{group\_cols()}{group.Rul.cols}}: Select all grouping columns.

\end{itemize}


Other helpers select variables by matching patterns in their names:
\begin{itemize}

\item{} \code{\LinkA{starts\_with()}{starts.Rul.with()}}: Starts with a prefix.
\item{} \code{\LinkA{ends\_with()}{ends.Rul.with()}}: Ends with a suffix.
\item{} \code{\LinkA{contains()}{contains()}}: Contains a literal string.
\item{} \code{\LinkA{matches()}{matches()}}: Matches a regular expression.
\item{} \code{\LinkA{num\_range()}{num.Rul.range()}}: Matches a numerical range like x01, x02, x03.

\end{itemize}


Or from variables stored in a character vector:
\begin{itemize}

\item{} \code{\LinkA{all\_of()}{all.Rul.of()}}: Matches variable names in a character vector. All
names must be present, otherwise an out-of-bounds error is
thrown.
\item{} \code{\LinkA{any\_of()}{any.Rul.of()}}: Same as \code{all\_of()}, except that no error is thrown
for names that don't exist.

\end{itemize}


Or using a predicate function:
\begin{itemize}

\item{} \code{\LinkA{where()}{where()}}: Applies a function to all variables and selects those
for which the function returns \code{TRUE}.

\end{itemize}

\end{SubSection}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
select(.data, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> One or more unquoted
expressions separated by commas. Variable names can be used as if they
were positions in the data frame, so expressions like \code{x:y} can
be used to select a range of variables.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} Rows are not affected.
\item{} Output columns are a subset of input columns, potentially with a different
order. Columns will be renamed if \code{new\_name = old\_name} form is used.
\item{} Data frame attributes are preserved.
\item{} Groups are maintained; you can't select off grouping variables.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{Section}{Examples}


Here we show the usage for the basic selection operators. See the
specific help pages to learn about helpers like \code{\LinkA{starts\_with()}{starts.Rul.with}}.

The selection language can be used in functions like
\code{dplyr::select()} or \code{tidyr::pivot\_longer()}. Let's first attach
the tidyverse:

\begin{alltt}library(tidyverse)

# For better printing
iris <- as_tibble(iris)
\end{alltt}


Select variables by name:

\begin{alltt}starwars %>% select(height)
#> # A tibble: 87 x 1
#>   height
#>    <int>
#> 1    172
#> 2    167
#> 3     96
#> 4    202
#> # i 83 more rows

iris %>% pivot_longer(Sepal.Length)
#> # A tibble: 150 x 6
#>   Sepal.Width Petal.Length Petal.Width Species name         value
#>         <dbl>        <dbl>       <dbl> <fct>   <chr>        <dbl>
#> 1         3.5          1.4         0.2 setosa  Sepal.Length   5.1
#> 2         3            1.4         0.2 setosa  Sepal.Length   4.9
#> 3         3.2          1.3         0.2 setosa  Sepal.Length   4.7
#> 4         3.1          1.5         0.2 setosa  Sepal.Length   4.6
#> # i 146 more rows
\end{alltt}


Select multiple variables by separating them with commas. Note how
the order of columns is determined by the order of inputs:

\begin{alltt}starwars %>% select(homeworld, height, mass)
#> # A tibble: 87 x 3
#>   homeworld height  mass
#>   <chr>      <int> <dbl>
#> 1 Tatooine     172    77
#> 2 Tatooine     167    75
#> 3 Naboo         96    32
#> 4 Tatooine     202   136
#> # i 83 more rows
\end{alltt}


Functions like \code{tidyr::pivot\_longer()} don't take variables with
dots. In this case use \code{c()} to select multiple variables:

\begin{alltt}iris %>% pivot_longer(c(Sepal.Length, Petal.Length))
#> # A tibble: 300 x 5
#>   Sepal.Width Petal.Width Species name         value
#>         <dbl>       <dbl> <fct>   <chr>        <dbl>
#> 1         3.5         0.2 setosa  Sepal.Length   5.1
#> 2         3.5         0.2 setosa  Petal.Length   1.4
#> 3         3           0.2 setosa  Sepal.Length   4.9
#> 4         3           0.2 setosa  Petal.Length   1.4
#> # i 296 more rows
\end{alltt}

%
\begin{SubSection}{Operators:}

The \code{:} operator selects a range of consecutive variables:

\begin{alltt}starwars %>% select(name:mass)
#> # A tibble: 87 x 3
#>   name           height  mass
#>   <chr>           <int> <dbl>
#> 1 Luke Skywalker    172    77
#> 2 C-3PO             167    75
#> 3 R2-D2              96    32
#> 4 Darth Vader       202   136
#> # i 83 more rows
\end{alltt}


The \code{!} operator negates a selection:

\begin{alltt}starwars %>% select(!(name:mass))
#> # A tibble: 87 x 11
#>   hair_color skin_color  eye_color birth_year sex   gender    homeworld species
#>   <chr>      <chr>       <chr>          <dbl> <chr> <chr>     <chr>     <chr>  
#> 1 blond      fair        blue            19   male  masculine Tatooine  Human  
#> 2 <NA>       gold        yellow         112   none  masculine Tatooine  Droid  
#> 3 <NA>       white, blue red             33   none  masculine Naboo     Droid  
#> 4 none       white       yellow          41.9 male  masculine Tatooine  Human  
#> # i 83 more rows
#> # i 3 more variables: films <list>, vehicles <list>, starships <list>

iris %>% select(!c(Sepal.Length, Petal.Length))
#> # A tibble: 150 x 3
#>   Sepal.Width Petal.Width Species
#>         <dbl>       <dbl> <fct>  
#> 1         3.5         0.2 setosa 
#> 2         3           0.2 setosa 
#> 3         3.2         0.2 setosa 
#> 4         3.1         0.2 setosa 
#> # i 146 more rows

iris %>% select(!ends_with("Width"))
#> # A tibble: 150 x 3
#>   Sepal.Length Petal.Length Species
#>          <dbl>        <dbl> <fct>  
#> 1          5.1          1.4 setosa 
#> 2          4.9          1.4 setosa 
#> 3          4.7          1.3 setosa 
#> 4          4.6          1.5 setosa 
#> # i 146 more rows
\end{alltt}


\code{\&} and \code{|} take the intersection or the union of two selections:

\begin{alltt}iris %>% select(starts_with("Petal") & ends_with("Width"))
#> # A tibble: 150 x 1
#>   Petal.Width
#>         <dbl>
#> 1         0.2
#> 2         0.2
#> 3         0.2
#> 4         0.2
#> # i 146 more rows

iris %>% select(starts_with("Petal") | ends_with("Width"))
#> # A tibble: 150 x 3
#>   Petal.Length Petal.Width Sepal.Width
#>          <dbl>       <dbl>       <dbl>
#> 1          1.4         0.2         3.5
#> 2          1.4         0.2         3  
#> 3          1.3         0.2         3.2
#> 4          1.5         0.2         3.1
#> # i 146 more rows
\end{alltt}


To take the difference between two selections, combine the \code{\&} and
\code{!} operators:

\begin{alltt}iris %>% select(starts_with("Petal") & !ends_with("Width"))
#> # A tibble: 150 x 1
#>   Petal.Length
#>          <dbl>
#> 1          1.4
#> 2          1.4
#> 3          1.3
#> 4          1.5
#> # i 146 more rows
\end{alltt}

\end{SubSection}

\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{arrange}{arrange}()},
\code{\LinkA{filter}{filter}()},
\code{\LinkA{mutate}{mutate}()},
\code{\LinkA{reframe}{reframe}()},
\code{\LinkA{rename}{rename}()},
\code{\LinkA{slice}{slice}()},
\code{\LinkA{summarise}{summarise}()}
\end{SeeAlso}
\HeaderA{select\_all}{Select and rename a selection of variables}{select.Rul.all}
\aliasA{rename\_all}{select\_all}{rename.Rul.all}
\aliasA{rename\_at}{select\_all}{rename.Rul.at}
\aliasA{rename\_if}{select\_all}{rename.Rul.if}
\aliasA{select\_at}{select\_all}{select.Rul.at}
\aliasA{select\_if}{select\_all}{select.Rul.if}
\keyword{internal}{select\_all}
%
\begin{Description}
\strong{[Superseded]}

\code{rename\_if()}, \code{rename\_at()}, and \code{rename\_all()} have been superseded by
\code{rename\_with()}. The matching select statements have been superseded by the
combination of a \code{select()} + \code{rename\_with()}. Any predicate functions passed
as arguments to \code{select()} or \code{rename\_with()} must be wrapped in \code{\LinkA{where()}{where}}.

These functions were superseded because \code{mutate\_if()} and friends were
superseded by \code{across()}. \code{select\_if()} and \code{rename\_if()} already use tidy
selection so they can't be replaced by \code{across()} and instead we need a new
function.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
select_all(.tbl, .funs = list(), ...)

rename_all(.tbl, .funs = list(), ...)

select_if(.tbl, .predicate, .funs = list(), ...)

rename_if(.tbl, .predicate, .funs = list(), ...)

select_at(.tbl, .vars, .funs = list(), ...)

rename_at(.tbl, .vars, .funs = list(), ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.funs}] A function \code{fun}, a purrr style lambda \code{\textasciitilde{} fun(.)} or a list of either form.

\item[\code{...}] Additional arguments for the function calls in
\code{.funs}. These are evaluated only once, with \LinkA{tidy dots}{tidy dots} support.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
mtcars <- as_tibble(mtcars) # for nicer printing

mtcars %>% rename_all(toupper)
# ->
mtcars %>% rename_with(toupper)

# NB: the transformation comes first in rename_with
is_whole <- function(x) all(floor(x) == x)
mtcars %>% rename_if(is_whole, toupper)
# ->
mtcars %>% rename_with(toupper, where(is_whole))

mtcars %>% rename_at(vars(mpg:hp), toupper)
# ->
mtcars %>% rename_with(toupper, mpg:hp)

# You now must select() and then rename

mtcars %>% select_all(toupper)
# ->
mtcars %>% rename_with(toupper)

# Selection drops unselected variables:
mtcars %>% select_if(is_whole, toupper)
# ->
mtcars %>% select(where(is_whole)) %>% rename_with(toupper)

mtcars %>% select_at(vars(-contains("ar"), starts_with("c")), toupper)
# ->
mtcars %>%
  select(!contains("ar") | starts_with("c")) %>%
  rename_with(toupper)
\end{ExampleCode}
\end{Examples}
\HeaderA{setops}{Set operations}{setops}
\aliasA{intersect}{setops}{intersect}
\aliasA{setdiff}{setops}{setdiff}
\aliasA{setequal}{setops}{setequal}
\aliasA{symdiff}{setops}{symdiff}
\aliasA{union}{setops}{union}
\aliasA{union\_all}{setops}{union.Rul.all}
%
\begin{Description}
Perform set operations using the rows of a data frame.
\begin{itemize}

\item{} \code{intersect(x, y)} finds all rows in both \code{x} and \code{y}.
\item{} \code{union(x, y)} finds all rows in either \code{x} or \code{y}, excluding duplicates.
\item{} \code{union\_all(x, y)} finds all rows in either \code{x} or \code{y}, including duplicates.
\item{} \code{setdiff(x, y)} finds all rows in \code{x} that aren't in \code{y}.
\item{} \code{symdiff(x, y)} computes the symmetric difference, i.e. all rows in
\code{x} that aren't in \code{y} and all rows in \code{y} that aren't in \code{x}.
\item{} \code{setequal(x, y)} returns \code{TRUE} if \code{x} and \code{y} contain the same rows
(ignoring order).

\end{itemize}


Note that \code{intersect()}, \code{union()}, \code{setdiff()}, and \code{symdiff()} remove
duplicates in \code{x} and \code{y}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
intersect(x, y, ...)

union(x, y, ...)

union_all(x, y, ...)

setdiff(x, y, ...)

setequal(x, y, ...)

symdiff(x, y, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}, \code{y}] Pair of compatible data frames. A pair of data frames is
compatible if they have the same column names (possibly in different
orders) and compatible types.

\item[\code{...}] These dots are for future extensions and must be empty.
\end{ldescription}
\end{Arguments}
%
\begin{Section}{Base functions}
\code{intersect()}, \code{union()}, \code{setdiff()}, and \code{setequal()} override the base
functions of the same name in order to make them generic. The existing
behaviour for vectors is preserved by providing default methods that call
the base functions.
\end{Section}
%
\begin{Examples}
\begin{ExampleCode}
df1 <- tibble(x = 1:3)
df2 <- tibble(x = 3:5)

intersect(df1, df2)
union(df1, df2)
union_all(df1, df2)
setdiff(df1, df2)
setdiff(df2, df1)
symdiff(df1, df2)

setequal(df1, df2)
setequal(df1, df1[3:1, ])

# Note that the following functions remove pre-existing duplicates:
df1 <- tibble(x = c(1:3, 3, 3))
df2 <- tibble(x = c(3:5, 5))

intersect(df1, df2)
union(df1, df2)
setdiff(df1, df2)
symdiff(df1, df2)
\end{ExampleCode}
\end{Examples}
\HeaderA{slice}{Subset rows using their positions}{slice}
\aliasA{slice\_head}{slice}{slice.Rul.head}
\aliasA{slice\_max}{slice}{slice.Rul.max}
\aliasA{slice\_min}{slice}{slice.Rul.min}
\aliasA{slice\_sample}{slice}{slice.Rul.sample}
\aliasA{slice\_tail}{slice}{slice.Rul.tail}
\keyword{single table verbs}{slice}
%
\begin{Description}
\code{slice()} lets you index rows by their (integer) locations. It allows you
to select, remove, and duplicate rows. It is accompanied by a number of
helpers for common use cases:
\begin{itemize}

\item{} \code{slice\_head()} and \code{slice\_tail()} select the first or last rows.
\item{} \code{slice\_sample()} randomly selects rows.
\item{} \code{slice\_min()} and \code{slice\_max()} select rows with the smallest or largest
values of a variable.

\end{itemize}


If \code{.data} is a \LinkA{grouped\_df}{grouped.Rul.df}, the operation will be performed on each group,
so that (e.g.) \code{slice\_head(df, n = 5)} will select the first five rows in
each group.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
slice(.data, ..., .by = NULL, .preserve = FALSE)

slice_head(.data, ..., n, prop, by = NULL)

slice_tail(.data, ..., n, prop, by = NULL)

slice_min(
  .data,
  order_by,
  ...,
  n,
  prop,
  by = NULL,
  with_ties = TRUE,
  na_rm = FALSE
)

slice_max(
  .data,
  order_by,
  ...,
  n,
  prop,
  by = NULL,
  with_ties = TRUE,
  na_rm = FALSE
)

slice_sample(.data, ..., n, prop, by = NULL, weight_by = NULL, replace = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] For \code{slice()}: <\code{\LinkA{data-masking}{data.Rdash.masking}}>
Integer row values.

Provide either positive values to keep, or negative values to drop.
The values provided must be either all positive or all negative.
Indices beyond the number of rows in the input are silently ignored.

For \AsIs{\texttt{slice\_*()}}, these arguments are passed on to methods.

\item[\code{.by}, \code{by}] \strong{[Experimental]}

<\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Optionally, a selection of columns to
group by for just this operation, functioning as an alternative to \code{\LinkA{group\_by()}{group.Rul.by}}. For
details and examples, see \LinkA{?dplyr\_by}{dplyr.Rul.by}.

\item[\code{.preserve}] Relevant when the \code{.data} input is grouped.
If \code{.preserve = FALSE} (the default), the grouping structure
is recalculated based on the resulting data, otherwise the grouping is kept as is.

\item[\code{n}, \code{prop}] Provide either \code{n}, the number of rows, or \code{prop}, the
proportion of rows to select. If neither are supplied, \code{n = 1} will be
used. If \code{n} is greater than the number of rows in the group
(or \code{prop > 1}), the result will be silently truncated to the group size.
\code{prop} will be rounded towards zero to generate an integer number of
rows.

A negative value of \code{n} or \code{prop} will be subtracted from the group
size. For example, \code{n = -2} with a group of 5 rows will select 5 - 2 = 3
rows; \code{prop = -0.25} with 8 rows will select 8 * (1 - 0.25) = 6 rows.

\item[\code{order\_by}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Variable or
function of variables to order by. To order by multiple variables, wrap
them in a data frame or tibble.

\item[\code{with\_ties}] Should ties be kept together? The default, \code{TRUE},
may return more rows than you request. Use \code{FALSE} to ignore ties,
and return the first \code{n} rows.

\item[\code{na\_rm}] Should missing values in \code{order\_by} be removed from the result?
If \code{FALSE}, \code{NA} values are sorted to the end (like in \code{\LinkA{arrange()}{arrange}}), so
they will only be included if there are insufficient non-missing values to
reach \code{n}/\code{prop}.

\item[\code{weight\_by}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Sampling
weights. This must evaluate to a vector of non-negative numbers the same
length as the input. Weights are automatically standardised to sum to 1.

\item[\code{replace}] Should sampling be performed with (\code{TRUE}) or without
(\code{FALSE}, the default) replacement.
\end{ldescription}
\end{Arguments}
%
\begin{Details}
Slice does not work with relational databases because they have no
intrinsic notion of row order. If you want to perform the equivalent
operation, use \code{\LinkA{filter()}{filter}} and \code{\LinkA{row\_number()}{row.Rul.number}}.
\end{Details}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} Each row may appear 0, 1, or many times in the output.
\item{} Columns are not modified.
\item{} Groups are not modified.
\item{} Data frame attributes are preserved.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

These function are \strong{generic}s, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
\begin{itemize}

\item{} \code{slice()}: no methods found.
\item{} \code{slice\_head()}: no methods found.
\item{} \code{slice\_tail()}: no methods found.
\item{} \code{slice\_min()}: no methods found.
\item{} \code{slice\_max()}: no methods found.
\item{} \code{slice\_sample()}: no methods found.

\end{itemize}

\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{arrange}{arrange}()},
\code{\LinkA{filter}{filter}()},
\code{\LinkA{mutate}{mutate}()},
\code{\LinkA{reframe}{reframe}()},
\code{\LinkA{rename}{rename}()},
\code{\LinkA{select}{select}()},
\code{\LinkA{summarise}{summarise}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# Similar to head(mtcars, 1):
mtcars %>% slice(1L)
# Similar to tail(mtcars, 1):
mtcars %>% slice(n())
mtcars %>% slice(5:n())
# Rows can be dropped with negative indices:
slice(mtcars, -(1:4))

# First and last rows based on existing order
mtcars %>% slice_head(n = 5)
mtcars %>% slice_tail(n = 5)

# Rows with minimum and maximum values of a variable
mtcars %>% slice_min(mpg, n = 5)
mtcars %>% slice_max(mpg, n = 5)

# slice_min() and slice_max() may return more rows than requested
# in the presence of ties.
mtcars %>% slice_min(cyl, n = 1)
# Use with_ties = FALSE to return exactly n matches
mtcars %>% slice_min(cyl, n = 1, with_ties = FALSE)
# Or use additional variables to break the tie:
mtcars %>% slice_min(tibble(cyl, mpg), n = 1)

# slice_sample() allows you to random select with or without replacement
mtcars %>% slice_sample(n = 5)
mtcars %>% slice_sample(n = 5, replace = TRUE)

# you can optionally weight by a variable - this code weights by the
# physical weight of the cars, so heavy cars are more likely to get
# selected
mtcars %>% slice_sample(weight_by = wt, n = 5)

# Group wise operation ----------------------------------------
df <- tibble(
  group = rep(c("a", "b", "c"), c(1, 2, 4)),
  x = runif(7)
)

# All slice helpers operate per group, silently truncating to the group
# size, so the following code works without error
df %>% group_by(group) %>% slice_head(n = 2)

# When specifying the proportion of rows to include non-integer sizes
# are rounded down, so group a gets 0 rows
df %>% group_by(group) %>% slice_head(prop = 0.5)

# Filter equivalents --------------------------------------------
# slice() expressions can often be written to use `filter()` and
# `row_number()`, which can also be translated to SQL. For many databases,
# you'll need to supply an explicit variable to use to compute the row number.
filter(mtcars, row_number() == 1L)
filter(mtcars, row_number() == n())
filter(mtcars, between(row_number(), 5, n()))
\end{ExampleCode}
\end{Examples}
\HeaderA{sql}{SQL escaping.}{sql}
%
\begin{Description}
These functions are critical when writing functions that translate R
functions to sql functions. Typically a conversion function should escape
all its inputs and return an sql object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sql(...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] Character vectors that will be combined into a single SQL
expression.
\end{ldescription}
\end{Arguments}
\HeaderA{src}{Create a "src" object}{src}
\aliasA{is.src}{src}{is.src}
\keyword{internal}{src}
%
\begin{Description}
\code{src()} is the standard constructor for srcs and \code{is.src()} tests.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
src(subclass, ...)

is.src(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{subclass}] name of subclass. "src" is an abstract base class, so you
must supply this value. \code{src\_} is automatically prepended to the
class name

\item[\code{...}] fields used by object.

These dots are evaluated with \LinkA{explicit splicing}{explicit splicing}.

\item[\code{x}] object to test for "src"-ness.
\end{ldescription}
\end{Arguments}
\HeaderA{src\_dbi}{Source for database backends}{src.Rul.dbi}
\aliasA{src\_mysql}{src\_dbi}{src.Rul.mysql}
\aliasA{src\_postgres}{src\_dbi}{src.Rul.postgres}
\aliasA{src\_sqlite}{src\_dbi}{src.Rul.sqlite}
\keyword{internal}{src\_dbi}
%
\begin{Description}
\strong{[Deprecated]}

These functions have been deprecated; instead please use \code{\LinkA{tbl()}{tbl}}
directly on an \code{DBIConnection}. See \url{https://dbplyr.tidyverse.org/} for
more details.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
src_mysql(
  dbname,
  host = NULL,
  port = 0L,
  username = "root",
  password = "",
  ...
)

src_postgres(
  dbname = NULL,
  host = NULL,
  port = NULL,
  user = NULL,
  password = NULL,
  ...
)

src_sqlite(path, create = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dbname}] Database name

\item[\code{host}, \code{port}] Host name and port number of database

\item[\code{...}] for the src, other arguments passed on to the underlying
database connector, \code{\LinkA{DBI::dbConnect()}{DBI::dbConnect()}}. For the tbl, included for
compatibility with the generic, but otherwise ignored.

\item[\code{user}, \code{username}, \code{password}] User name and password.

Generally, you should avoid saving username and password in your
scripts as it is easy to accidentally expose valuable credentials.
Instead, retrieve them from environment variables, or use database
specific credential scores. For example, with MySQL you can set up \code{my.cnf}
as described in \code{\LinkA{RMySQL::MySQL()}{RMySQL::MySQL()}}.

\item[\code{path}] Path to SQLite database. You can use the special path
":memory:" to create a temporary in memory database.

\item[\code{create}] if \code{FALSE}, \code{path} must already exist. If
\code{TRUE}, will create a new SQLite3 database at \code{path} if
\code{path} does not exist and connect to the existing database if
\code{path} does exist.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An S3 object with class \code{src\_dbi}, \code{src\_sql}, \code{src}.
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}

con <- DBI::dbConnect(RSQLite::SQLite(), ":memory:")
copy_to(con, mtcars)

# To retrieve a single table from a source, use `tbl()`
mtcars <- con %>% tbl("mtcars")
mtcars

# You can also use pass raw SQL if you want a more sophisticated query
con %>% tbl(sql("SELECT * FROM mtcars WHERE cyl == 8"))

\end{ExampleCode}
\end{Examples}
\HeaderA{src\_local}{A local source}{src.Rul.local}
\aliasA{src\_df}{src\_local}{src.Rul.df}
\keyword{internal}{src\_local}
%
\begin{Description}
\strong{[Deprecated]}
This function was deprecated since it existed to support a style of testing
dplyr backends that turned out not to be useful.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
src_local(tbl, pkg = NULL, env = NULL)

src_df(pkg = NULL, env = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{tbl}] name of the function used to generate \code{tbl} objects

\item[\code{pkg}, \code{env}] Either the name of a package or an environment object in
which to look for objects.
\end{ldescription}
\end{Arguments}
\HeaderA{src\_tbls}{List all tbls provided by a source.}{src.Rul.tbls}
\keyword{internal}{src\_tbls}
%
\begin{Description}
This is a generic method which individual src's will provide methods for.
Most methods will not be documented because it's usually pretty obvious what
possible results will be.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
src_tbls(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] a data src.

\item[\code{...}] other arguments passed on to the individual methods.
\end{ldescription}
\end{Arguments}
\HeaderA{starwars}{Starwars characters}{starwars}
\keyword{datasets}{starwars}
%
\begin{Description}
The original data, from SWAPI, the Star Wars API, \url{https://swapi.py4e.com/}, has been revised
to reflect additional research into gender and sex determinations of characters.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
starwars
\end{verbatim}
\end{Usage}
%
\begin{Format}
A tibble with 87 rows and 14 variables:
\begin{description}

\item[name] Name of the character
\item[height] Height (cm)
\item[mass] Weight (kg)
\item[hair\_color,skin\_color,eye\_color] Hair, skin, and eye colors
\item[birth\_year] Year born (BBY = Before Battle of Yavin)
\item[sex] The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).
\item[gender] The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).
\item[homeworld] Name of homeworld
\item[species] Name of species
\item[films] List of films the character appeared in
\item[vehicles] List of vehicles the character has piloted
\item[starships] List of starships the character has piloted

\end{description}

\end{Format}
%
\begin{Examples}
\begin{ExampleCode}
starwars
\end{ExampleCode}
\end{Examples}
\HeaderA{storms}{Storm tracks data}{storms}
\keyword{datasets}{storms}
%
\begin{Description}
This dataset is the NOAA Atlantic hurricane database best track data,
\url{https://www.nhc.noaa.gov/data/\#hurdat}. The data includes the positions and
attributes of storms from 1975-2022. Storms
from 1979 onward are measured every six hours during the lifetime of the
storm. Storms in earlier years have some missing data.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
storms
\end{verbatim}
\end{Usage}
%
\begin{Format}
A tibble with 19,537 observations
and 13 variables:
\begin{description}

\item[name] Storm Name
\item[year,month,day] Date of report
\item[hour] Hour of report (in UTC)
\item[lat,long] Location of storm center
\item[status] Storm classification (Tropical Depression, Tropical Storm,
or Hurricane)
\item[category] Saffir-Simpson hurricane category calculated from wind speed.
\begin{itemize}

\item{} \code{NA}: Not a hurricane
\item{} 1: 64+ knots
\item{} 2: 83+ knots
\item{} 3: 96+ knots
\item{} 4: 113+ knots
\item{} 5: 137+ knots

\end{itemize}


\item[wind] storm's maximum sustained wind speed (in knots)
\item[pressure] Air pressure at the storm's center (in millibars)
\item[tropicalstorm\_force\_diameter] Diameter (in nautical miles) of the
area experiencing tropical storm strength winds (34 knots or above).
Only available starting in 2004.
\item[hurricane\_force\_diameter] Diameter (in nautical miles) of the area
experiencing hurricane strength winds (64 knots or above). Only available
starting in 2004.

\end{description}

\end{Format}
%
\begin{SeeAlso}
The script to create the storms data set:
\url{https://github.com/tidyverse/dplyr/blob/main/data-raw/storms.R}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
storms

# Show a few recent storm paths
if (requireNamespace("ggplot2", quietly = TRUE)) {
  library(ggplot2)
  storms %>%
    filter(year >= 2000) %>%
    ggplot(aes(long, lat, color = paste(year, name))) +
    geom_path(show.legend = FALSE) +
    facet_wrap(~year)
}

storms
\end{ExampleCode}
\end{Examples}
\HeaderA{summarise}{Summarise each group down to one row}{summarise}
\aliasA{summarize}{summarise}{summarize}
\keyword{single table verbs}{summarise}
%
\begin{Description}
\code{summarise()} creates a new data frame. It returns one row for each
combination of grouping variables; if there are no grouping variables, the
output will have a single row summarising all observations in the input. It
will contain one column for each grouping variable and one column for each of
the summary statistics that you have specified.

\code{summarise()} and \code{summarize()} are synonyms.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
summarise(.data, ..., .by = NULL, .groups = NULL)

summarize(.data, ..., .by = NULL, .groups = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Name-value pairs of
summary functions. The name will be the name of the variable in the result.

The value can be:
\begin{itemize}

\item{} A vector of length 1, e.g. \code{min(x)}, \code{n()}, or \code{sum(is.na(y))}.
\item{} A data frame, to add multiple columns from a single expression.

\end{itemize}


\strong{[Deprecated]} Returning values with size 0 or >1 was
deprecated as of 1.1.0. Please use \code{\LinkA{reframe()}{reframe}} for this instead.

\item[\code{.by}] \strong{[Experimental]}

<\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Optionally, a selection of columns to
group by for just this operation, functioning as an alternative to \code{\LinkA{group\_by()}{group.Rul.by}}. For
details and examples, see \LinkA{?dplyr\_by}{dplyr.Rul.by}.

\item[\code{.groups}] \strong{[Experimental]} Grouping structure of the
result.
\begin{itemize}

\item{} "drop\_last": dropping the last level of grouping. This was the
only supported option before version 1.0.0.
\item{} "drop": All levels of grouping are dropped.
\item{} "keep": Same grouping structure as \code{.data}.
\item{} "rowwise": Each row is its own group.

\end{itemize}


When \code{.groups} is not specified, it is chosen
based on the number of rows of the results:
\begin{itemize}

\item{} If all the results have 1 row, you get "drop\_last".
\item{} If the number of rows varies, you get "keep" (note that returning a
variable number of rows was deprecated in favor of \code{\LinkA{reframe()}{reframe}}, which
also unconditionally drops all levels of grouping).

\end{itemize}


In addition, a message informs you of that choice, unless the result is ungrouped,
the option "dplyr.summarise.inform" is set to \code{FALSE},
or when \code{summarise()} is called from a function in a package.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object \emph{usually} of the same type as \code{.data}.
\begin{itemize}

\item{} The rows come from the underlying \code{\LinkA{group\_keys()}{group.Rul.keys}}.
\item{} The columns are a combination of the grouping keys and the summary
expressions that you provide.
\item{} The grouping structure is controlled by the \AsIs{\texttt{.groups=}} argument, the
output may be another \LinkA{grouped\_df}{grouped.Rul.df}, a \LinkA{tibble}{tibble} or a \LinkA{rowwise}{rowwise} data frame.
\item{} Data frame attributes are \strong{not} preserved, because \code{summarise()}
fundamentally creates a new data frame.

\end{itemize}

\end{Value}
%
\begin{Section}{Useful functions}

\begin{itemize}

\item{} Center: \code{\LinkA{mean()}{mean}}, \code{\LinkA{median()}{median}}
\item{} Spread: \code{\LinkA{sd()}{sd}}, \code{\LinkA{IQR()}{IQR}}, \code{\LinkA{mad()}{mad}}
\item{} Range: \code{\LinkA{min()}{min}}, \code{\LinkA{max()}{max}},
\item{} Position: \code{\LinkA{first()}{first}}, \code{\LinkA{last()}{last}}, \code{\LinkA{nth()}{nth}},
\item{} Count: \code{\LinkA{n()}{n}}, \code{\LinkA{n\_distinct()}{n.Rul.distinct}}
\item{} Logical: \code{\LinkA{any()}{any}}, \code{\LinkA{all()}{all}}

\end{itemize}

\end{Section}
%
\begin{Section}{Backend variations}


The data frame backend supports creating a variable and using it in the
same summary. This means that previously created summary variables can be
further transformed or combined within the summary, as in \code{\LinkA{mutate()}{mutate}}.
However, it also means that summary variables with the same names as previous
variables overwrite them, making those variables unavailable to later summary
variables.

This behaviour may not be supported in other backends. To avoid unexpected
results, consider using new names for your summary variables, especially when
creating multiple summaries.
\end{Section}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

The following methods are currently available in loaded packages:
no methods found.
\end{Section}
%
\begin{SeeAlso}
Other single table verbs: 
\code{\LinkA{arrange}{arrange}()},
\code{\LinkA{filter}{filter}()},
\code{\LinkA{mutate}{mutate}()},
\code{\LinkA{reframe}{reframe}()},
\code{\LinkA{rename}{rename}()},
\code{\LinkA{select}{select}()},
\code{\LinkA{slice}{slice}()}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# A summary applied to ungrouped tbl returns a single row
mtcars %>%
  summarise(mean = mean(disp), n = n())

# Usually, you'll want to group first
mtcars %>%
  group_by(cyl) %>%
  summarise(mean = mean(disp), n = n())

# Each summary call removes one grouping level (since that group
# is now just a single row)
mtcars %>%
  group_by(cyl, vs) %>%
  summarise(cyl_n = n()) %>%
  group_vars()

# BEWARE: reusing variables may lead to unexpected results
mtcars %>%
  group_by(cyl) %>%
  summarise(disp = mean(disp), sd = sd(disp))

# Refer to column names stored as strings with the `.data` pronoun:
var <- "mass"
summarise(starwars, avg = mean(.data[[var]], na.rm = TRUE))
# Learn more in ?rlang::args_data_masking

# In dplyr 1.1.0, returning multiple rows per group was deprecated in favor
# of `reframe()`, which never messages and always returns an ungrouped
# result:
mtcars %>%
   group_by(cyl) %>%
   summarise(qs = quantile(disp, c(0.25, 0.75)), prob = c(0.25, 0.75))
# ->
mtcars %>%
   group_by(cyl) %>%
   reframe(qs = quantile(disp, c(0.25, 0.75)), prob = c(0.25, 0.75))
\end{ExampleCode}
\end{Examples}
\HeaderA{summarise\_all}{Summarise multiple columns}{summarise.Rul.all}
\aliasA{summarise\_at}{summarise\_all}{summarise.Rul.at}
\aliasA{summarise\_if}{summarise\_all}{summarise.Rul.if}
\aliasA{summarize\_all}{summarise\_all}{summarize.Rul.all}
\aliasA{summarize\_at}{summarise\_all}{summarize.Rul.at}
\aliasA{summarize\_if}{summarise\_all}{summarize.Rul.if}
\keyword{internal}{summarise\_all}
%
\begin{Description}
\strong{[Superseded]}

Scoped verbs (\AsIs{\texttt{\_if}}, \AsIs{\texttt{\_at}}, \AsIs{\texttt{\_all}}) have been superseded by the use of
\code{\LinkA{pick()}{pick}} or \code{\LinkA{across()}{across}} in an existing verb. See \code{vignette("colwise")} for
details.

The \LinkA{scoped}{scoped} variants of \code{\LinkA{summarise()}{summarise}} make it easy to apply the same
transformation to multiple variables.
There are three variants.
\begin{itemize}

\item{} \code{summarise\_all()} affects every variable
\item{} \code{summarise\_at()} affects variables selected with a character vector or
vars()
\item{} \code{summarise\_if()} affects variables selected with a predicate function

\end{itemize}

\end{Description}
%
\begin{Usage}
\begin{verbatim}
summarise_all(.tbl, .funs, ...)

summarise_if(.tbl, .predicate, .funs, ...)

summarise_at(.tbl, .vars, .funs, ..., .cols = NULL)

summarize_all(.tbl, .funs, ...)

summarize_if(.tbl, .predicate, .funs, ...)

summarize_at(.tbl, .vars, .funs, ..., .cols = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.tbl}] A \code{tbl} object.

\item[\code{.funs}] A function \code{fun}, a quosure style lambda \code{\textasciitilde{} fun(.)} or a list of either form.

\item[\code{...}] Additional arguments for the function calls in
\code{.funs}. These are evaluated only once, with \LinkA{tidy dots}{tidy dots} support.

\item[\code{.predicate}] A predicate function to be applied to the columns
or a logical vector. The variables for which \code{.predicate} is or
returns \code{TRUE} are selected. This argument is passed to
\code{\LinkA{rlang::as\_function()}{rlang::as.Rul.function()}} and thus supports quosure-style lambda
functions and strings representing function names.

\item[\code{.vars}] A list of columns generated by \code{\LinkA{vars()}{vars}},
a character vector of column names, a numeric vector of column
positions, or \code{NULL}.

\item[\code{.cols}] This argument has been renamed to \code{.vars} to fit
dplyr's terminology and is deprecated.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A data frame. By default, the newly created columns have the shortest
names needed to uniquely identify the output. To force inclusion of a name,
even when not needed, name the input (see examples for details).
\end{Value}
%
\begin{Section}{Grouping variables}


If applied on a grouped tibble, these operations are \emph{not} applied
to the grouping variables. The behaviour depends on whether the
selection is \strong{implicit} (\code{all} and \code{if} selections) or
\strong{explicit} (\code{at} selections).
\begin{itemize}

\item{} Grouping variables covered by explicit selections in
\code{summarise\_at()} are always an error. Add \code{-group\_cols()} to the
\code{\LinkA{vars()}{vars}} selection to avoid this:

\begin{alltt}data %>%
  summarise_at(vars(-group_cols(), ...), myoperation)
\end{alltt}


Or remove \code{group\_vars()} from the character vector of column names:

\begin{alltt}nms <- setdiff(nms, group_vars(data))
data %>% summarise_at(nms, myoperation)
\end{alltt}

\item{} Grouping variables covered by implicit selections are silently
ignored by \code{summarise\_all()} and \code{summarise\_if()}.

\end{itemize}

\end{Section}
%
\begin{Section}{Naming}


The names of the new columns are derived from the names of the
input variables and the names of the functions.
\begin{itemize}

\item{} if there is only one unnamed function (i.e. if \code{.funs} is an unnamed list
of length one),
the names of the input variables are used to name the new columns;
\item{} for \AsIs{\texttt{\_at}} functions, if there is only one unnamed variable (i.e.,
if \code{.vars} is of the form \code{vars(a\_single\_column)}) and \code{.funs} has length
greater than one,
the names of the functions are used to name the new columns;
\item{} otherwise, the new names are created by
concatenating the names of the input variables and the names of the
functions, separated with an underscore \code{"\_"}.

\end{itemize}


The \code{.funs} argument can be a named or unnamed list.
If a function is unnamed and the name cannot be derived automatically,
a name of the form "fn\#" is used.
Similarly, \code{\LinkA{vars()}{vars}} accepts named and unnamed arguments.
If a variable in \code{.vars} is named, a new column by that name will be created.

Name collisions in the new columns are disambiguated using a unique suffix.
\end{Section}
%
\begin{SeeAlso}
\LinkA{The other scoped verbs}{scoped}, \code{\LinkA{vars()}{vars}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
# The _at() variants directly support strings:
starwars %>%
  summarise_at(c("height", "mass"), mean, na.rm = TRUE)
# ->
starwars %>% summarise(across(c("height", "mass"), ~ mean(.x, na.rm = TRUE)))

# You can also supply selection helpers to _at() functions but you have
# to quote them with vars():
starwars %>%
  summarise_at(vars(height:mass), mean, na.rm = TRUE)
# ->
starwars %>%
  summarise(across(height:mass, ~ mean(.x, na.rm = TRUE)))

# The _if() variants apply a predicate function (a function that
# returns TRUE or FALSE) to determine the relevant subset of
# columns. Here we apply mean() to the numeric columns:
starwars %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)
starwars %>%
  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))

by_species <- iris %>%
  group_by(Species)

# If you want to apply multiple transformations, pass a list of
# functions. When there are multiple functions, they create new
# variables instead of modifying the variables in place:
by_species %>%
  summarise_all(list(min, max))
# ->
by_species %>%
  summarise(across(everything(), list(min = min, max = max)))
\end{ExampleCode}
\end{Examples}
\HeaderA{summarise\_each}{Summarise and mutate multiple columns.}{summarise.Rul.each}
\aliasA{mutate\_each}{summarise\_each}{mutate.Rul.each}
\aliasA{mutate\_each\_}{summarise\_each}{mutate.Rul.each.Rul.}
\aliasA{summarise\_each\_}{summarise\_each}{summarise.Rul.each.Rul.}
\aliasA{summarize\_each}{summarise\_each}{summarize.Rul.each}
\aliasA{summarize\_each\_}{summarise\_each}{summarize.Rul.each.Rul.}
\keyword{internal}{summarise\_each}
%
\begin{Description}
\strong{[Deprecated]}

\code{mutate\_each()} and \code{summarise\_each()} are deprecated in favour of
the new \code{\LinkA{across()}{across}} function that works within \code{summarise()} and \code{mutate()}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
summarise_each(tbl, funs, ...)

summarise_each_(tbl, funs, vars)

mutate_each(tbl, funs, ...)

mutate_each_(tbl, funs, vars)

summarize_each(tbl, funs, ...)

summarize_each_(tbl, funs, vars)
\end{verbatim}
\end{Usage}
\HeaderA{tbl}{Create a table from a data source}{tbl}
\aliasA{is.tbl}{tbl}{is.tbl}
%
\begin{Description}
This is a generic method that dispatches based on the first argument.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tbl(src, ...)

is.tbl(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{src}] A data source

\item[\code{...}] Other arguments passed on to the individual methods

\item[\code{x}] Any object
\end{ldescription}
\end{Arguments}
\HeaderA{tbl\_df}{Coerce to a tibble}{tbl.Rul.df}
\aliasA{as.tbl}{tbl\_df}{as.tbl}
\keyword{internal}{tbl\_df}
%
\begin{Description}
\strong{[Deprecated]}
Please use \code{\LinkA{tibble::as\_tibble()}{tibble::as.Rul.tibble()}} instead.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tbl_df(data)

as.tbl(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}, \code{x}] Object to coerce
\end{ldescription}
\end{Arguments}
\HeaderA{tbl\_ptype}{Return a prototype of a tbl}{tbl.Rul.ptype}
\keyword{internal}{tbl\_ptype}
%
\begin{Description}
Used in \AsIs{\texttt{\_if}} functions to enable type-based selection even when the data
is lazily generated. Should either return the complete tibble, or if that
can not be computed quickly, a 0-row tibble where the columns are of
the correct type.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tbl_ptype(.data)
\end{verbatim}
\end{Usage}
\HeaderA{tbl\_vars}{List variables provided by a tbl.}{tbl.Rul.vars}
\aliasA{tbl\_nongroup\_vars}{tbl\_vars}{tbl.Rul.nongroup.Rul.vars}
\keyword{internal}{tbl\_vars}
%
\begin{Description}
\code{tbl\_vars()} returns all variables while \code{tbl\_nongroup\_vars()}
returns only non-grouping variables. The \code{groups} attribute
of the object returned by \code{tbl\_vars()} is a character vector of the
grouping columns.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
tbl_vars(x)

tbl_nongroup_vars(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A tbl object
\end{ldescription}
\end{Arguments}
%
\begin{SeeAlso}
\code{\LinkA{group\_vars()}{group.Rul.vars}} for a function that returns grouping
variables.
\end{SeeAlso}
\HeaderA{tidyeval-compat}{Other tidy eval tools}{tidyeval.Rdash.compat}
\aliasA{.data}{tidyeval-compat}{.data}
\aliasA{as\_label}{tidyeval-compat}{as.Rul.label}
\aliasA{enexpr}{tidyeval-compat}{enexpr}
\aliasA{enexprs}{tidyeval-compat}{enexprs}
\aliasA{enquo}{tidyeval-compat}{enquo}
\aliasA{enquos}{tidyeval-compat}{enquos}
\aliasA{ensym}{tidyeval-compat}{ensym}
\aliasA{ensyms}{tidyeval-compat}{ensyms}
\aliasA{expr}{tidyeval-compat}{expr}
\aliasA{quo}{tidyeval-compat}{quo}
\aliasA{quos}{tidyeval-compat}{quos}
\aliasA{quo\_name}{tidyeval-compat}{quo.Rul.name}
\aliasA{sym}{tidyeval-compat}{sym}
\aliasA{syms}{tidyeval-compat}{syms}
\keyword{internal}{tidyeval-compat}
%
\begin{Description}
These tidy eval functions are no longer for normal usage, but are still
exported from dplyr for backward compatibility.
See \code{\LinkA{?rlang::args\_data\_masking}{?rlang::args.Rul.data.Rul.masking}} and
\code{vignette("programming")} for the latest recommendations.
\begin{itemize}

\item{} \LinkA{expr()}{expr()}
\item{} \LinkA{enquo()}{enquo()}
\item{} \LinkA{enquos()}{enquos()}
\item{} \LinkA{sym()}{sym()}
\item{} \LinkA{syms()}{syms()}
\item{} \LinkA{as\_label()}{as.Rul.label()}
\item{} \LinkA{quo()}{quo()}
\item{} \LinkA{quos()}{quos()}
\item{} \LinkA{quo\_name()}{quo.Rul.name()}
\item{} \LinkA{ensym()}{ensym()}
\item{} \LinkA{ensyms()}{ensyms()}
\item{} \LinkA{enexpr()}{enexpr()}
\item{} \LinkA{enexprs()}{enexprs()}

\end{itemize}

\end{Description}
\HeaderA{top\_n}{Select top (or bottom) n rows (by value)}{top.Rul.n}
\aliasA{top\_frac}{top\_n}{top.Rul.frac}
\keyword{internal}{top\_n}
%
\begin{Description}
\strong{[Superseded]}
\code{top\_n()} has been superseded in favour of \code{\LinkA{slice\_min()}{slice.Rul.min}}/\code{\LinkA{slice\_max()}{slice.Rul.max}}.
While it will not be deprecated in the near future, retirement means
that we will only perform critical bug fixes, so we recommend moving to the
newer alternatives.

\code{top\_n()} was superseded because the name was fundamentally confusing as
it returned what you might reasonably consider to be the \emph{bottom}
rows. Additionally, the \code{wt} variable had a confusing name, and strange
default (the last column in the data frame). Unfortunately we could not
see an easy way to fix the existing \code{top\_n()} function without breaking
existing code, so we created a new alternative.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
top_n(x, n, wt)

top_frac(x, n, wt)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A data frame.

\item[\code{n}] Number of rows to return for \code{top\_n()}, fraction of rows to
return for \code{top\_frac()}. If \code{n} is positive, selects the top rows.
If negative, selects the bottom rows.
If \code{x} is grouped, this is the number (or fraction) of rows per group.
Will include more rows if there are ties.

\item[\code{wt}] (Optional). The variable to use for ordering. If not
specified, defaults to the last variable in the tbl.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
df <- data.frame(x = c(6, 4, 1, 10, 3, 1, 1))

df %>% top_n(2)  # highest values
df %>% top_n(-2) # lowest values
# now use
df %>% slice_max(x, n = 2)
df %>% slice_min(x, n = 2)

# top_frac() -> prop argument of slice_min()/slice_max()
df %>% top_frac(.5)
# ->
df %>% slice_max(x, prop = 0.5)
\end{ExampleCode}
\end{Examples}
\HeaderA{transmute}{Create, modify, and delete columns}{transmute}
\keyword{internal}{transmute}
%
\begin{Description}
\strong{[Superseded]}

\code{transmute()} creates a new data frame containing only the specified
computations. It's superseded because you can perform the same job
with \code{mutate(.keep = "none")}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
transmute(.data, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame, data frame extension (e.g. a tibble), or a
lazy data frame (e.g. from dbplyr or dtplyr). See \emph{Methods}, below, for
more details.

\item[\code{...}] <\code{\LinkA{data-masking}{data.Rdash.masking}}> Name-value pairs.
The name gives the name of the column in the output.

The value can be:
\begin{itemize}

\item{} A vector of length 1, which will be recycled to the correct length.
\item{} A vector the same length as the current group (or the whole data frame
if ungrouped).
\item{} \code{NULL}, to remove the column.
\item{} A data frame or tibble, to create multiple columns in the output.

\end{itemize}

\end{ldescription}
\end{Arguments}
%
\begin{Value}
An object of the same type as \code{.data}. The output has the following
properties:
\begin{itemize}

\item{} Columns created or modified through \code{...} will be returned in the order
specified by \code{...}.
\item{} Unmodified grouping columns will be placed at the front.
\item{} The number of rows is not affected.
\item{} Columns given the value \code{NULL} will be removed.
\item{} Groups will be recomputed if a grouping variable is mutated.
\item{} Data frame attributes are preserved.

\end{itemize}

\end{Value}
%
\begin{Section}{Methods}

This function is a \strong{generic}, which means that packages can provide
implementations (methods) for other classes. See the documentation of
individual methods for extra arguments and differences in behaviour.

Methods available in currently loaded packages:
no methods found.
\end{Section}
\HeaderA{vars}{Select variables}{vars}
%
\begin{Description}
\strong{[Superseded]}

\code{vars()} is superseded because it is only needed for the scoped verbs (i.e.
\code{\LinkA{mutate\_at()}{mutate.Rul.at}}, \code{\LinkA{summarise\_at()}{summarise.Rul.at}}, and friends), which have been been
superseded in favour of \code{\LinkA{across()}{across}}. See \code{vignette("colwise")} for details.

This helper is intended to provide tidy-select semantics for scoped verbs
like \code{mutate\_at()} and \code{summarise\_at()}. Note that anywhere you can supply
\code{vars()} specification, you can also supply a numeric vector of column
positions or a character vector of column names.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
vars(...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{...}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> Variables to operate on.
\end{ldescription}
\end{Arguments}
%
\begin{SeeAlso}
\code{\LinkA{all\_vars()}{all.Rul.vars}} and \code{\LinkA{any\_vars()}{any.Rul.vars}} for other quoting
functions that you can use with scoped verbs.
\end{SeeAlso}
\HeaderA{with\_groups}{Perform an operation with temporary groups}{with.Rul.groups}
\keyword{internal}{with\_groups}
%
\begin{Description}
\strong{[Superseded]}

This was an experimental function that allows you to modify the grouping
variables for a single operation; it is superseded in favour of using the
\code{.by} argument to individual verbs.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
with_groups(.data, .groups, .f, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{.data}] A data frame

\item[\code{.groups}] <\code{\LinkA{tidy-select}{dplyr.Rul.tidy.Rul.select}}> One or more variables
to group by. Unlike \code{\LinkA{group\_by()}{group.Rul.by}}, you can only group by existing variables,
and you can use tidy-select syntax like \code{c(x, y, z)} to select multiple
variables.

Use \code{NULL} to temporarily \strong{un}group.

\item[\code{.f}] Function to apply to regrouped data.
Supports purrr-style \code{\textasciitilde{}} syntax

\item[\code{...}] Additional arguments passed on to \code{...}.
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
df <- tibble(g = c(1, 1, 2, 2, 3), x = runif(5))

# Old
df %>%
  with_groups(g, mutate, x_mean = mean(x))
# New
df %>% mutate(x_mean = mean(x), .by = g)
\end{ExampleCode}
\end{Examples}
\HeaderA{with\_order}{Run a function with one order, translating result back to original order}{with.Rul.order}
\keyword{internal}{with\_order}
%
\begin{Description}
This is used to power the ordering parameters of dplyr's window functions
\end{Description}
%
\begin{Usage}
\begin{verbatim}
with_order(order_by, fun, x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{order\_by}] vector to order by

\item[\code{fun}] window function

\item[\code{x}, \code{...}] arguments to \code{f}
\end{ldescription}
\end{Arguments}
\printindex{}
\end{document}
